2023-06-26 05:04:25,835:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-26 05:04:25,836:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-26 05:04:25,836:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-26 05:04:25,836:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-26 05:04:27,816:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-26 05:04:53,468:WARNING:C:\New folder\lib\site-packages\pandas_profiling\model\correlations.py:67: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/pandas-profiling/issues
(include the error message: 'No data; `observed` has size 0.')
  warnings.warn(

2023-06-26 05:06:04,856:INFO:PyCaret RegressionExperiment
2023-06-26 05:06:04,857:INFO:Logging name: reg-default-name
2023-06-26 05:06:04,857:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-26 05:06:04,857:INFO:version 3.0.2
2023-06-26 05:06:04,858:INFO:Initializing setup()
2023-06-26 05:06:04,858:INFO:self.USI: 264a
2023-06-26 05:06:04,858:INFO:self._variable_keys: {'log_plots_param', 'target_param', 'pipeline', 'y_train', 'memory', 'USI', 'exp_id', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'X_test', 'transform_target_param', 'data', 'logging_param', '_ml_usecase', 'idx', 'n_jobs_param', 'y', 'X', '_available_plots', 'gpu_param', 'X_train', 'exp_name_log', 'seed', 'html_param', 'fold_shuffle_param'}
2023-06-26 05:06:04,858:INFO:Checking environment
2023-06-26 05:06:04,858:INFO:python_version: 3.10.4
2023-06-26 05:06:04,858:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2023-06-26 05:06:04,858:INFO:machine: AMD64
2023-06-26 05:06:04,883:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-26 05:06:04,889:INFO:Memory: svmem(total=7969243136, available=2377273344, percent=70.2, used=5591969792, free=2377273344)
2023-06-26 05:06:04,891:INFO:Physical Core: 6
2023-06-26 05:06:04,891:INFO:Logical Core: 6
2023-06-26 05:06:04,891:INFO:Checking libraries
2023-06-26 05:06:04,891:INFO:System:
2023-06-26 05:06:04,891:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2023-06-26 05:06:04,891:INFO:executable: C:\New folder\python.exe
2023-06-26 05:06:04,891:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-26 05:06:04,891:INFO:PyCaret required dependencies:
2023-06-26 05:06:04,891:INFO:                 pip: 23.1.2
2023-06-26 05:06:04,892:INFO:          setuptools: 58.1.0
2023-06-26 05:06:04,892:INFO:             pycaret: 3.0.2
2023-06-26 05:06:04,892:INFO:             IPython: 8.7.0
2023-06-26 05:06:04,892:INFO:          ipywidgets: 8.0.3
2023-06-26 05:06:04,892:INFO:                tqdm: 4.65.0
2023-06-26 05:06:04,892:INFO:               numpy: 1.23.5
2023-06-26 05:06:04,892:INFO:              pandas: 1.5.3
2023-06-26 05:06:04,892:INFO:              jinja2: 3.1.0
2023-06-26 05:06:04,892:INFO:               scipy: 1.9.1
2023-06-26 05:06:04,892:INFO:              joblib: 1.2.0
2023-06-26 05:06:04,892:INFO:             sklearn: 1.1.2
2023-06-26 05:06:04,892:INFO:                pyod: 1.1.0
2023-06-26 05:06:04,892:INFO:            imblearn: 0.10.1
2023-06-26 05:06:04,892:INFO:   category_encoders: 2.6.1
2023-06-26 05:06:04,892:INFO:            lightgbm: 3.3.5
2023-06-26 05:06:04,893:INFO:               numba: 0.57.1
2023-06-26 05:06:04,893:INFO:            requests: 2.28.1
2023-06-26 05:06:04,893:INFO:          matplotlib: 3.7.1
2023-06-26 05:06:04,893:INFO:          scikitplot: 0.3.7
2023-06-26 05:06:04,900:INFO:         yellowbrick: 1.5
2023-06-26 05:06:04,901:INFO:              plotly: 5.15.0
2023-06-26 05:06:04,902:INFO:             kaleido: 0.2.1
2023-06-26 05:06:04,902:INFO:         statsmodels: 0.14.0
2023-06-26 05:06:04,902:INFO:              sktime: 0.17.0
2023-06-26 05:06:04,902:INFO:               tbats: 1.1.3
2023-06-26 05:06:04,902:INFO:            pmdarima: 2.0.3
2023-06-26 05:06:04,902:INFO:              psutil: 5.9.4
2023-06-26 05:06:04,902:INFO:PyCaret optional dependencies:
2023-06-26 05:06:05,069:INFO:                shap: Not installed
2023-06-26 05:06:05,070:INFO:           interpret: Not installed
2023-06-26 05:06:05,070:INFO:                umap: Not installed
2023-06-26 05:06:05,070:INFO:    pandas_profiling: 4.3.1
2023-06-26 05:06:05,070:INFO:  explainerdashboard: Not installed
2023-06-26 05:06:05,070:INFO:             autoviz: Not installed
2023-06-26 05:06:05,071:INFO:           fairlearn: Not installed
2023-06-26 05:06:05,071:INFO:             xgboost: 1.7.5
2023-06-26 05:06:05,071:INFO:            catboost: Not installed
2023-06-26 05:06:05,071:INFO:              kmodes: Not installed
2023-06-26 05:06:05,071:INFO:             mlxtend: Not installed
2023-06-26 05:06:05,071:INFO:       statsforecast: Not installed
2023-06-26 05:06:05,071:INFO:        tune_sklearn: Not installed
2023-06-26 05:06:05,074:INFO:                 ray: Not installed
2023-06-26 05:06:05,074:INFO:            hyperopt: Not installed
2023-06-26 05:06:05,076:INFO:              optuna: Not installed
2023-06-26 05:06:05,079:INFO:               skopt: Not installed
2023-06-26 05:06:05,080:INFO:              mlflow: Not installed
2023-06-26 05:06:05,080:INFO:              gradio: Not installed
2023-06-26 05:06:05,080:INFO:             fastapi: Not installed
2023-06-26 05:06:05,080:INFO:             uvicorn: Not installed
2023-06-26 05:06:05,080:INFO:              m2cgen: Not installed
2023-06-26 05:06:05,081:INFO:           evidently: Not installed
2023-06-26 05:06:05,081:INFO:               fugue: Not installed
2023-06-26 05:06:05,081:INFO:           streamlit: 1.23.1
2023-06-26 05:06:05,081:INFO:             prophet: Not installed
2023-06-26 05:06:05,081:INFO:None
2023-06-26 05:06:05,081:INFO:Set up data.
2023-06-26 05:06:05,208:INFO:Set up train/test split.
2023-06-26 05:06:05,281:INFO:Set up index.
2023-06-26 05:06:05,282:INFO:Set up folding strategy.
2023-06-26 05:06:05,282:INFO:Assigning column types.
2023-06-26 05:06:05,323:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-26 05:06:05,323:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-26 05:06:05,331:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-26 05:06:05,339:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:06:05,507:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:05,622:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:06:05,632:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:06,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:06,526:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-26 05:06:06,533:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-26 05:06:06,542:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:06:06,666:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:06,740:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:06:06,741:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:06,747:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:06,748:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-26 05:06:06,755:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-26 05:06:06,765:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:06:06,889:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:06,964:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:06:06,965:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:06,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:06,977:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-26 05:06:06,985:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:06:07,133:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:07,224:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:06:07,225:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:07,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:07,233:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-26 05:06:07,252:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:06:07,406:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:07,486:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:06:07,487:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:07,494:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:07,515:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:06:07,667:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:07,737:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:06:07,740:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:07,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:07,751:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-26 05:06:07,887:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:07,955:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:06:07,956:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:07,960:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:08,105:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:08,169:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:06:08,170:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:08,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:08,175:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-26 05:06:08,315:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:08,370:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:08,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:08,486:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:08,549:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:08,552:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:08,552:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-26 05:06:08,733:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:08,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:08,928:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:08,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:08,959:INFO:Preparing preprocessing pipeline...
2023-06-26 05:06:08,959:INFO:Set up simple imputation.
2023-06-26 05:06:08,978:INFO:Set up encoding of ordinal features.
2023-06-26 05:06:08,994:INFO:Set up encoding of categorical features.
2023-06-26 05:06:10,612:INFO:Finished creating preprocessing pipeline.
2023-06-26 05:06:10,687:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Naman\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtFullB...
                                                                    'Condition2',
                                                                    'BldgType',
                                                                    'HouseStyle',
                                                                    'RoofStyle',
                                                                    'RoofMatl',
                                                                    'Exterior1st',
                                                                    'Exterior2nd',
                                                                    'MasVnrType',
                                                                    'ExterQual',
                                                                    'ExterCond',
                                                                    'Foundation',
                                                                    'BsmtQual',
                                                                    'BsmtCond',
                                                                    'BsmtExposure',
                                                                    'BsmtFinType1',
                                                                    'BsmtFinType2',
                                                                    'Heating',
                                                                    'HeatingQC',
                                                                    'Electrical',
                                                                    'KitchenQual',
                                                                    'Functional',
                                                                    'FireplaceQu',
                                                                    'GarageType', ...],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-06-26 05:06:10,688:INFO:Creating final display dataframe.
2023-06-26 05:06:14,251:INFO:Setup _display_container:                     Description             Value
0                    Session id              4661
1                        Target                Id
2                   Target type        Regression
3           Original data shape        (1460, 81)
4        Transformed data shape       (1460, 275)
5   Transformed train set shape       (1021, 275)
6    Transformed test set shape        (439, 275)
7              Ordinal features                 4
8              Numeric features                37
9          Categorical features                43
10     Rows with missing values            100.0%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              264a
2023-06-26 05:06:14,435:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:14,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:14,595:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:14,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:14,599:INFO:setup() successfully completed in 9.79s...............
2023-06-26 05:06:14,599:INFO:Initializing compare_models()
2023-06-26 05:06:14,599:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-26 05:06:14,599:INFO:Checking exceptions
2023-06-26 05:06:14,612:INFO:Preparing display monitor
2023-06-26 05:06:14,622:INFO:Initializing Linear Regression
2023-06-26 05:06:14,622:INFO:Total runtime is 0.0 minutes
2023-06-26 05:06:14,622:INFO:SubProcess create_model() called ==================================
2023-06-26 05:06:14,623:INFO:Initializing create_model()
2023-06-26 05:06:14,623:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9C4C8E290>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:06:14,623:INFO:Checking exceptions
2023-06-26 05:06:14,623:INFO:Importing libraries
2023-06-26 05:06:14,623:INFO:Copying training dataset
2023-06-26 05:06:14,687:INFO:Defining folds
2023-06-26 05:06:14,687:INFO:Declaring metric variables
2023-06-26 05:06:14,687:INFO:Importing untrained model
2023-06-26 05:06:14,691:INFO:Linear Regression Imported successfully
2023-06-26 05:06:14,696:INFO:Starting cross validation
2023-06-26 05:06:14,764:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:06:21,327:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:06:23,213:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:06:23,422:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:06:23,694:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 2.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:06:23,875:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:06:24,905:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:06:25,074:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:06:25,085:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:06:25,094:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:06:25,183:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:06:25,203:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:06:25,806:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:06:26,229:WARNING:C:\New folder\lib\site-packages\pandas_profiling\model\correlations.py:67: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/pandas-profiling/issues
(include the error message: 'No data; `observed` has size 0.')
  warnings.warn(

2023-06-26 05:06:26,988:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:06:27,903:INFO:PyCaret RegressionExperiment
2023-06-26 05:06:27,904:INFO:Logging name: reg-default-name
2023-06-26 05:06:27,907:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-26 05:06:27,908:INFO:version 3.0.2
2023-06-26 05:06:27,909:INFO:Initializing setup()
2023-06-26 05:06:27,909:INFO:self.USI: 6bf9
2023-06-26 05:06:27,910:INFO:self._variable_keys: {'log_plots_param', 'target_param', 'pipeline', 'y_train', 'memory', 'USI', 'exp_id', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'X_test', 'transform_target_param', 'data', 'logging_param', '_ml_usecase', 'idx', 'n_jobs_param', 'y', 'X', '_available_plots', 'gpu_param', 'X_train', 'exp_name_log', 'seed', 'html_param', 'fold_shuffle_param'}
2023-06-26 05:06:27,910:INFO:Checking environment
2023-06-26 05:06:27,911:INFO:python_version: 3.10.4
2023-06-26 05:06:27,912:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2023-06-26 05:06:27,913:INFO:machine: AMD64
2023-06-26 05:06:27,914:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-26 05:06:27,919:INFO:Memory: svmem(total=7969243136, available=1588215808, percent=80.1, used=6381027328, free=1588215808)
2023-06-26 05:06:27,919:INFO:Physical Core: 6
2023-06-26 05:06:27,920:INFO:Logical Core: 6
2023-06-26 05:06:27,920:INFO:Checking libraries
2023-06-26 05:06:27,923:INFO:System:
2023-06-26 05:06:27,924:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2023-06-26 05:06:27,924:INFO:executable: C:\New folder\python.exe
2023-06-26 05:06:27,924:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-26 05:06:27,924:INFO:PyCaret required dependencies:
2023-06-26 05:06:27,924:INFO:                 pip: 23.1.2
2023-06-26 05:06:27,924:INFO:          setuptools: 58.1.0
2023-06-26 05:06:27,924:INFO:             pycaret: 3.0.2
2023-06-26 05:06:27,924:INFO:             IPython: 8.7.0
2023-06-26 05:06:27,924:INFO:          ipywidgets: 8.0.3
2023-06-26 05:06:27,924:INFO:                tqdm: 4.65.0
2023-06-26 05:06:27,926:INFO:               numpy: 1.23.5
2023-06-26 05:06:27,926:INFO:              pandas: 1.5.3
2023-06-26 05:06:27,926:INFO:              jinja2: 3.1.0
2023-06-26 05:06:27,926:INFO:               scipy: 1.9.1
2023-06-26 05:06:27,926:INFO:              joblib: 1.2.0
2023-06-26 05:06:27,926:INFO:             sklearn: 1.1.2
2023-06-26 05:06:27,926:INFO:                pyod: 1.1.0
2023-06-26 05:06:27,926:INFO:            imblearn: 0.10.1
2023-06-26 05:06:27,927:INFO:   category_encoders: 2.6.1
2023-06-26 05:06:27,927:INFO:            lightgbm: 3.3.5
2023-06-26 05:06:27,927:INFO:               numba: 0.57.1
2023-06-26 05:06:27,927:INFO:            requests: 2.28.1
2023-06-26 05:06:27,927:INFO:          matplotlib: 3.7.1
2023-06-26 05:06:27,927:INFO:          scikitplot: 0.3.7
2023-06-26 05:06:27,927:INFO:         yellowbrick: 1.5
2023-06-26 05:06:27,927:INFO:              plotly: 5.15.0
2023-06-26 05:06:27,928:INFO:             kaleido: 0.2.1
2023-06-26 05:06:27,928:INFO:         statsmodels: 0.14.0
2023-06-26 05:06:27,928:INFO:              sktime: 0.17.0
2023-06-26 05:06:27,928:INFO:               tbats: 1.1.3
2023-06-26 05:06:27,928:INFO:            pmdarima: 2.0.3
2023-06-26 05:06:27,928:INFO:              psutil: 5.9.4
2023-06-26 05:06:27,928:INFO:PyCaret optional dependencies:
2023-06-26 05:06:27,929:INFO:                shap: Not installed
2023-06-26 05:06:27,929:INFO:           interpret: Not installed
2023-06-26 05:06:27,929:INFO:                umap: Not installed
2023-06-26 05:06:27,929:INFO:    pandas_profiling: 4.3.1
2023-06-26 05:06:27,930:INFO:  explainerdashboard: Not installed
2023-06-26 05:06:27,930:INFO:             autoviz: Not installed
2023-06-26 05:06:27,930:INFO:           fairlearn: Not installed
2023-06-26 05:06:27,930:INFO:             xgboost: 1.7.5
2023-06-26 05:06:27,930:INFO:            catboost: Not installed
2023-06-26 05:06:27,930:INFO:              kmodes: Not installed
2023-06-26 05:06:27,930:INFO:             mlxtend: Not installed
2023-06-26 05:06:27,930:INFO:       statsforecast: Not installed
2023-06-26 05:06:27,930:INFO:        tune_sklearn: Not installed
2023-06-26 05:06:27,930:INFO:                 ray: Not installed
2023-06-26 05:06:27,931:INFO:            hyperopt: Not installed
2023-06-26 05:06:27,931:INFO:              optuna: Not installed
2023-06-26 05:06:27,932:INFO:               skopt: Not installed
2023-06-26 05:06:27,933:INFO:              mlflow: Not installed
2023-06-26 05:06:27,935:INFO:              gradio: Not installed
2023-06-26 05:06:27,935:INFO:             fastapi: Not installed
2023-06-26 05:06:27,935:INFO:             uvicorn: Not installed
2023-06-26 05:06:27,935:INFO:              m2cgen: Not installed
2023-06-26 05:06:27,935:INFO:           evidently: Not installed
2023-06-26 05:06:27,935:INFO:               fugue: Not installed
2023-06-26 05:06:27,935:INFO:           streamlit: 1.23.1
2023-06-26 05:06:27,935:INFO:             prophet: Not installed
2023-06-26 05:06:27,935:INFO:None
2023-06-26 05:06:27,935:INFO:Set up data.
2023-06-26 05:06:27,980:INFO:Set up train/test split.
2023-06-26 05:06:28,006:INFO:Set up index.
2023-06-26 05:06:28,007:INFO:Set up folding strategy.
2023-06-26 05:06:28,007:INFO:Assigning column types.
2023-06-26 05:06:28,023:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-26 05:06:28,024:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,029:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,034:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,119:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,181:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,196:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:28,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:28,200:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,205:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,210:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,303:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,359:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,359:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:28,362:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:28,363:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-26 05:06:28,369:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,375:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,455:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,507:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,509:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:28,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:28,515:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,521:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,605:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,651:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:06:28,652:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:28,654:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:28,655:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-26 05:06:28,665:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:06:29,047:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:29,635:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:06:29,640:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:29,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:29,786:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:06:30,779:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:31,296:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:06:31,299:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:31,340:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:31,343:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-26 05:06:32,446:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:33,031:WARNING:Summarize dataset:   0%|                                             | 0/5 [00:00<?, ?it/s]
2023-06-26 05:06:33,085:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:06:33,088:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:33,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:33,704:WARNING:Summarize dataset:   0%|                | 0/86 [00:00<?, ?it/s, Describe variable:MSZoning]
2023-06-26 05:06:33,744:WARNING:Summarize dataset:   1%|        | 1/86 [00:00<01:00,  1.41it/s, Describe variable:MSZoning]
2023-06-26 05:06:33,770:WARNING:Summarize dataset:   1%|1         | 1/86 [00:00<01:00,  1.41it/s, Describe variable:Street]
2023-06-26 05:06:33,797:WARNING:Summarize dataset:   2%|2          | 2/86 [00:00<00:59,  1.41it/s, Describe variable:Alley]
2023-06-26 05:06:33,807:WARNING:Summarize dataset:   3%|1    | 3/86 [00:00<00:58,  1.41it/s, Describe variable:LandContour]
2023-06-26 05:06:33,809:WARNING:Summarize dataset:   5%|3       | 4/86 [00:00<00:58,  1.41it/s, Describe variable:LotShape]
2023-06-26 05:06:33,829:WARNING:Summarize dataset:   6%|4      | 5/86 [00:00<00:57,  1.41it/s, Describe variable:Utilities]
2023-06-26 05:06:33,833:WARNING:Summarize dataset:   7%|4      | 6/86 [00:00<00:56,  1.41it/s, Describe variable:LotConfig]
2023-06-26 05:06:33,930:WARNING:Summarize dataset:   8%|5      | 7/86 [00:00<00:56,  1.41it/s, Describe variable:LandSlope]
2023-06-26 05:06:33,939:WARNING:Summarize dataset:   9%|6      | 8/86 [00:00<00:07, 11.11it/s, Describe variable:LandSlope]
2023-06-26 05:06:33,956:WARNING:Summarize dataset:   9%|5     | 8/86 [00:00<00:07, 11.11it/s, Describe variable:Condition1]
2023-06-26 05:06:34,014:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:34,015:WARNING:Summarize dataset:  10%|6     | 9/86 [00:00<00:06, 11.11it/s, Describe variable:Condition2]
2023-06-26 05:06:34,075:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:06:34,095:WARNING:Summarize dataset:  12%|3  | 10/86 [00:01<00:06, 11.11it/s, Describe variable:Neighborhood]
2023-06-26 05:06:34,111:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:34,112:WARNING:Summarize dataset:  13%|3  | 11/86 [00:01<00:05, 12.75it/s, Describe variable:Neighborhood]
2023-06-26 05:06:34,118:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:34,120:WARNING:Summarize dataset:  13%|8      | 11/86 [00:01<00:05, 12.75it/s, Describe variable:BldgType]
2023-06-26 05:06:34,158:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-26 05:06:34,173:WARNING:Summarize dataset:  14%|6    | 12/86 [00:01<00:05, 12.75it/s, Describe variable:HouseStyle]
2023-06-26 05:06:34,249:WARNING:Summarize dataset:  15%|7    | 13/86 [00:01<00:05, 13.78it/s, Describe variable:HouseStyle]
2023-06-26 05:06:34,293:WARNING:Summarize dataset:  15%|6   | 13/86 [00:01<00:05, 13.78it/s, Describe variable:LotFrontage]
2023-06-26 05:06:34,294:WARNING:Summarize dataset:  16%|6   | 14/86 [00:01<00:05, 13.78it/s, Describe variable:OverallCond]
2023-06-26 05:06:34,307:WARNING:Summarize dataset:  17%|8    | 15/86 [00:01<00:05, 13.78it/s, Describe variable:MSSubClass]
2023-06-26 05:06:34,313:WARNING:Summarize dataset:  19%|#1    | 16/86 [00:01<00:05, 13.78it/s, Describe variable:RoofStyle]
2023-06-26 05:06:34,325:WARNING:Summarize dataset:  20%|#1    | 17/86 [00:01<00:03, 18.95it/s, Describe variable:RoofStyle]
2023-06-26 05:06:34,336:WARNING:Summarize dataset:  20%|#3     | 17/86 [00:01<00:03, 18.95it/s, Describe variable:RoofMatl]
2023-06-26 05:06:34,356:WARNING:Summarize dataset:  21%|8   | 18/86 [00:01<00:03, 18.95it/s, Describe variable:Exterior1st]
2023-06-26 05:06:34,360:WARNING:Summarize dataset:  22%|#7      | 19/86 [00:01<00:03, 18.95it/s, Describe variable:LotArea]
2023-06-26 05:06:34,369:WARNING:Summarize dataset:  23%|9   | 20/86 [00:01<00:03, 18.95it/s, Describe variable:Exterior2nd]
2023-06-26 05:06:34,372:WARNING:Summarize dataset:  24%|9   | 21/86 [00:01<00:03, 18.95it/s, Describe variable:OverallQual]
2023-06-26 05:06:34,380:WARNING:Summarize dataset:  26%|#5    | 22/86 [00:01<00:03, 18.95it/s, Describe variable:ExterQual]
2023-06-26 05:06:34,412:WARNING:Summarize dataset:  27%|###4         | 23/86 [00:01<00:03, 18.95it/s, Describe variable:Id]
2023-06-26 05:06:34,412:WARNING:Summarize dataset:  28%|#3   | 24/86 [00:01<00:03, 18.95it/s, Describe variable:Foundation]
2023-06-26 05:06:34,414:WARNING:Summarize dataset:  29%|#7    | 25/86 [00:01<00:03, 18.95it/s, Describe variable:ExterCond]
2023-06-26 05:06:34,420:WARNING:Summarize dataset:  30%|9  | 26/86 [00:01<00:03, 18.95it/s, Describe variable:YearRemodAdd]
2023-06-26 05:06:34,420:WARNING:Summarize dataset:  31%|#8    | 27/86 [00:01<00:03, 18.95it/s, Describe variable:YearBuilt]
2023-06-26 05:06:34,420:WARNING:Summarize dataset:  33%|#6   | 28/86 [00:01<00:03, 18.95it/s, Describe variable:MasVnrType]
2023-06-26 05:06:34,420:WARNING:Summarize dataset:  34%|##3    | 29/86 [00:01<00:03, 18.95it/s, Describe variable:BsmtQual]
2023-06-26 05:06:34,421:WARNING:Summarize dataset:  35%|#  | 30/86 [00:01<00:02, 18.95it/s, Describe variable:BsmtFinType1]
2023-06-26 05:06:34,453:WARNING:Summarize dataset:  36%|#  | 31/86 [00:01<00:01, 43.14it/s, Describe variable:BsmtFinType1]
2023-06-26 05:06:34,458:WARNING:Summarize dataset:  36%|##5    | 31/86 [00:01<00:01, 43.14it/s, Describe variable:BsmtCond]
2023-06-26 05:06:34,458:WARNING:Summarize dataset:  37%|#1 | 32/86 [00:01<00:01, 43.14it/s, Describe variable:BsmtExposure]
2023-06-26 05:06:34,466:WARNING:Summarize dataset:  38%|#1 | 33/86 [00:01<00:01, 43.14it/s, Describe variable:BsmtFinType2]
2023-06-26 05:06:34,467:WARNING:Summarize dataset:  40%|###1    | 34/86 [00:01<00:01, 43.14it/s, Describe variable:Heating]
2023-06-26 05:06:34,467:WARNING:Summarize dataset:  41%|##4   | 35/86 [00:01<00:01, 43.14it/s, Describe variable:HeatingQC]
2023-06-26 05:06:34,468:WARNING:Summarize dataset:  42%|##   | 36/86 [00:01<00:01, 43.14it/s, Describe variable:CentralAir]
2023-06-26 05:06:34,472:WARNING:Summarize dataset:  43%|##1  | 37/86 [00:01<00:01, 43.14it/s, Describe variable:MasVnrArea]
2023-06-26 05:06:34,486:WARNING:Summarize dataset:  44%|##2  | 38/86 [00:01<00:01, 43.14it/s, Describe variable:BsmtFinSF2]
2023-06-26 05:06:34,513:WARNING:Summarize dataset:  45%|##2  | 39/86 [00:01<00:01, 43.14it/s, Describe variable:Electrical]
2023-06-26 05:06:34,526:WARNING:Summarize dataset:  47%|###2   | 40/86 [00:01<00:01, 43.14it/s, Describe variable:2ndFlrSF]
2023-06-26 05:06:34,554:WARNING:Summarize dataset:  48%|##3  | 41/86 [00:01<00:01, 43.14it/s, Describe variable:BsmtFinSF1]
2023-06-26 05:06:34,554:WARNING:Summarize dataset:  49%|##4  | 42/86 [00:01<00:00, 58.19it/s, Describe variable:BsmtFinSF1]
2023-06-26 05:06:34,569:WARNING:Summarize dataset:  49%|#4 | 42/86 [00:01<00:00, 58.19it/s, Describe variable:BsmtFullBath]
2023-06-26 05:06:34,622:WARNING:Summarize dataset:  50%|###   | 43/86 [00:01<00:00, 58.19it/s, Describe variable:BsmtUnfSF]
2023-06-26 05:06:34,639:WARNING:Summarize dataset:  51%|#5 | 44/86 [00:01<00:00, 58.19it/s, Describe variable:LowQualFinSF]
2023-06-26 05:06:34,693:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:34,708:WARNING:Summarize dataset:  52%|#5 | 45/86 [00:01<00:00, 58.19it/s, Describe variable:BsmtHalfBath]
2023-06-26 05:06:34,746:WARNING:Summarize dataset:  53%|##1 | 46/86 [00:01<00:00, 58.19it/s, Describe variable:TotalBsmtSF]
2023-06-26 05:06:34,747:WARNING:Summarize dataset:  55%|###8   | 47/86 [00:01<00:00, 58.19it/s, Describe variable:1stFlrSF]
2023-06-26 05:06:34,747:WARNING:Summarize dataset:  56%|###9   | 48/86 [00:01<00:00, 58.19it/s, Describe variable:FullBath]
2023-06-26 05:06:34,747:WARNING:Summarize dataset:  57%|##2 | 49/86 [00:01<00:00, 58.19it/s, Describe variable:KitchenQual]
2023-06-26 05:06:34,747:WARNING:Summarize dataset:  58%|##3 | 50/86 [00:01<00:00, 51.74it/s, Describe variable:KitchenQual]
2023-06-26 05:06:34,747:WARNING:Summarize dataset:  58%|##9  | 50/86 [00:01<00:00, 51.74it/s, Describe variable:Functional]
2023-06-26 05:06:34,747:WARNING:Summarize dataset:  59%|####1  | 51/86 [00:01<00:00, 51.74it/s, Describe variable:HalfBath]
2023-06-26 05:06:34,776:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:34,799:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:34,823:WARNING:Summarize dataset:  60%|###  | 52/86 [00:01<00:00, 51.74it/s, Describe variable:Fireplaces]
2023-06-26 05:06:34,853:WARNING:Summarize dataset:  62%|##4 | 53/86 [00:01<00:00, 51.74it/s, Describe variable:FireplaceQu]
2023-06-26 05:06:34,854:WARNING:Summarize dataset:  63%|#8 | 54/86 [00:01<00:00, 51.74it/s, Describe variable:KitchenAbvGr]
2023-06-26 05:06:34,870:WARNING:Summarize dataset:  64%|###1 | 55/86 [00:01<00:00, 51.74it/s, Describe variable:GarageType]
2023-06-26 05:06:34,906:WARNING:Summarize dataset:  65%|###2 | 56/86 [00:01<00:00, 51.74it/s, Describe variable:GarageCars]
2023-06-26 05:06:34,909:WARNING:Summarize dataset:  66%|###3 | 57/86 [00:01<00:00, 49.03it/s, Describe variable:GarageCars]
2023-06-26 05:06:34,927:WARNING:Summarize dataset:  66%|#9 | 57/86 [00:01<00:00, 49.03it/s, Describe variable:TotRmsAbvGrd]
2023-06-26 05:06:34,932:WARNING:Summarize dataset:  67%|## | 58/86 [00:01<00:00, 49.03it/s, Describe variable:BedroomAbvGr]
2023-06-26 05:06:34,937:WARNING:Summarize dataset:  69%|####1 | 59/86 [00:01<00:00, 49.03it/s, Describe variable:GrLivArea]
2023-06-26 05:06:34,939:WARNING:Summarize dataset:  70%|###4 | 60/86 [00:01<00:00, 49.03it/s, Describe variable:PavedDrive]
2023-06-26 05:06:34,959:WARNING:Summarize dataset:  71%|###5 | 61/86 [00:01<00:00, 49.03it/s, Describe variable:GarageQual]
2023-06-26 05:06:34,988:WARNING:Summarize dataset:  72%|###6 | 62/86 [00:01<00:00, 49.03it/s, Describe variable:GarageCond]
2023-06-26 05:06:34,995:WARNING:Summarize dataset:  73%|##1| 63/86 [00:01<00:00, 49.03it/s, Describe variable:GarageFinish]
2023-06-26 05:06:35,001:WARNING:Summarize dataset:  74%|##9 | 64/86 [00:01<00:00, 49.03it/s, Describe variable:GarageYrBlt]
2023-06-26 05:06:35,012:WARNING:Summarize dataset:  76%|###7 | 65/86 [00:01<00:00, 49.03it/s, Describe variable:GarageArea]
2023-06-26 05:06:35,013:WARNING:Summarize dataset:  77%|###8 | 66/86 [00:01<00:00, 57.46it/s, Describe variable:GarageArea]
2023-06-26 05:06:35,026:WARNING:Summarize dataset:  77%|####6 | 66/86 [00:01<00:00, 57.46it/s, Describe variable:3SsnPorch]
2023-06-26 05:06:35,028:WARNING:Summarize dataset:  78%|#5| 67/86 [00:01<00:00, 57.46it/s, Describe variable:EnclosedPorch]
2023-06-26 05:06:35,029:WARNING:Summarize dataset:  79%|###1| 68/86 [00:01<00:00, 57.46it/s, Describe variable:OpenPorchSF]
2023-06-26 05:06:35,044:WARNING:Summarize dataset:  80%|#######2 | 69/86 [00:02<00:00, 57.46it/s, Describe variable:PoolQC]
2023-06-26 05:06:35,070:WARNING:Summarize dataset:  81%|###2| 70/86 [00:02<00:00, 57.46it/s, Describe variable:MiscFeature]
2023-06-26 05:06:35,090:WARNING:Summarize dataset:  83%|#####7 | 71/86 [00:02<00:00, 57.46it/s, Describe variable:PoolArea]
2023-06-26 05:06:35,118:WARNING:Summarize dataset:  84%|###3| 72/86 [00:02<00:00, 57.46it/s, Describe variable:ScreenPorch]
2023-06-26 05:06:35,124:WARNING:Summarize dataset:  85%|###3| 73/86 [00:02<00:00, 58.88it/s, Describe variable:ScreenPorch]
2023-06-26 05:06:35,125:WARNING:Summarize dataset:  85%|#####9 | 73/86 [00:02<00:00, 58.88it/s, Describe variable:SaleType]
2023-06-26 05:06:35,184:WARNING:Summarize dataset:  86%|#######7 | 74/86 [00:02<00:00, 58.88it/s, Describe variable:YrSold]
2023-06-26 05:06:35,202:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:06:35,203:WARNING:Summarize dataset:  87%|####3| 75/86 [00:02<00:00, 58.88it/s, Describe variable:WoodDeckSF]
2023-06-26 05:06:35,254:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:35,267:WARNING:Summarize dataset:  88%|#7| 76/86 [00:02<00:00, 58.88it/s, Describe variable:SaleCondition]
2023-06-26 05:06:35,270:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:35,270:WARNING:Summarize dataset:  90%|########9 | 77/86 [00:02<00:00, 58.88it/s, Describe variable:Fence]
2023-06-26 05:06:35,272:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-26 05:06:35,272:WARNING:Summarize dataset:  91%|#######2| 78/86 [00:02<00:00, 58.88it/s, Describe variable:MiscVal]
2023-06-26 05:06:35,296:WARNING:Summarize dataset:  92%|########2| 79/86 [00:02<00:00, 58.88it/s, Describe variable:MoSold]
2023-06-26 05:06:35,297:WARNING:Summarize dataset:  93%|########3| 80/86 [00:02<00:00, 52.20it/s, Describe variable:MoSold]
2023-06-26 05:06:35,302:WARNING:Summarize dataset:  93%|#####5| 80/86 [00:02<00:00, 52.20it/s, Describe variable:SalePrice]
2023-06-26 05:06:35,305:WARNING:Summarize dataset:  94%|##############1| 81/86 [00:02<00:00, 52.20it/s, Get variable types]
2023-06-26 05:06:35,305:WARNING:Summarize dataset:  93%|######5| 82/88 [00:02<00:00, 52.20it/s, Calculate auto correlation]
2023-06-26 05:06:35,455:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:35,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:35,616:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:35,621:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:35,625:INFO:Preparing preprocessing pipeline...
2023-06-26 05:06:35,625:INFO:Set up simple imputation.
2023-06-26 05:06:35,645:INFO:Set up encoding of ordinal features.
2023-06-26 05:06:35,689:INFO:Set up encoding of categorical features.
2023-06-26 05:06:37,000:INFO:Calculating mean and std
2023-06-26 05:06:37,003:INFO:Creating metrics dataframe
2023-06-26 05:06:37,334:INFO:Finished creating preprocessing pipeline.
2023-06-26 05:06:37,414:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Naman\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtFullB...
                                                                    'Condition2',
                                                                    'BldgType',
                                                                    'HouseStyle',
                                                                    'RoofStyle',
                                                                    'RoofMatl',
                                                                    'Exterior1st',
                                                                    'Exterior2nd',
                                                                    'MasVnrType',
                                                                    'ExterQual',
                                                                    'ExterCond',
                                                                    'Foundation',
                                                                    'BsmtQual',
                                                                    'BsmtCond',
                                                                    'BsmtExposure',
                                                                    'BsmtFinType1',
                                                                    'BsmtFinType2',
                                                                    'Heating',
                                                                    'HeatingQC',
                                                                    'Electrical',
                                                                    'KitchenQual',
                                                                    'Functional',
                                                                    'FireplaceQu',
                                                                    'GarageType', ...],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-06-26 05:06:37,415:INFO:Creating final display dataframe.
2023-06-26 05:06:38,326:INFO:Uploading results into container
2023-06-26 05:06:38,327:INFO:Uploading model into container now
2023-06-26 05:06:38,328:INFO:_master_model_container: 1
2023-06-26 05:06:38,328:INFO:_display_container: 2
2023-06-26 05:06:38,328:INFO:LinearRegression(n_jobs=-1)
2023-06-26 05:06:38,328:INFO:create_model() successfully completed......................................
2023-06-26 05:06:38,557:INFO:SubProcess create_model() end ==================================
2023-06-26 05:06:38,557:INFO:Creating metrics dataframe
2023-06-26 05:06:38,560:INFO:Initializing Lasso Regression
2023-06-26 05:06:38,560:INFO:Total runtime is 0.3989744226137797 minutes
2023-06-26 05:06:38,560:INFO:SubProcess create_model() called ==================================
2023-06-26 05:06:38,560:INFO:Initializing create_model()
2023-06-26 05:06:38,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9C4C8E290>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:06:38,560:INFO:Checking exceptions
2023-06-26 05:06:38,560:INFO:Importing libraries
2023-06-26 05:06:38,560:INFO:Copying training dataset
2023-06-26 05:06:38,599:INFO:Defining folds
2023-06-26 05:06:38,600:INFO:Declaring metric variables
2023-06-26 05:06:38,600:INFO:Importing untrained model
2023-06-26 05:06:38,600:INFO:Lasso Regression Imported successfully
2023-06-26 05:06:38,600:INFO:Starting cross validation
2023-06-26 05:06:38,644:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:06:40,017:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.708e+04, tolerance: 1.593e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:06:40,649:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:271: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_full_transform(

2023-06-26 05:06:42,890:INFO:Setup _display_container:                     Description             Value
0                    Session id              5040
1                        Target                Id
2                   Target type        Regression
3           Original data shape        (1460, 81)
4        Transformed data shape       (1460, 276)
5   Transformed train set shape       (1021, 276)
6    Transformed test set shape        (439, 276)
7              Ordinal features                 4
8              Numeric features                37
9          Categorical features                43
10     Rows with missing values            100.0%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              6bf9
2023-06-26 05:06:42,891:INFO:                    Description             Value
2023-06-26 05:06:42,893:INFO:0                    Session id              5040
2023-06-26 05:06:42,893:INFO:1                        Target                Id
2023-06-26 05:06:42,893:INFO:2                   Target type        Regression
2023-06-26 05:06:42,893:INFO:3           Original data shape        (1460, 81)
2023-06-26 05:06:42,893:INFO:4        Transformed data shape       (1460, 276)
2023-06-26 05:06:42,894:INFO:5   Transformed train set shape       (1021, 276)
2023-06-26 05:06:42,894:INFO:6    Transformed test set shape        (439, 276)
2023-06-26 05:06:42,894:INFO:7              Ordinal features                 4
2023-06-26 05:06:42,894:INFO:8              Numeric features                37
2023-06-26 05:06:42,894:INFO:9          Categorical features                43
2023-06-26 05:06:42,894:INFO:10     Rows with missing values            100.0%
2023-06-26 05:06:42,894:INFO:11                   Preprocess              True
2023-06-26 05:06:42,894:INFO:12              Imputation type            simple
2023-06-26 05:06:42,894:INFO:13           Numeric imputation              mean
2023-06-26 05:06:42,894:INFO:14       Categorical imputation              mode
2023-06-26 05:06:42,894:INFO:15     Maximum one-hot encoding                25
2023-06-26 05:06:42,894:INFO:16              Encoding method              None
2023-06-26 05:06:42,895:INFO:17               Fold Generator             KFold
2023-06-26 05:06:42,895:INFO:18                  Fold Number                10
2023-06-26 05:06:42,895:INFO:19                     CPU Jobs                -1
2023-06-26 05:06:42,895:INFO:20                      Use GPU             False
2023-06-26 05:06:42,895:INFO:21               Log Experiment             False
2023-06-26 05:06:42,895:INFO:22              Experiment Name  reg-default-name
2023-06-26 05:06:42,895:INFO:23                          USI              6bf9
2023-06-26 05:06:43,046:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:43,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:43,192:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:06:43,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:06:43,195:INFO:setup() successfully completed in 15.5s...............
2023-06-26 05:06:43,196:INFO:Initializing compare_models()
2023-06-26 05:06:43,197:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BAAF63E0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002B9BAAF63E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-26 05:06:43,197:INFO:Checking exceptions
2023-06-26 05:06:43,209:INFO:Preparing display monitor
2023-06-26 05:06:43,211:WARNING:
2023-06-26 05:06:43,211:WARNING:
2023-06-26 05:06:43,211:WARNING:Processing:   0%|                                                   | 0/81 [00:00<?, ?it/s]
2023-06-26 05:06:43,213:WARNING:[A[A
2023-06-26 05:06:43,214:INFO:Initializing Linear Regression
2023-06-26 05:06:43,214:INFO:Total runtime is 0.0 minutes
2023-06-26 05:06:43,214:INFO:SubProcess create_model() called ==================================
2023-06-26 05:06:43,214:INFO:Initializing create_model()
2023-06-26 05:06:43,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BAAF63E0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BD66AE00>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:06:43,214:INFO:Checking exceptions
2023-06-26 05:06:43,214:INFO:Importing libraries
2023-06-26 05:06:43,214:INFO:Copying training dataset
2023-06-26 05:06:43,271:INFO:Defining folds
2023-06-26 05:06:43,271:INFO:Declaring metric variables
2023-06-26 05:06:43,271:INFO:Importing untrained model
2023-06-26 05:06:43,271:INFO:Linear Regression Imported successfully
2023-06-26 05:06:43,272:INFO:Starting cross validation
2023-06-26 05:06:43,290:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:06:50,900:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:06:51,503:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:06:51,767:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:06:51,779:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:06:53,493:INFO:Calculating mean and std
2023-06-26 05:06:53,495:INFO:Creating metrics dataframe
2023-06-26 05:06:53,965:WARNING:Summarize dataset:  93%|######5| 82/88 [00:20<00:00, 52.20it/s, Calculate auto correlation]
2023-06-26 05:06:54,917:INFO:Uploading results into container
2023-06-26 05:06:54,921:INFO:Uploading model into container now
2023-06-26 05:06:54,921:INFO:_master_model_container: 2
2023-06-26 05:06:54,921:INFO:_display_container: 2
2023-06-26 05:06:54,922:INFO:Lasso(random_state=4661)
2023-06-26 05:06:54,922:INFO:create_model() successfully completed......................................
2023-06-26 05:06:55,182:INFO:SubProcess create_model() end ==================================
2023-06-26 05:06:55,183:INFO:Creating metrics dataframe
2023-06-26 05:06:55,187:INFO:Initializing Ridge Regression
2023-06-26 05:06:55,188:INFO:Total runtime is 0.6761042634646097 minutes
2023-06-26 05:06:55,188:INFO:SubProcess create_model() called ==================================
2023-06-26 05:06:55,189:INFO:Initializing create_model()
2023-06-26 05:06:55,189:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9C4C8E290>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:06:55,196:INFO:Checking exceptions
2023-06-26 05:06:55,196:INFO:Importing libraries
2023-06-26 05:06:55,196:INFO:Copying training dataset
2023-06-26 05:06:55,301:INFO:Defining folds
2023-06-26 05:06:55,301:INFO:Declaring metric variables
2023-06-26 05:06:55,301:INFO:Importing untrained model
2023-06-26 05:06:55,302:INFO:Ridge Regression Imported successfully
2023-06-26 05:06:55,303:INFO:Starting cross validation
2023-06-26 05:06:55,371:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:06:58,323:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:06:58,576:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:07:00,294:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:07:01,327:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:07:01,761:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:07:02,004:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:07:10,682:WARNING:C:\New folder\lib\site-packages\pandas_profiling\model\correlations.py:67: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/pandas-profiling/issues
(include the error message: 'No data; `observed` has size 0.')
  warnings.warn(

2023-06-26 05:07:10,683:WARNING:Summarize dataset:  94%|######6| 83/88 [00:37<00:08,  1.75s/it, Calculate auto correlation]
2023-06-26 05:07:10,683:WARNING:Summarize dataset:  94%|##############1| 83/88 [00:37<00:08,  1.75s/it, Get scatter matrix]
2023-06-26 05:07:10,683:WARNING:Summarize dataset:   8%|#5                | 83/988 [00:37<26:21,  1.75s/it, scatter Id, Id]
2023-06-26 05:07:10,966:WARNING:Summarize dataset:   9%|#5                | 84/988 [00:37<24:53,  1.65s/it, scatter Id, Id]
2023-06-26 05:07:10,973:WARNING:Summarize dataset:   9%|8         | 84/988 [00:37<24:53,  1.65s/it, scatter MSSubClass, Id]
2023-06-26 05:07:11,368:WARNING:Summarize dataset:   9%|7        | 85/988 [00:38<24:51,  1.65s/it, scatter LotFrontage, Id]
2023-06-26 05:07:11,704:WARNING:Summarize dataset:   9%|#1           | 86/988 [00:38<24:50,  1.65s/it, scatter LotArea, Id]
2023-06-26 05:07:12,023:WARNING:Summarize dataset:   9%|7        | 87/988 [00:38<24:48,  1.65s/it, scatter OverallQual, Id]
2023-06-26 05:07:12,320:WARNING:Summarize dataset:   9%|8        | 88/988 [00:39<24:46,  1.65s/it, scatter OverallCond, Id]
2023-06-26 05:07:12,689:WARNING:Summarize dataset:   9%|8        | 89/988 [00:39<18:31,  1.24s/it, scatter OverallCond, Id]
2023-06-26 05:07:12,690:WARNING:Summarize dataset:   9%|9          | 89/988 [00:39<18:31,  1.24s/it, scatter YearBuilt, Id]
2023-06-26 05:07:13,145:WARNING:Summarize dataset:   9%|7       | 90/988 [00:40<18:29,  1.24s/it, scatter YearRemodAdd, Id]
2023-06-26 05:07:13,335:INFO:Calculating mean and std
2023-06-26 05:07:13,336:WARNING:
2023-06-26 05:07:13,336:WARNING:
2023-06-26 05:07:13,336:WARNING:Processing:   6%|##6                                        | 5/81 [00:30<07:37,  6.02s/it]
2023-06-26 05:07:13,336:WARNING:[A[A
2023-06-26 05:07:13,336:INFO:Creating metrics dataframe
2023-06-26 05:07:13,620:WARNING:Summarize dataset:   9%|9         | 91/988 [00:40<18:28,  1.24s/it, scatter MasVnrArea, Id]
2023-06-26 05:07:14,092:WARNING:Summarize dataset:   9%|9         | 92/988 [00:41<15:59,  1.07s/it, scatter MasVnrArea, Id]
2023-06-26 05:07:14,092:WARNING:Summarize dataset:   9%|9         | 92/988 [00:41<15:59,  1.07s/it, scatter BsmtFinSF1, Id]
2023-06-26 05:07:14,492:WARNING:
2023-06-26 05:07:14,493:WARNING:
2023-06-26 05:07:14,493:WARNING:Processing:   7%|###1                                       | 6/81 [00:31<06:10,  4.94s/it]
2023-06-26 05:07:14,493:WARNING:[A[A
2023-06-26 05:07:14,494:INFO:Uploading results into container
2023-06-26 05:07:14,495:INFO:Uploading model into container now
2023-06-26 05:07:14,495:INFO:_master_model_container: 1
2023-06-26 05:07:14,495:INFO:_display_container: 2
2023-06-26 05:07:14,496:INFO:LinearRegression(n_jobs=-1)
2023-06-26 05:07:14,496:INFO:create_model() successfully completed......................................
2023-06-26 05:07:14,764:INFO:SubProcess create_model() end ==================================
2023-06-26 05:07:14,764:INFO:Creating metrics dataframe
2023-06-26 05:07:14,768:INFO:Initializing Lasso Regression
2023-06-26 05:07:14,768:INFO:Total runtime is 0.5259100039800008 minutes
2023-06-26 05:07:14,768:INFO:SubProcess create_model() called ==================================
2023-06-26 05:07:14,769:INFO:Initializing create_model()
2023-06-26 05:07:14,769:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BAAF63E0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BD66AE00>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:07:14,769:INFO:Checking exceptions
2023-06-26 05:07:14,769:INFO:Importing libraries
2023-06-26 05:07:14,769:INFO:Copying training dataset
2023-06-26 05:07:14,799:WARNING:
2023-06-26 05:07:14,799:WARNING:
2023-06-26 05:07:14,799:WARNING:Processing:   9%|###7                                       | 7/81 [00:31<04:43,  3.83s/it]
2023-06-26 05:07:14,799:WARNING:[A[A
2023-06-26 05:07:14,799:INFO:Defining folds
2023-06-26 05:07:14,799:INFO:Declaring metric variables
2023-06-26 05:07:14,799:INFO:Importing untrained model
2023-06-26 05:07:14,800:INFO:Lasso Regression Imported successfully
2023-06-26 05:07:14,800:INFO:Starting cross validation
2023-06-26 05:07:14,824:WARNING:Summarize dataset:   9%|9         | 93/988 [00:41<15:58,  1.07s/it, scatter BsmtFinSF2, Id]
2023-06-26 05:07:14,847:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:07:15,153:WARNING:Summarize dataset:  10%|#          | 94/988 [00:42<15:57,  1.07s/it, scatter BsmtUnfSF, Id]
2023-06-26 05:07:15,346:WARNING:Summarize dataset:  10%|#          | 95/988 [00:42<13:39,  1.09it/s, scatter BsmtUnfSF, Id]
2023-06-26 05:07:15,346:WARNING:Summarize dataset:  10%|8        | 95/988 [00:42<13:39,  1.09it/s, scatter TotalBsmtSF, Id]
2023-06-26 05:07:15,646:WARNING:Summarize dataset:  10%|#1          | 96/988 [00:42<13:39,  1.09it/s, scatter 1stFlrSF, Id]
2023-06-26 05:07:16,041:WARNING:Summarize dataset:  10%|#1          | 97/988 [00:43<12:05,  1.23it/s, scatter 1stFlrSF, Id]
2023-06-26 05:07:16,042:WARNING:Summarize dataset:  10%|#1          | 97/988 [00:43<12:05,  1.23it/s, scatter 2ndFlrSF, Id]
2023-06-26 05:07:16,460:WARNING:Summarize dataset:  10%|7       | 98/988 [00:43<12:04,  1.23it/s, scatter LowQualFinSF, Id]
2023-06-26 05:07:16,553:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.909e+07, tolerance: 1.644e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:16,634:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.963e+07, tolerance: 1.675e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:16,859:WARNING:Summarize dataset:  10%|8       | 99/988 [00:43<10:49,  1.37it/s, scatter LowQualFinSF, Id]
2023-06-26 05:07:16,864:WARNING:Summarize dataset:  10%|#1         | 99/988 [00:43<10:49,  1.37it/s, scatter GrLivArea, Id]
2023-06-26 05:07:17,229:WARNING:Summarize dataset:  10%|#         | 100/988 [00:44<10:07,  1.46it/s, scatter GrLivArea, Id]
2023-06-26 05:07:17,230:WARNING:Summarize dataset:  10%|7      | 100/988 [00:44<10:07,  1.46it/s, scatter BedroomAbvGr, Id]
2023-06-26 05:07:17,614:WARNING:Summarize dataset:  10%|7      | 101/988 [00:44<09:25,  1.57it/s, scatter BedroomAbvGr, Id]
2023-06-26 05:07:17,615:WARNING:Summarize dataset:  10%|7      | 101/988 [00:44<09:25,  1.57it/s, scatter TotRmsAbvGrd, Id]
2023-06-26 05:07:17,794:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:07:19,230:WARNING:Summarize dataset:  10%|7      | 102/988 [00:46<12:01,  1.23it/s, scatter TotRmsAbvGrd, Id]
2023-06-26 05:07:19,232:WARNING:Summarize dataset:  10%|8       | 102/988 [00:46<12:01,  1.23it/s, scatter GarageYrBlt, Id]
2023-06-26 05:07:19,589:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:07:19,637:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:07:21,273:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:07:21,638:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:07:21,727:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:07:22,032:WARNING:Summarize dataset:  10%|8       | 103/988 [00:48<18:03,  1.22s/it, scatter GarageYrBlt, Id]
2023-06-26 05:07:22,034:WARNING:Summarize dataset:  10%|9        | 103/988 [00:49<18:03,  1.22s/it, scatter GarageArea, Id]
2023-06-26 05:07:22,887:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:07:22,893:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:07:22,931:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:07:23,119:WARNING:Summarize dataset:  11%|9        | 104/988 [00:50<17:34,  1.19s/it, scatter GarageArea, Id]
2023-06-26 05:07:23,119:WARNING:Summarize dataset:  11%|9        | 104/988 [00:50<17:34,  1.19s/it, scatter WoodDeckSF, Id]
2023-06-26 05:07:23,443:WARNING:Summarize dataset:  11%|9        | 105/988 [00:50<14:25,  1.02it/s, scatter WoodDeckSF, Id]
2023-06-26 05:07:23,443:WARNING:Summarize dataset:  11%|8       | 105/988 [00:50<14:25,  1.02it/s, scatter OpenPorchSF, Id]
2023-06-26 05:07:23,798:WARNING:Summarize dataset:  11%|8       | 106/988 [00:50<12:01,  1.22it/s, scatter OpenPorchSF, Id]
2023-06-26 05:07:23,799:WARNING:Summarize dataset:  11%|6     | 106/988 [00:50<12:01,  1.22it/s, scatter EnclosedPorch, Id]
2023-06-26 05:07:24,080:WARNING:Summarize dataset:  11%|6     | 107/988 [00:51<09:53,  1.49it/s, scatter EnclosedPorch, Id]
2023-06-26 05:07:24,081:WARNING:Summarize dataset:  11%|#         | 107/988 [00:51<09:53,  1.49it/s, scatter 3SsnPorch, Id]
2023-06-26 05:07:24,390:WARNING:Summarize dataset:  11%|#         | 108/988 [00:51<08:23,  1.75it/s, scatter 3SsnPorch, Id]
2023-06-26 05:07:24,390:WARNING:Summarize dataset:  11%|8       | 108/988 [00:51<08:23,  1.75it/s, scatter ScreenPorch, Id]
2023-06-26 05:07:24,634:WARNING:Summarize dataset:  11%|8       | 109/988 [00:51<07:00,  2.09it/s, scatter ScreenPorch, Id]
2023-06-26 05:07:24,635:WARNING:Summarize dataset:  11%|#2         | 109/988 [00:51<07:00,  2.09it/s, scatter PoolArea, Id]
2023-06-26 05:07:24,910:WARNING:Summarize dataset:  11%|#2         | 110/988 [00:51<06:08,  2.38it/s, scatter PoolArea, Id]
2023-06-26 05:07:24,911:WARNING:Summarize dataset:  11%|#3          | 110/988 [00:51<06:08,  2.38it/s, scatter MiscVal, Id]
2023-06-26 05:07:25,482:WARNING:Summarize dataset:  11%|#3          | 111/988 [00:52<06:47,  2.15it/s, scatter MiscVal, Id]
2023-06-26 05:07:25,483:WARNING:Summarize dataset:  11%|#4           | 111/988 [00:52<06:47,  2.15it/s, scatter MoSold, Id]
2023-06-26 05:07:25,740:WARNING:Summarize dataset:  11%|#4           | 112/988 [00:52<05:53,  2.48it/s, scatter MoSold, Id]
2023-06-26 05:07:25,740:WARNING:Summarize dataset:  11%|#1        | 112/988 [00:52<05:53,  2.48it/s, scatter SalePrice, Id]
2023-06-26 05:07:26,056:WARNING:Summarize dataset:  11%|#1        | 113/988 [00:53<05:30,  2.65it/s, scatter SalePrice, Id]
2023-06-26 05:07:26,060:WARNING:Summarize dataset:  11%|#        | 113/988 [00:53<05:30,  2.65it/s, scatter Id, MSSubClass]
2023-06-26 05:07:26,354:WARNING:Summarize dataset:  12%|#        | 114/988 [00:53<05:09,  2.83it/s, scatter Id, MSSubClass]
2023-06-26 05:07:26,357:WARNING:Summarize dataset:  12%|1| 114/988 [00:53<05:09,  2.83it/s, scatter MSSubClass, MSSubClass]
2023-06-26 05:07:26,617:WARNING:Summarize dataset:  12%|1| 115/988 [00:53<04:45,  3.06it/s, scatter MSSubClass, MSSubClass]
2023-06-26 05:07:26,617:WARNING:Summarize dataset:  12%|1| 115/988 [00:53<04:45,  3.06it/s, scatter LotFrontage, MSSubClass
2023-06-26 05:07:26,880:WARNING:Summarize dataset:  12%|1| 116/988 [00:53<04:28,  3.25it/s, scatter LotFrontage, MSSubClass
2023-06-26 05:07:26,880:WARNING:Summarize dataset:  12%|4   | 116/988 [00:53<04:28,  3.25it/s, scatter LotArea, MSSubClass]
2023-06-26 05:07:27,169:WARNING:Summarize dataset:  12%|4   | 117/988 [00:54<04:23,  3.31it/s, scatter LotArea, MSSubClass]
2023-06-26 05:07:27,172:WARNING:Summarize dataset:  12%|1| 117/988 [00:54<04:23,  3.31it/s, scatter OverallQual, MSSubClass
2023-06-26 05:07:27,417:WARNING:Summarize dataset:  12%|1| 118/988 [00:54<04:08,  3.50it/s, scatter OverallQual, MSSubClass
2023-06-26 05:07:27,418:WARNING:Summarize dataset:  12%|1| 118/988 [00:54<04:08,  3.50it/s, scatter OverallCond, MSSubClass
2023-06-26 05:07:27,523:INFO:Calculating mean and std
2023-06-26 05:07:27,525:INFO:Creating metrics dataframe
2023-06-26 05:07:27,717:WARNING:Summarize dataset:  12%|1| 119/988 [00:54<04:12,  3.45it/s, scatter OverallCond, MSSubClass
2023-06-26 05:07:27,717:WARNING:Summarize dataset:  12%|2 | 119/988 [00:54<04:12,  3.45it/s, scatter YearBuilt, MSSubClass]
2023-06-26 05:07:28,030:WARNING:Summarize dataset:  12%|2 | 120/988 [00:54<04:17,  3.37it/s, scatter YearBuilt, MSSubClass]
2023-06-26 05:07:28,031:WARNING:Summarize dataset:  12%|1| 120/988 [00:54<04:17,  3.37it/s, scatter YearRemodAdd, MSSubClas
2023-06-26 05:07:28,306:WARNING:Summarize dataset:  12%|1| 121/988 [00:55<04:11,  3.44it/s, scatter YearRemodAdd, MSSubClas
2023-06-26 05:07:28,306:WARNING:Summarize dataset:  12%|1| 121/988 [00:55<04:11,  3.44it/s, scatter MasVnrArea, MSSubClass]
2023-06-26 05:07:28,397:INFO:Uploading results into container
2023-06-26 05:07:28,398:INFO:Uploading model into container now
2023-06-26 05:07:28,399:INFO:_master_model_container: 3
2023-06-26 05:07:28,399:INFO:_display_container: 2
2023-06-26 05:07:28,399:INFO:Ridge(random_state=4661)
2023-06-26 05:07:28,399:INFO:create_model() successfully completed......................................
2023-06-26 05:07:28,627:INFO:SubProcess create_model() end ==================================
2023-06-26 05:07:28,627:INFO:Creating metrics dataframe
2023-06-26 05:07:28,630:INFO:Initializing Elastic Net
2023-06-26 05:07:28,630:INFO:Total runtime is 1.2334799329439798 minutes
2023-06-26 05:07:28,630:INFO:SubProcess create_model() called ==================================
2023-06-26 05:07:28,631:INFO:Initializing create_model()
2023-06-26 05:07:28,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9C4C8E290>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:07:28,631:INFO:Checking exceptions
2023-06-26 05:07:28,631:INFO:Importing libraries
2023-06-26 05:07:28,631:INFO:Copying training dataset
2023-06-26 05:07:28,711:INFO:Defining folds
2023-06-26 05:07:28,711:INFO:Declaring metric variables
2023-06-26 05:07:28,712:INFO:Importing untrained model
2023-06-26 05:07:28,712:INFO:Elastic Net Imported successfully
2023-06-26 05:07:28,712:INFO:Starting cross validation
2023-06-26 05:07:28,731:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:07:28,878:WARNING:Summarize dataset:  12%|1| 122/988 [00:55<05:24,  2.67it/s, scatter MasVnrArea, MSSubClass]
2023-06-26 05:07:28,878:WARNING:Summarize dataset:  12%|1| 122/988 [00:55<05:24,  2.67it/s, scatter BsmtFinSF1, MSSubClass]
2023-06-26 05:07:29,164:WARNING:Summarize dataset:  12%|1| 123/988 [00:56<05:01,  2.87it/s, scatter BsmtFinSF1, MSSubClass]
2023-06-26 05:07:29,169:WARNING:Summarize dataset:  12%|1| 123/988 [00:56<05:01,  2.87it/s, scatter BsmtFinSF2, MSSubClass]
2023-06-26 05:07:29,456:WARNING:Summarize dataset:  13%|1| 124/988 [00:56<04:46,  3.02it/s, scatter BsmtFinSF2, MSSubClass]
2023-06-26 05:07:29,457:WARNING:Summarize dataset:  13%|2 | 124/988 [00:56<04:46,  3.02it/s, scatter BsmtUnfSF, MSSubClass]
2023-06-26 05:07:29,696:WARNING:Summarize dataset:  13%|2 | 125/988 [00:56<04:22,  3.29it/s, scatter BsmtUnfSF, MSSubClass]
2023-06-26 05:07:29,696:WARNING:Summarize dataset:  13%|1| 125/988 [00:56<04:22,  3.29it/s, scatter TotalBsmtSF, MSSubClass
2023-06-26 05:07:30,116:WARNING:Summarize dataset:  13%|1| 126/988 [00:57<04:45,  3.02it/s, scatter TotalBsmtSF, MSSubClass
2023-06-26 05:07:30,135:WARNING:Summarize dataset:  13%|3  | 126/988 [00:57<04:45,  3.02it/s, scatter 1stFlrSF, MSSubClass]
2023-06-26 05:07:30,396:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.285e+06, tolerance: 1.623e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:30,400:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.224e+07, tolerance: 1.593e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:30,466:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+06, tolerance: 1.628e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:30,504:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.998e+06, tolerance: 1.619e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:30,511:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e+06, tolerance: 1.641e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:30,553:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.202e+06, tolerance: 1.618e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:30,556:WARNING:Summarize dataset:  13%|3  | 127/988 [00:57<05:19,  2.69it/s, scatter 1stFlrSF, MSSubClass]
2023-06-26 05:07:30,557:WARNING:Summarize dataset:  13%|3  | 127/988 [00:57<05:19,  2.69it/s, scatter 2ndFlrSF, MSSubClass]
2023-06-26 05:07:30,958:WARNING:Summarize dataset:  13%|3  | 128/988 [00:57<05:27,  2.63it/s, scatter 2ndFlrSF, MSSubClass]
2023-06-26 05:07:30,959:WARNING:Summarize dataset:  13%|1| 128/988 [00:57<05:27,  2.63it/s, scatter LowQualFinSF, MSSubClas
2023-06-26 05:07:31,343:WARNING:Summarize dataset:  13%|1| 129/988 [00:58<05:28,  2.62it/s, scatter LowQualFinSF, MSSubClas
2023-06-26 05:07:31,344:WARNING:Summarize dataset:  13%|2 | 129/988 [00:58<05:28,  2.62it/s, scatter GrLivArea, MSSubClass]
2023-06-26 05:07:31,511:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:07:31,718:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.845e+06, tolerance: 1.609e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:31,724:WARNING:Summarize dataset:  13%|2 | 130/988 [00:58<05:27,  2.62it/s, scatter GrLivArea, MSSubClass]
2023-06-26 05:07:31,725:WARNING:Summarize dataset:  13%|1| 130/988 [00:58<05:27,  2.62it/s, scatter BedroomAbvGr, MSSubClas
2023-06-26 05:07:31,759:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.765e+06, tolerance: 1.612e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:31,809:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.751e+06, tolerance: 1.615e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:31,834:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.251e+06, tolerance: 1.600e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:32,074:WARNING:Summarize dataset:  13%|1| 131/988 [00:59<05:18,  2.69it/s, scatter BedroomAbvGr, MSSubClas
2023-06-26 05:07:32,074:WARNING:Summarize dataset:  13%|1| 131/988 [00:59<05:18,  2.69it/s, scatter TotRmsAbvGrd, MSSubClas
2023-06-26 05:07:32,441:WARNING:Summarize dataset:  13%|1| 132/988 [00:59<05:16,  2.70it/s, scatter TotRmsAbvGrd, MSSubClas
2023-06-26 05:07:32,441:WARNING:Summarize dataset:  13%|1| 132/988 [00:59<05:16,  2.70it/s, scatter GarageYrBlt, MSSubClass
2023-06-26 05:07:32,702:WARNING:Summarize dataset:  13%|1| 133/988 [00:59<04:48,  2.96it/s, scatter GarageYrBlt, MSSubClass
2023-06-26 05:07:32,702:WARNING:Summarize dataset:  13%|1| 133/988 [00:59<04:48,  2.96it/s, scatter GarageArea, MSSubClass]
2023-06-26 05:07:34,415:WARNING:Summarize dataset:  14%|1| 134/988 [01:01<10:40,  1.33it/s, scatter GarageArea, MSSubClass]
2023-06-26 05:07:34,418:WARNING:Summarize dataset:  14%|1| 134/988 [01:01<10:40,  1.33it/s, scatter WoodDeckSF, MSSubClass]
2023-06-26 05:07:36,929:WARNING:Summarize dataset:  14%|1| 135/988 [01:03<18:11,  1.28s/it, scatter WoodDeckSF, MSSubClass]
2023-06-26 05:07:36,931:WARNING:Summarize dataset:  14%|1| 135/988 [01:03<18:11,  1.28s/it, scatter OpenPorchSF, MSSubClass
2023-06-26 05:07:38,085:WARNING:Summarize dataset:  14%|1| 136/988 [01:05<17:38,  1.24s/it, scatter OpenPorchSF, MSSubClass
2023-06-26 05:07:38,087:WARNING:Summarize dataset:  14%|1| 136/988 [01:05<17:38,  1.24s/it, scatter EnclosedPorch, MSSubCla
2023-06-26 05:07:38,372:WARNING:Summarize dataset:  14%|1| 137/988 [01:05<13:33,  1.05it/s, scatter EnclosedPorch, MSSubCla
2023-06-26 05:07:38,372:WARNING:Summarize dataset:  14%|2 | 137/988 [01:05<13:33,  1.05it/s, scatter 3SsnPorch, MSSubClass]
2023-06-26 05:07:38,656:WARNING:Summarize dataset:  14%|2 | 138/988 [01:05<10:41,  1.33it/s, scatter 3SsnPorch, MSSubClass]
2023-06-26 05:07:38,656:WARNING:Summarize dataset:  14%|1| 138/988 [01:05<10:41,  1.33it/s, scatter ScreenPorch, MSSubClass
2023-06-26 05:07:38,936:WARNING:Summarize dataset:  14%|1| 139/988 [01:05<08:39,  1.63it/s, scatter ScreenPorch, MSSubClass
2023-06-26 05:07:38,936:WARNING:Summarize dataset:  14%|4  | 139/988 [01:05<08:39,  1.63it/s, scatter PoolArea, MSSubClass]
2023-06-26 05:07:39,548:WARNING:Summarize dataset:  14%|4  | 140/988 [01:06<08:38,  1.63it/s, scatter PoolArea, MSSubClass]
2023-06-26 05:07:39,554:WARNING:Summarize dataset:  14%|5   | 140/988 [01:06<08:38,  1.63it/s, scatter MiscVal, MSSubClass]
2023-06-26 05:07:39,856:WARNING:Summarize dataset:  14%|5   | 141/988 [01:06<07:21,  1.92it/s, scatter MiscVal, MSSubClass]
2023-06-26 05:07:39,857:WARNING:Summarize dataset:  14%|7    | 141/988 [01:06<07:21,  1.92it/s, scatter MoSold, MSSubClass]
2023-06-26 05:07:40,082:WARNING:Summarize dataset:  14%|7    | 141/988 [01:07<06:42,  2.10it/s, scatter MoSold, MSSubClass]
2023-06-26 05:07:40,082:WARNING:
2023-06-26 05:07:42,545:INFO:Calculating mean and std
2023-06-26 05:07:42,546:WARNING:
2023-06-26 05:07:42,546:WARNING:
2023-06-26 05:07:42,546:WARNING:Processing:  11%|####7                                      | 9/81 [00:59<09:30,  7.92s/it]
2023-06-26 05:07:42,546:WARNING:[A[A
2023-06-26 05:07:42,546:INFO:Creating metrics dataframe
2023-06-26 05:07:43,801:WARNING:
2023-06-26 05:07:43,801:WARNING:
2023-06-26 05:07:43,801:WARNING:Processing:  12%|#####1                                    | 10/81 [01:00<07:35,  6.42s/it]
2023-06-26 05:07:43,801:WARNING:[A[A
2023-06-26 05:07:43,801:INFO:Uploading results into container
2023-06-26 05:07:43,802:INFO:Uploading model into container now
2023-06-26 05:07:43,802:INFO:_master_model_container: 2
2023-06-26 05:07:43,804:INFO:_display_container: 2
2023-06-26 05:07:43,804:INFO:Lasso(random_state=5040)
2023-06-26 05:07:43,805:INFO:create_model() successfully completed......................................
2023-06-26 05:07:44,004:INFO:SubProcess create_model() end ==================================
2023-06-26 05:07:44,004:INFO:Creating metrics dataframe
2023-06-26 05:07:44,009:INFO:Initializing Ridge Regression
2023-06-26 05:07:44,010:INFO:Total runtime is 1.0132759491602579 minutes
2023-06-26 05:07:44,010:INFO:SubProcess create_model() called ==================================
2023-06-26 05:07:44,011:INFO:Initializing create_model()
2023-06-26 05:07:44,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BAAF63E0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BD66AE00>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:07:44,011:INFO:Checking exceptions
2023-06-26 05:07:44,011:INFO:Importing libraries
2023-06-26 05:07:44,011:INFO:Copying training dataset
2023-06-26 05:07:44,044:WARNING:
2023-06-26 05:07:44,044:WARNING:
2023-06-26 05:07:44,045:WARNING:Processing:  14%|#####7                                    | 11/81 [01:00<05:43,  4.91s/it]
2023-06-26 05:07:44,046:WARNING:[A[A
2023-06-26 05:07:44,046:INFO:Defining folds
2023-06-26 05:07:44,046:INFO:Declaring metric variables
2023-06-26 05:07:44,047:INFO:Importing untrained model
2023-06-26 05:07:44,047:INFO:Ridge Regression Imported successfully
2023-06-26 05:07:44,048:INFO:Starting cross validation
2023-06-26 05:07:44,090:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:07:47,310:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:07:47,681:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:07:48,902:INFO:Calculating mean and std
2023-06-26 05:07:48,910:INFO:Creating metrics dataframe
2023-06-26 05:07:49,926:INFO:Uploading results into container
2023-06-26 05:07:49,927:INFO:Uploading model into container now
2023-06-26 05:07:49,929:INFO:_master_model_container: 4
2023-06-26 05:07:49,929:INFO:_display_container: 2
2023-06-26 05:07:49,930:INFO:ElasticNet(random_state=4661)
2023-06-26 05:07:49,930:INFO:create_model() successfully completed......................................
2023-06-26 05:07:50,132:INFO:SubProcess create_model() end ==================================
2023-06-26 05:07:50,132:INFO:Creating metrics dataframe
2023-06-26 05:07:50,136:INFO:Initializing Least Angle Regression
2023-06-26 05:07:50,136:INFO:Total runtime is 1.5919076244036356 minutes
2023-06-26 05:07:50,136:INFO:SubProcess create_model() called ==================================
2023-06-26 05:07:50,136:INFO:Initializing create_model()
2023-06-26 05:07:50,136:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9C4C8E290>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:07:50,137:INFO:Checking exceptions
2023-06-26 05:07:50,137:INFO:Importing libraries
2023-06-26 05:07:50,137:INFO:Copying training dataset
2023-06-26 05:07:50,163:INFO:Defining folds
2023-06-26 05:07:50,163:INFO:Declaring metric variables
2023-06-26 05:07:50,163:INFO:Importing untrained model
2023-06-26 05:07:50,163:INFO:Least Angle Regression Imported successfully
2023-06-26 05:07:50,164:INFO:Starting cross validation
2023-06-26 05:07:50,188:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:07:51,233:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:07:51,269:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.717e-01, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,272:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=5.580e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,276:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=4.060e-01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,279:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=3.456e-01, with an active set of 80 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,280:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=3.290e-01, with an active set of 84 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,281:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=3.179e-01, with an active set of 86 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,282:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=3.041e-01, with an active set of 94 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,284:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.822e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,285:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.760e-01, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,287:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.567e-01, with an active set of 110 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,287:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.475e-01, with an active set of 112 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,312:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=2.068e-01, with an active set of 137 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,312:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=2.065e-01, with an active set of 137 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,313:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=1.987e-01, with an active set of 142 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,316:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.838e-01, with an active set of 151 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,316:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:07:51,319:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=3.146e-01, with an active set of 154 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,319:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.580e-01, with an active set of 154 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,319:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.409e-01, with an active set of 154 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,323:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=2.085e-01, with an active set of 166 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,323:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=2.079e-01, with an active set of 166 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,324:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=1.984e-01, with an active set of 167 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,325:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=1.984e-01, with an active set of 167 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,325:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 183 iterations, i.e. alpha=1.974e-01, with an active set of 168 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,326:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 185 iterations, i.e. alpha=1.940e-01, with an active set of 170 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,329:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=1.801e-01, with an active set of 178 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,330:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 200 iterations, i.e. alpha=1.711e-01, with an active set of 183 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,331:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 200 iterations, i.e. alpha=1.701e-01, with an active set of 183 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,334:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=1.756e-01, with an active set of 188 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,337:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=2.058e-01, with an active set of 195 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,338:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 222 iterations, i.e. alpha=2.015e-01, with an active set of 196 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,338:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 222 iterations, i.e. alpha=1.959e-01, with an active set of 196 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,339:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 224 iterations, i.e. alpha=1.883e-01, with an active set of 197 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,343:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:07:51,344:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=1.998e-01, with an active set of 204 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,344:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=1.989e-01, with an active set of 204 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,344:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=1.968e-01, with an active set of 204 regressors, and the smallest cholesky pivot element being 8.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,345:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=1.891e-01, with an active set of 206 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,346:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=1.816e-01, with an active set of 208 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,350:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:07:51,352:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=1.843e-01, with an active set of 209 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,352:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=1.781e-01, with an active set of 210 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,353:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:07:51,353:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=1.746e-01, with an active set of 211 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,354:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=1.696e-01, with an active set of 213 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,355:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=1.669e-01, with an active set of 213 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,357:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.636e-01, with an active set of 215 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,357:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.846e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,357:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.624e-01, with an active set of 215 regressors, and the smallest cholesky pivot element being 8.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,357:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.595e-01, with an active set of 215 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,358:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.535e-01, with an active set of 216 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,358:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=1.449e-01, with an active set of 217 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,360:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=1.460e-01, with an active set of 218 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,360:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=1.446e-01, with an active set of 218 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,361:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=1.403e-01, with an active set of 219 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,361:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=1.372e-01, with an active set of 219 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,361:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=1.321e-01, with an active set of 219 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,362:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=4.712e-01, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,363:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=2.272e-01, with an active set of 125 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,364:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=4.713e-01, with an active set of 223 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,364:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=4.078e-01, with an active set of 223 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,365:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=3.122e-01, with an active set of 223 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,365:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=6.480e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,365:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=2.136e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,365:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=2.918e-01, with an active set of 224 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,366:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 271 iterations, i.e. alpha=2.372e-01, with an active set of 225 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,366:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=6.113e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,369:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=3.208e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,369:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=2.971e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,369:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 148 iterations, i.e. alpha=1.848e-01, with an active set of 142 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,372:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:07:51,372:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=2.921e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,372:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=2.707e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,373:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=2.698e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,373:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=2.527e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,373:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 162 iterations, i.e. alpha=1.555e-01, with an active set of 154 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,373:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.512e-01, with an active set of 79 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,374:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=2.214e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,375:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=3.295e-01, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,375:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=2.106e-01, with an active set of 228 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,375:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=2.049e-01, with an active set of 228 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,376:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=2.034e-01, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,376:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=2.002e-01, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,376:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.473e-01, with an active set of 161 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,376:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.712e-01, with an active set of 228 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,376:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.663e-01, with an active set of 228 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,376:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.571e-01, with an active set of 228 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,377:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.505e-01, with an active set of 228 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,377:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=1.322e-01, with an active set of 229 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,377:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=1.395e-01, with an active set of 164 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,377:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=1.309e-01, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,378:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=1.206e-01, with an active set of 229 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,378:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=1.170e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,379:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=1.149e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,379:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=1.125e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,379:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=1.328e-01, with an active set of 170 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,379:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=9.862e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,379:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=9.599e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,380:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=9.186e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,380:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.899e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,380:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=8.958e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,381:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=1.277e-01, with an active set of 173 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,381:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=7.703e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,382:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=7.204e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,382:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=6.533e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,382:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=6.426e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,382:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=6.135e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,383:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=5.406e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-06-26 05:07:51,383:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=5.497e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,383:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=5.472e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,383:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=5.393e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,383:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=4.622e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,384:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=4.532e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,384:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=4.509e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,385:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=4.393e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,385:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=3.917e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,385:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=3.873e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,386:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=3.754e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,386:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=3.662e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,386:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=3.635e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,386:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=3.531e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,387:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=3.396e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,387:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=3.115e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,387:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.356e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,387:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.346e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,387:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.243e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,388:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.900e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,388:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.898e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,388:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.885e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,388:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.855e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,389:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.690e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,389:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.601e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,389:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.420e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,391:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.780e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,392:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.242e-01, with an active set of 123 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,392:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.274e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,394:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 212 iterations, i.e. alpha=1.081e-01, with an active set of 189 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,395:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=1.989e-01, with an active set of 137 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,395:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=2.728e-01, with an active set of 113 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,397:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=1.894e-01, with an active set of 142 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,397:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.483e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,397:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=1.791e-01, with an active set of 143 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,398:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 224 iterations, i.e. alpha=1.036e+00, with an active set of 191 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,398:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.422e-01, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,398:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=1.483e-01, with an active set of 145 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,398:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.162e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,399:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=9.284e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,399:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=7.411e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,399:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=1.329e-01, with an active set of 149 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,399:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=7.161e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,399:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=6.759e-01, with an active set of 194 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,399:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=6.910e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,400:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=6.086e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,400:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.276e-01, with an active set of 152 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,400:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=3.516e+01, with an active set of 123 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,400:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=5.312e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,401:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.876e+01, with an active set of 123 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,401:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.865e+01, with an active set of 123 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,401:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=4.915e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,401:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=4.838e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,401:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=3.695e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,401:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=1.238e+01, with an active set of 125 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,402:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=3.535e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,402:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=2.931e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,402:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=2.379e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,402:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=2.207e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,402:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=2.100e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,402:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=6.591e-01, with an active set of 197 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,403:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=8.910e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,403:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=2.073e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,403:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=6.449e-01, with an active set of 197 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,403:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.946e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,403:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.910e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,403:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=8.892e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,403:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.886e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,403:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.095e-01, with an active set of 165 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,403:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.777e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,403:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=6.168e-01, with an active set of 198 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,404:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.511e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,404:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.415e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,404:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=9.750e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,404:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=1.054e-01, with an active set of 168 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,405:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=8.793e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,405:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=7.630e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,405:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=3.161e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,405:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=7.554e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,405:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=7.530e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 8.229e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,406:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.050e-01, with an active set of 171 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,406:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=7.399e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,406:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=8.006e+00, with an active set of 136 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,406:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=6.705e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,406:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=7.693e+00, with an active set of 136 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,406:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=4.555e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,406:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=4.125e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,406:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=5.454e-01, with an active set of 202 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,406:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=3.996e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,407:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=2.060e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,407:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.735e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,407:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.079e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,407:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=9.351e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,408:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=8.228e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,408:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=8.521e-02, with an active set of 177 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,408:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=5.267e-01, with an active set of 205 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,408:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=8.090e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,408:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=5.385e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,408:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=4.840e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,408:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=2.710e-06, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,410:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=4.777e-01, with an active set of 209 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,410:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=4.597e-01, with an active set of 209 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,410:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=4.465e-01, with an active set of 209 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,411:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 192 iterations, i.e. alpha=7.894e-02, with an active set of 183 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,411:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=3.994e-01, with an active set of 211 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,411:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=7.272e-02, with an active set of 185 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,411:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=7.254e-02, with an active set of 185 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,412:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=3.765e-01, with an active set of 212 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,412:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=6.928e-02, with an active set of 187 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,413:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=4.535e-01, with an active set of 214 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,413:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=6.755e-02, with an active set of 188 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,413:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=4.142e-01, with an active set of 214 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,414:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 199 iterations, i.e. alpha=6.681e-02, with an active set of 189 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,414:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.773e-01, with an active set of 152 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,414:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 199 iterations, i.e. alpha=6.382e-02, with an active set of 189 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,414:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.484e-01, with an active set of 152 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,415:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=1.154e+00, with an active set of 217 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,416:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=6.169e-02, with an active set of 191 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,416:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=8.481e-01, with an active set of 218 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,417:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=7.911e-01, with an active set of 218 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,418:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=7.155e-01, with an active set of 220 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,418:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=5.833e-02, with an active set of 196 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,418:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=6.172e-01, with an active set of 220 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,418:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=6.086e-01, with an active set of 220 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,419:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=6.017e-01, with an active set of 220 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,419:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=2.356e-01, with an active set of 164 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,419:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 163 iterations, i.e. alpha=1.672e-01, with an active set of 159 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,421:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=8.056e+00, with an active set of 142 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,421:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=1.791e-01, with an active set of 163 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,422:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=5.767e-01, with an active set of 222 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,422:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=8.033e+00, with an active set of 142 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,422:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=5.366e-02, with an active set of 204 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,423:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=5.594e-01, with an active set of 223 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,424:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=1.949e-01, with an active set of 176 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,424:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=1.758e-01, with an active set of 168 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,424:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=6.004e-01, with an active set of 224 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,424:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.176e+01, with an active set of 147 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,425:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=5.103e-01, with an active set of 224 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,426:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=1.842e-01, with an active set of 181 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,426:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=4.844e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,427:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=4.799e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,427:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=5.292e-02, with an active set of 206 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,428:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 191 iterations, i.e. alpha=1.657e-01, with an active set of 177 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,427:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=4.685e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,428:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 192 iterations, i.e. alpha=1.589e-01, with an active set of 178 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,429:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.558e-01, with an active set of 228 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,429:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=5.095e-02, with an active set of 207 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,429:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.490e-01, with an active set of 228 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,430:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 188 iterations, i.e. alpha=9.549e+00, with an active set of 162 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,430:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=1.547e-01, with an active set of 180 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,430:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.329e-01, with an active set of 228 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,430:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=1.805e-01, with an active set of 191 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,431:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=3.873e-01, with an active set of 229 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,431:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=4.724e-02, with an active set of 208 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,431:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=3.822e-01, with an active set of 229 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,432:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 222 iterations, i.e. alpha=4.638e-02, with an active set of 209 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,432:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=1.507e-01, with an active set of 186 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,432:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=3.846e-01, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,433:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=3.844e-01, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,433:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=4.583e-02, with an active set of 210 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,433:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=3.758e-01, with an active set of 231 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,433:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=4.512e-02, with an active set of 210 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,433:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=3.474e-01, with an active set of 231 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,434:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=1.668e-01, with an active set of 200 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,434:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=1.166e+01, with an active set of 173 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,435:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=3.400e-01, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,435:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=1.078e+01, with an active set of 173 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,435:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=3.209e-01, with an active set of 232 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,435:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=1.638e-01, with an active set of 202 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,435:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=1.295e-01, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,436:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=2.908e-01, with an active set of 232 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,436:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 231 iterations, i.e. alpha=1.572e-01, with an active set of 203 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,437:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 226 iterations, i.e. alpha=4.330e-02, with an active set of 212 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,437:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 226 iterations, i.e. alpha=4.197e-02, with an active set of 212 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,437:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=2.813e-01, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,438:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 213 iterations, i.e. alpha=1.270e-01, with an active set of 194 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,438:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=4.064e-02, with an active set of 213 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,438:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=1.466e-01, with an active set of 205 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,438:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=3.925e-02, with an active set of 213 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,439:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.614e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,439:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.330e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,439:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.273e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,440:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.270e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,440:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=1.049e-01, with an active set of 201 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,440:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=1.602e-01, with an active set of 209 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,441:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.940e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,441:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.901e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,441:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.746e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,442:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.692e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,442:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.647e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,442:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.514e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,442:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 233 iterations, i.e. alpha=4.799e-02, with an active set of 216 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,443:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.294e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,443:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 233 iterations, i.e. alpha=4.728e-02, with an active set of 216 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,443:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.193e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,443:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=1.088e-01, with an active set of 206 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,444:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 233 iterations, i.e. alpha=4.207e-02, with an active set of 216 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,444:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.115e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,444:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=1.978e-01, with an active set of 211 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,445:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=9.862e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,445:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=8.988e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,445:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=3.475e-02, with an active set of 217 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,445:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=1.597e-01, with an active set of 209 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,445:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=7.961e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,445:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=3.424e-02, with an active set of 217 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,446:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=7.530e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,446:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=3.226e-02, with an active set of 217 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,446:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=6.163e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,446:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=2.982e-02, with an active set of 217 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,446:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=5.905e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,446:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=2.830e-02, with an active set of 217 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,446:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=5.730e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,446:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=2.826e-02, with an active set of 217 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,446:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=1.097e-01, with an active set of 210 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,446:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=5.324e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,447:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.528e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,447:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.333e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,447:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=2.663e-02, with an active set of 218 regressors, and the smallest cholesky pivot element being 9.714e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,447:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.154e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,447:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.604e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,447:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.544e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,447:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.150e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,447:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.213e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,449:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.209e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,449:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=8.701e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,449:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=8.435e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,449:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=5.482e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,449:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.953e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,450:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=2.576e-02, with an active set of 221 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,450:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=2.432e-02, with an active set of 221 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,450:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=1.467e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,451:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=2.386e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,451:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=1.461e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,451:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=1.327e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,452:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=2.383e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,452:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=1.205e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,452:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=2.338e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,452:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=9.170e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,453:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=7.664e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,453:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.993e+00, with an active set of 215 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,453:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=6.552e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,453:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=9.131e-02, with an active set of 219 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,453:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=6.288e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,453:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=8.843e-02, with an active set of 219 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,453:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=6.288e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,453:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=8.770e-02, with an active set of 219 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,454:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=4.977e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,454:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=8.646e-02, with an active set of 219 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,454:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=4.976e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,454:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=4.716e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,455:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=2.311e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,455:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=4.116e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,455:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=2.305e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,455:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=3.692e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,455:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.930e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,455:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=3.169e+00, with an active set of 218 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,456:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.595e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,456:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.460e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,456:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.406e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,456:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.085e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,456:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.070e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,456:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=8.321e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 8.816e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,456:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.000e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,457:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.918e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,457:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=8.054e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,457:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=2.467e-02, with an active set of 226 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,457:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.858e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,457:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.652e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,457:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=2.432e-02, with an active set of 226 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,457:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.564e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,457:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=2.059e-02, with an active set of 226 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,457:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=7.689e-02, with an active set of 225 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,457:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.511e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,458:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.269e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,458:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=1.837e-02, with an active set of 226 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,458:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=7.599e-02, with an active set of 225 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,458:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=1.190e+01, with an active set of 220 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,458:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.030e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,458:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=1.749e-02, with an active set of 226 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,443:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 231 iterations, i.e. alpha=1.079e+01, with an active set of 193 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,458:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=7.364e-05, with an active set of 237 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,458:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=7.303e-05, with an active set of 237 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,458:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=6.923e-02, with an active set of 226 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,458:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=6.213e+00, with an active set of 220 regressors, and the smallest cholesky pivot element being 9.003e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,459:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=7.071e-05, with an active set of 237 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,459:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=6.014e-05, with an active set of 237 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,459:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=6.243e-02, with an active set of 226 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,459:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=1.737e-02, with an active set of 227 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,459:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=5.979e-05, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,459:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=1.732e-02, with an active set of 227 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,459:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=5.218e-05, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,459:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=5.978e-02, with an active set of 227 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,460:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=4.559e-05, with an active set of 237 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,460:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=3.958e-05, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,460:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=3.787e-05, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,461:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=3.465e-05, with an active set of 237 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,461:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=5.505e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,461:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=3.077e-05, with an active set of 237 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,461:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.981e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,462:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.816e-05, with an active set of 237 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,462:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.731e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,462:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.671e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,462:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.414e-05, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,462:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.594e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,462:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.236e-05, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,462:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.396e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,463:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.376e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,463:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.366e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,463:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.194e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,463:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.154e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,463:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=4.966e+02, with an active set of 224 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,464:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.145e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,464:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=1.890e+02, with an active set of 224 regressors, and the smallest cholesky pivot element being 9.003e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,464:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.134e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,464:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=1.078e+02, with an active set of 224 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,464:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=7.391e+01, with an active set of 224 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,465:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=9.702e-03, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,465:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=6.857e+01, with an active set of 225 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,465:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=6.563e+01, with an active set of 225 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,465:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=6.521e+01, with an active set of 225 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,466:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=6.346e+01, with an active set of 225 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,466:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=5.782e+01, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,466:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=6.063e+01, with an active set of 225 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,466:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=5.766e+01, with an active set of 225 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,466:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=2.464e+01, with an active set of 231 regressors, and the smallest cholesky pivot element being 8.816e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,466:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=5.556e+01, with an active set of 225 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,466:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=2.125e+01, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,466:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=5.171e+01, with an active set of 225 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,466:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=1.052e-02, with an active set of 231 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,467:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=5.083e+01, with an active set of 225 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,467:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=2.075e+01, with an active set of 231 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,467:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.963e+01, with an active set of 231 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,467:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.689e+01, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,467:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.686e+01, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,467:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=4.907e+01, with an active set of 226 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,467:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=4.895e+01, with an active set of 226 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,468:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.535e+01, with an active set of 232 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,468:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=4.515e+01, with an active set of 226 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,468:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.344e+01, with an active set of 232 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,469:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.335e+01, with an active set of 232 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,469:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.301e+01, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,469:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=4.365e+01, with an active set of 227 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,469:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=4.173e+01, with an active set of 227 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,469:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.298e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,470:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=3.873e+01, with an active set of 228 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,470:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.255e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,470:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.229e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,470:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=1.501e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,470:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.222e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,470:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.049e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,470:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=1.325e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,470:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=8.536e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,471:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 298 iterations, i.e. alpha=4.178e+01, with an active set of 230 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,471:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=8.192e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,471:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=1.229e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,471:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 298 iterations, i.e. alpha=3.832e+01, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,471:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=7.854e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,471:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 298 iterations, i.e. alpha=3.316e+01, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,471:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=7.781e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,471:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 298 iterations, i.e. alpha=3.238e+01, with an active set of 230 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,471:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=1.207e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,471:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=6.858e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,471:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 298 iterations, i.e. alpha=3.072e+01, with an active set of 230 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,471:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=6.748e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,472:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=1.192e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,472:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=6.549e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,472:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=6.261e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,472:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=1.185e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,472:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=6.052e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,472:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 300 iterations, i.e. alpha=3.526e+01, with an active set of 231 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,472:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 300 iterations, i.e. alpha=2.862e+01, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,472:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=9.588e-03, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,472:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=4.830e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,473:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=9.574e-03, with an active set of 232 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,473:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=4.589e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,473:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 301 iterations, i.e. alpha=2.693e+01, with an active set of 232 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,473:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=9.077e-03, with an active set of 232 regressors, and the smallest cholesky pivot element being 9.714e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,473:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=8.998e-03, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,473:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.630e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,474:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.535e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,474:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.524e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,474:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.471e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,474:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=4.100e+00, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,474:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=3.852e+00, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,474:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.022e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,475:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=8.588e-03, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,475:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=2.564e+00, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,475:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=2.556e+00, with an active set of 234 regressors, and the smallest cholesky pivot element being 8.816e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,476:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=8.177e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,476:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=2.456e+00, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,476:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=7.771e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,476:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=7.187e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,477:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=2.321e+00, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,474:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 303 iterations, i.e. alpha=2.449e+01, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,477:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=2.250e+00, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,477:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=7.176e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,477:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 303 iterations, i.e. alpha=2.355e+01, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,477:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 303 iterations, i.e. alpha=2.233e+01, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,478:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=2.222e+00, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,478:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 303 iterations, i.e. alpha=1.905e+01, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,478:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 303 iterations, i.e. alpha=1.818e+01, with an active set of 234 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,478:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=2.178e+00, with an active set of 234 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,478:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 303 iterations, i.e. alpha=1.531e+01, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,478:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 303 iterations, i.e. alpha=1.501e+01, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,478:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.947e+00, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,478:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=6.330e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,479:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=6.156e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,479:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.746e+00, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,479:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=1.435e+01, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,479:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.725e+00, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,479:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=1.286e+01, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,480:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.700e+00, with an active set of 234 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,480:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=1.235e+01, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,480:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=1.183e+01, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,480:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.672e+00, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,480:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=1.075e+01, with an active set of 235 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,480:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.523e+00, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,481:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 305 iterations, i.e. alpha=1.058e+01, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,481:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 305 iterations, i.e. alpha=1.035e+01, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,481:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 305 iterations, i.e. alpha=1.028e+01, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,481:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=1.347e+00, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,482:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 305 iterations, i.e. alpha=9.294e+00, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,482:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 305 iterations, i.e. alpha=8.340e+00, with an active set of 236 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,482:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 305 iterations, i.e. alpha=8.328e+00, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,483:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 306 iterations, i.e. alpha=7.957e+00, with an active set of 237 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,483:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 306 iterations, i.e. alpha=5.565e+00, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,483:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 306 iterations, i.e. alpha=4.694e+00, with an active set of 237 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,483:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 306 iterations, i.e. alpha=4.248e+00, with an active set of 237 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,483:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=6.030e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,484:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=5.130e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,484:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 306 iterations, i.e. alpha=3.977e+00, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,485:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=5.124e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,485:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 306 iterations, i.e. alpha=3.960e+00, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,486:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 306 iterations, i.e. alpha=3.138e+00, with an active set of 237 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,486:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=5.107e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,486:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=5.046e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,487:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=2.886e+00, with an active set of 238 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,487:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=4.815e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,487:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=1.392e+00, with an active set of 238 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,487:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=4.371e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,487:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=1.235e+00, with an active set of 238 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,487:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=4.187e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,488:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=1.057e+00, with an active set of 238 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,488:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=4.181e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,488:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=1.034e+00, with an active set of 238 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,488:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=1.014e+00, with an active set of 238 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,488:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=4.133e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,488:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=4.126e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 8.816e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,489:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=4.104e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,489:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.902e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,489:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=1.710e-01, with an active set of 245 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,489:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=3.896e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,489:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=6.444e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,489:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=3.452e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,489:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=5.395e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,489:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=3.191e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,489:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=5.374e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,490:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=3.017e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,490:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=4.647e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,490:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=2.859e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,490:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=4.293e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,490:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=2.832e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,490:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=4.235e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,490:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=2.777e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,490:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=4.231e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,490:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=2.541e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,490:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=2.101e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,491:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.874e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,491:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=3.783e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,491:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.492e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,491:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=2.995e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,491:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.438e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,491:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=2.793e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,491:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.325e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,491:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=2.444e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,491:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=2.007e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,492:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=7.362e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,492:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=6.808e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,492:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=1.660e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,492:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=4.487e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,493:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=1.652e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,493:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=4.393e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,493:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=4.247e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,493:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=1.561e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,493:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=1.503e-01, with an active set of 238 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,494:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=3.853e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,494:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=3.323e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,494:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=6.412e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,494:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=6.181e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,494:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=6.395e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,495:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=2.988e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,495:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=1.946e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,495:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=1.041e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:51,495:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=3.814e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,353:INFO:Calculating mean and std
2023-06-26 05:07:52,354:WARNING:
2023-06-26 05:07:52,354:WARNING:
2023-06-26 05:07:52,354:WARNING:Processing:  16%|######7                                   | 13/81 [01:09<05:12,  4.60s/it]
2023-06-26 05:07:52,354:WARNING:[A[A
2023-06-26 05:07:52,354:INFO:Creating metrics dataframe
2023-06-26 05:07:52,645:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:07:52,667:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:07:52,672:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=6.269e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,693:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=6.431e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,697:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=3.150e-01, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,716:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 139 iterations, i.e. alpha=2.010e-01, with an active set of 136 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,720:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=1.512e-01, with an active set of 153 regressors, and the smallest cholesky pivot element being 8.816e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,723:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.327e-01, with an active set of 164 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,726:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=1.378e-01, with an active set of 157 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,726:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 178 iterations, i.e. alpha=1.225e-01, with an active set of 172 regressors, and the smallest cholesky pivot element being 8.816e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,729:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=1.127e-01, with an active set of 170 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,732:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=1.089e-01, with an active set of 178 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,733:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:07:52,746:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=9.808e-02, with an active set of 194 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,747:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=9.636e-02, with an active set of 195 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,747:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=1.077e-01, with an active set of 178 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,749:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=6.459e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,749:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=9.545e-02, with an active set of 201 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,753:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 202 iterations, i.e. alpha=1.010e-01, with an active set of 189 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,753:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 202 iterations, i.e. alpha=1.007e-01, with an active set of 189 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,755:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=8.896e-02, with an active set of 202 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,755:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=9.314e-02, with an active set of 193 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,755:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=4.124e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,756:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=8.825e-02, with an active set of 194 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,756:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=8.636e-02, with an active set of 205 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,756:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.820e-01, with an active set of 75 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,757:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=8.525e-02, with an active set of 205 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,757:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=8.343e-02, with an active set of 205 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,758:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 212 iterations, i.e. alpha=8.316e-02, with an active set of 196 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,758:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=3.521e-01, with an active set of 83 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,759:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=3.410e-01, with an active set of 85 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,760:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 233 iterations, i.e. alpha=9.697e-02, with an active set of 211 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,760:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 233 iterations, i.e. alpha=9.337e-02, with an active set of 211 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,760:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=3.247e-01, with an active set of 90 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,761:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=3.225e-01, with an active set of 92 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,762:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 238 iterations, i.e. alpha=9.209e-02, with an active set of 214 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,762:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 238 iterations, i.e. alpha=9.029e-02, with an active set of 214 regressors, and the smallest cholesky pivot element being 8.229e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,762:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 238 iterations, i.e. alpha=8.990e-02, with an active set of 214 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,763:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=7.819e-02, with an active set of 215 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,763:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=7.685e-02, with an active set of 215 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,764:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=7.460e-02, with an active set of 216 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,764:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=7.309e-02, with an active set of 216 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,764:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=7.293e-02, with an active set of 216 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,764:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=2.989e-01, with an active set of 104 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,764:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=7.217e-02, with an active set of 216 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,765:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=6.727e-02, with an active set of 217 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,765:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=6.589e-02, with an active set of 217 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,766:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=6.869e-02, with an active set of 209 regressors, and the smallest cholesky pivot element being 9.828e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,766:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.713e-01, with an active set of 110 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,766:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=6.476e-02, with an active set of 218 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,766:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=6.852e-02, with an active set of 209 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,766:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=6.851e-02, with an active set of 209 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,767:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=6.096e-02, with an active set of 219 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,768:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=6.981e-02, with an active set of 210 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,768:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.397e-01, with an active set of 117 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,770:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.272e-01, with an active set of 125 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,771:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=2.274e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,771:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=5.951e-02, with an active set of 220 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,772:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=5.764e-02, with an active set of 220 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,773:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=6.100e-02, with an active set of 216 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,774:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=5.725e-02, with an active set of 216 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,775:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=1.998e-01, with an active set of 136 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,776:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=6.529e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,776:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=6.028e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 8.229e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=1.896e-01, with an active set of 139 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,779:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=9.533e-02, with an active set of 223 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,781:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=1.083e-01, with an active set of 225 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,781:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=7.679e-02, with an active set of 223 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,783:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=7.319e-02, with an active set of 223 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,783:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=7.233e-02, with an active set of 223 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,784:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=6.301e-02, with an active set of 223 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,785:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=1.764e-01, with an active set of 145 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,786:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=1.750e-01, with an active set of 145 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,786:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=6.086e-02, with an active set of 223 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,787:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=6.023e-02, with an active set of 223 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,787:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=5.834e-02, with an active set of 223 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,788:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=5.442e-02, with an active set of 223 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,789:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=5.408e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,789:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=5.226e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,789:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=5.166e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,792:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=4.937e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,793:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=4.626e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,793:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=4.442e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,793:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=4.425e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,793:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 162 iterations, i.e. alpha=1.627e-01, with an active set of 151 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,793:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=4.334e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,794:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=4.281e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,794:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=4.058e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,796:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=3.910e-02, with an active set of 225 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,796:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=3.730e-02, with an active set of 225 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,797:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=3.567e-02, with an active set of 225 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,799:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=3.102e-02, with an active set of 227 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,800:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.501e-01, with an active set of 160 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,802:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=9.346e-02, with an active set of 227 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,805:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=9.144e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,806:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=1.400e-01, with an active set of 168 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,807:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=1.381e-01, with an active set of 168 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,807:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=1.377e-01, with an active set of 168 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,807:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=8.950e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,807:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=3.807e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,808:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=8.575e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,809:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=8.437e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,809:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=3.195e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,809:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=7.807e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,810:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=7.176e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,810:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=2.922e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,810:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=6.420e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,810:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=5.650e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,811:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=2.704e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,812:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=2.664e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,813:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=5.569e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,814:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=5.305e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,814:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=2.286e-02, with an active set of 231 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,815:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=2.230e-02, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,815:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 189 iterations, i.e. alpha=1.348e-01, with an active set of 175 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,815:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=2.075e-02, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,815:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=2.053e-02, with an active set of 231 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,815:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.992e-02, with an active set of 231 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,816:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.990e-02, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,816:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=4.988e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,816:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=4.858e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,816:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=4.629e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,816:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=4.564e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,817:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=4.324e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,817:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=1.937e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 8.229e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,817:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=1.852e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,817:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=3.911e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,818:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=1.598e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,818:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=1.538e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,818:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=3.582e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,819:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 192 iterations, i.e. alpha=1.284e-01, with an active set of 177 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,820:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=3.491e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,820:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=1.515e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,821:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=1.483e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,822:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=4.298e-02, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,823:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=3.211e-02, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,823:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=3.205e-02, with an active set of 231 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,823:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=3.079e-02, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,826:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=3.049e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,826:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.869e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,827:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.800e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,827:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.584e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,827:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.469e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,828:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=2.441e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,828:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=2.205e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,828:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=2.025e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,829:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.746e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,829:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.627e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,829:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.613e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,829:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.508e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,829:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 205 iterations, i.e. alpha=1.383e-01, with an active set of 188 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,829:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.437e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,829:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.402e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,830:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.360e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,830:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.352e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,830:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.340e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,830:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=1.160e-01, with an active set of 189 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,830:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.181e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,830:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.158e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,830:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=1.126e-01, with an active set of 189 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,830:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.155e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,830:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.048e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,830:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=1.372e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,831:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.027e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,831:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=1.287e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,831:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.011e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,831:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=9.396e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,831:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=1.269e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,831:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=7.929e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,831:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=1.172e-01, with an active set of 190 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,831:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=7.636e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,832:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=7.435e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,832:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=6.836e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,832:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=1.213e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,832:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=6.540e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,832:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=1.136e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,832:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=4.607e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,832:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=4.322e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,832:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=4.244e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,832:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=1.124e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,833:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=4.241e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,833:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=3.636e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,833:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=1.055e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,833:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=3.362e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,833:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=2.697e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,833:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=9.371e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,833:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=2.043e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,834:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.461e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,834:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=9.309e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,834:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=5.632e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,834:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=2.621e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,834:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=9.255e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,834:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=2.514e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,834:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=4.280e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,834:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=8.497e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,835:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.070e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,835:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=8.224e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,835:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=7.015e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,835:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=6.389e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,836:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=5.755e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,836:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=5.669e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,836:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=4.652e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,836:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=4.271e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,836:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=4.012e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,837:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=3.869e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,837:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.807e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,837:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.470e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,838:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.362e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,838:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.334e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,838:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.314e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,838:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.295e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,838:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.123e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,839:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=1.422e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,839:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=1.309e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,839:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=9.793e-04, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,839:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=9.333e-04, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,839:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=8.364e-04, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,839:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=7.701e-04, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,840:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=5.979e-04, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,840:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=3.481e-04, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,840:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.933e-04, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,840:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.473e-04, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,840:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=8.067e-05, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,841:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=4.753e-05, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,841:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=1.046e-05, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,841:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=1.046e-01, with an active set of 192 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,843:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 213 iterations, i.e. alpha=1.026e-01, with an active set of 195 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,846:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 214 iterations, i.e. alpha=9.948e-02, with an active set of 196 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,846:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 214 iterations, i.e. alpha=9.658e-02, with an active set of 196 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,856:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=1.108e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,861:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=9.636e-02, with an active set of 201 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,861:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=9.069e-02, with an active set of 201 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,862:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=8.814e-02, with an active set of 201 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,862:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=8.706e-02, with an active set of 201 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,863:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=8.223e-02, with an active set of 202 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,866:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=8.870e-02, with an active set of 206 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,874:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=7.920e-02, with an active set of 211 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,874:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=7.707e-02, with an active set of 211 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,876:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=9.331e-02, with an active set of 212 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,877:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 251 iterations, i.e. alpha=8.079e-02, with an active set of 213 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,882:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=4.865e-01, with an active set of 214 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,882:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=4.253e-01, with an active set of 214 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,884:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=2.358e-01, with an active set of 215 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,889:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=2.041e-01, with an active set of 218 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,893:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=2.011e-01, with an active set of 220 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,894:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=1.966e-01, with an active set of 222 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,895:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=1.839e-01, with an active set of 222 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,897:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.661e-01, with an active set of 225 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,897:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.613e-01, with an active set of 225 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,900:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.656e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,900:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.538e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,901:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.376e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,903:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.366e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,903:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.287e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,905:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.243e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,905:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.240e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,905:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.208e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,906:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:07:52,909:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=1.229e-01, with an active set of 229 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,911:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.247e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,911:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.195e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,911:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.121e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,912:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.094e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,915:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.064e-01, with an active set of 231 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,915:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.049e-01, with an active set of 231 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,916:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=9.764e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,917:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=9.584e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,918:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=8.584e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,919:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=8.476e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,919:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=8.292e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,919:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=8.056e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,919:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=7.849e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,921:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=7.476e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,921:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=7.188e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,921:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=7.167e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,921:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=6.092e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,922:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 289 iterations, i.e. alpha=5.732e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,922:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 289 iterations, i.e. alpha=5.079e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,922:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 289 iterations, i.e. alpha=4.730e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,922:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 289 iterations, i.e. alpha=4.618e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,923:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 289 iterations, i.e. alpha=4.617e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,923:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 289 iterations, i.e. alpha=4.052e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,923:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.734e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,924:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.440e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,925:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.078e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,926:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.904e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,926:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.726e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,926:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.714e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,926:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.669e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,927:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.594e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,927:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.449e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,927:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.400e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,928:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.109e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,928:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.811e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,928:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.806e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,928:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.667e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,928:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.515e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,929:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.262e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,929:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=1.100e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,930:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=1.088e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,930:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=1.019e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,930:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=1.017e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,931:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.174e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,931:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=9.700e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,932:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=9.026e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,932:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=8.726e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,932:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=7.465e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,933:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=7.323e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,933:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=7.155e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,933:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=6.529e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,933:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=6.344e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,933:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=5.527e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,934:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=5.011e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,934:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=4.394e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,934:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=3.922e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,935:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=3.866e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,935:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=3.406e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,935:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.979e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,935:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.895e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,935:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.348e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,936:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.252e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,936:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.054e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,936:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.883e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,937:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.634e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,937:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.633e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,937:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.581e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,938:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.576e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,938:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.558e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,939:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.508e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,939:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.322e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,939:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.281e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,940:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=8.564e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,940:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=7.454e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,940:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=7.339e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,940:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=4.036e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,941:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=3.006e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,941:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.810e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,941:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.154e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,942:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=8.807e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,942:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=4.368e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:52,988:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:07:53,001:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=6.046e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,029:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=1.656e-01, with an active set of 142 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,038:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=1.145e-01, with an active set of 167 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,040:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=1.110e-01, with an active set of 172 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,043:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 191 iterations, i.e. alpha=9.627e-02, with an active set of 182 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,043:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 192 iterations, i.e. alpha=8.835e-02, with an active set of 183 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,045:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=8.504e-02, with an active set of 186 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,046:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 199 iterations, i.e. alpha=8.268e-02, with an active set of 188 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,047:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 200 iterations, i.e. alpha=8.208e-02, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,050:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=8.010e-02, with an active set of 195 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,050:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=7.485e-02, with an active set of 195 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,050:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=7.321e-02, with an active set of 195 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,051:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=7.107e-02, with an active set of 196 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,051:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=7.071e-02, with an active set of 196 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,063:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=1.621e+01, with an active set of 210 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,066:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=1.557e+01, with an active set of 215 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,069:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=1.435e+01, with an active set of 218 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,070:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=1.432e+01, with an active set of 218 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,070:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=1.327e+01, with an active set of 218 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,070:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=1.238e+01, with an active set of 218 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,070:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=1.208e+01, with an active set of 218 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,081:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=4.542e+04, with an active set of 225 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,082:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=4.100e+04, with an active set of 225 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,082:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=3.774e+04, with an active set of 226 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,085:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.261e+04, with an active set of 229 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,085:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.102e+04, with an active set of 229 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,085:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.795e+04, with an active set of 229 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,085:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.749e+04, with an active set of 229 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,085:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.700e+04, with an active set of 229 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,085:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.489e+04, with an active set of 229 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,088:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 297 iterations, i.e. alpha=2.599e+04, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,088:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 298 iterations, i.e. alpha=2.527e+04, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,089:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 298 iterations, i.e. alpha=2.472e+04, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,089:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 298 iterations, i.e. alpha=2.426e+04, with an active set of 233 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,089:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 298 iterations, i.e. alpha=2.386e+04, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,089:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 298 iterations, i.e. alpha=2.299e+04, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:07:53,127:WARNING:
2023-06-26 05:07:53,128:WARNING:
2023-06-26 05:07:53,128:WARNING:Processing:  17%|#######2                                  | 14/81 [01:09<04:10,  3.73s/it]
2023-06-26 05:07:53,129:WARNING:[A[A
2023-06-26 05:07:53,129:INFO:Uploading results into container
2023-06-26 05:07:53,130:INFO:Uploading model into container now
2023-06-26 05:07:53,131:INFO:_master_model_container: 3
2023-06-26 05:07:53,131:INFO:_display_container: 2
2023-06-26 05:07:53,132:INFO:Ridge(random_state=5040)
2023-06-26 05:07:53,132:INFO:create_model() successfully completed......................................
2023-06-26 05:07:53,334:INFO:SubProcess create_model() end ==================================
2023-06-26 05:07:53,334:INFO:Creating metrics dataframe
2023-06-26 05:07:53,338:INFO:Initializing Elastic Net
2023-06-26 05:07:53,338:INFO:Total runtime is 1.1687328974405924 minutes
2023-06-26 05:07:53,339:INFO:SubProcess create_model() called ==================================
2023-06-26 05:07:53,339:INFO:Initializing create_model()
2023-06-26 05:07:53,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BAAF63E0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BD66AE00>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:07:53,340:INFO:Checking exceptions
2023-06-26 05:07:53,340:INFO:Importing libraries
2023-06-26 05:07:53,340:INFO:Copying training dataset
2023-06-26 05:07:53,369:WARNING:
2023-06-26 05:07:53,369:WARNING:
2023-06-26 05:07:53,369:WARNING:Processing:  19%|#######7                                  | 15/81 [01:10<03:10,  2.88s/it]
2023-06-26 05:07:53,370:WARNING:[A[A
2023-06-26 05:07:53,370:INFO:Defining folds
2023-06-26 05:07:53,370:INFO:Declaring metric variables
2023-06-26 05:07:53,370:INFO:Importing untrained model
2023-06-26 05:07:53,370:INFO:Elastic Net Imported successfully
2023-06-26 05:07:53,372:INFO:Starting cross validation
2023-06-26 05:07:53,383:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:07:59,383:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.954e+06, tolerance: 1.636e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:59,463:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.271e+06, tolerance: 1.620e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:59,481:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.229e+06, tolerance: 1.675e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:59,624:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.490e+06, tolerance: 1.644e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:59,634:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.151e+06, tolerance: 1.666e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:07:59,653:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.720e+06, tolerance: 1.657e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:08:00,399:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:08:00,413:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:08:00,718:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:08:00,937:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.473e+06, tolerance: 1.663e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:08:00,998:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.715e+06, tolerance: 1.648e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:08:01,049:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.192e+06, tolerance: 1.648e+04
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:08:01,454:INFO:Calculating mean and std
2023-06-26 05:08:01,467:INFO:Creating metrics dataframe
2023-06-26 05:08:08,400:INFO:Uploading results into container
2023-06-26 05:08:08,401:INFO:Uploading model into container now
2023-06-26 05:08:08,402:INFO:_master_model_container: 5
2023-06-26 05:08:08,402:INFO:_display_container: 2
2023-06-26 05:08:08,404:INFO:Lars(random_state=4661)
2023-06-26 05:08:08,405:INFO:create_model() successfully completed......................................
2023-06-26 05:08:08,589:INFO:SubProcess create_model() end ==================================
2023-06-26 05:08:08,590:INFO:Creating metrics dataframe
2023-06-26 05:08:08,592:INFO:Initializing Lasso Least Angle Regression
2023-06-26 05:08:08,593:INFO:Total runtime is 1.899522630373637 minutes
2023-06-26 05:08:08,593:INFO:SubProcess create_model() called ==================================
2023-06-26 05:08:08,593:INFO:Initializing create_model()
2023-06-26 05:08:08,593:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9C4C8E290>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:08:08,593:INFO:Checking exceptions
2023-06-26 05:08:08,593:INFO:Importing libraries
2023-06-26 05:08:08,593:INFO:Copying training dataset
2023-06-26 05:08:08,625:INFO:Defining folds
2023-06-26 05:08:08,635:INFO:Declaring metric variables
2023-06-26 05:08:08,635:INFO:Importing untrained model
2023-06-26 05:08:08,636:INFO:Lasso Least Angle Regression Imported successfully
2023-06-26 05:08:08,637:INFO:Starting cross validation
2023-06-26 05:08:08,658:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:08:11,142:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:08:11,174:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:08:11,190:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:08:11,287:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:08:11,371:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:08:11,415:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:08:12,145:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:08:12,190:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:08:12,261:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:08:12,425:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:08:35,221:WARNING:C:\New folder\lib\site-packages\pandas_profiling\model\correlations.py:67: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/pandas-profiling/issues
(include the error message: 'No data; `observed` has size 0.')
  warnings.warn(

2023-06-26 05:08:36,716:INFO:Calculating mean and std
2023-06-26 05:08:36,718:WARNING:
2023-06-26 05:08:36,718:WARNING:
2023-06-26 05:08:36,719:WARNING:Processing:  21%|########8                                 | 17/81 [01:53<11:19, 10.61s/it]
2023-06-26 05:08:36,719:WARNING:[A[A
2023-06-26 05:08:36,719:INFO:Creating metrics dataframe
2023-06-26 05:08:39,220:WARNING:
2023-06-26 05:08:39,220:WARNING:
2023-06-26 05:08:39,220:WARNING:Processing:  22%|#########3                                | 18/81 [01:56<09:12,  8.77s/it]
2023-06-26 05:08:39,221:WARNING:[A[A
2023-06-26 05:08:39,221:INFO:Uploading results into container
2023-06-26 05:08:39,245:INFO:Uploading model into container now
2023-06-26 05:08:39,246:INFO:_master_model_container: 4
2023-06-26 05:08:39,246:INFO:_display_container: 2
2023-06-26 05:08:39,246:INFO:ElasticNet(random_state=5040)
2023-06-26 05:08:39,247:INFO:create_model() successfully completed......................................
2023-06-26 05:08:39,442:INFO:SubProcess create_model() end ==================================
2023-06-26 05:08:39,443:INFO:Creating metrics dataframe
2023-06-26 05:08:39,446:INFO:Initializing Least Angle Regression
2023-06-26 05:08:39,447:INFO:Total runtime is 1.9372262199719747 minutes
2023-06-26 05:08:39,448:INFO:SubProcess create_model() called ==================================
2023-06-26 05:08:39,448:INFO:Initializing create_model()
2023-06-26 05:08:39,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BAAF63E0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BD66AE00>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:08:39,449:INFO:Checking exceptions
2023-06-26 05:08:39,449:INFO:Importing libraries
2023-06-26 05:08:39,449:INFO:Copying training dataset
2023-06-26 05:08:39,494:WARNING:
2023-06-26 05:08:39,494:WARNING:
2023-06-26 05:08:39,494:WARNING:Processing:  23%|#########8                                | 19/81 [01:56<06:54,  6.69s/it]
2023-06-26 05:08:39,494:WARNING:[A[A
2023-06-26 05:08:39,494:INFO:Defining folds
2023-06-26 05:08:39,494:INFO:Declaring metric variables
2023-06-26 05:08:39,495:INFO:Importing untrained model
2023-06-26 05:08:39,495:INFO:Least Angle Regression Imported successfully
2023-06-26 05:08:39,495:INFO:Starting cross validation
2023-06-26 05:08:39,540:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:08:42,504:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:08:42,520:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=6.873e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,526:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=4.646e-01, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,559:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:08:42,575:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.773e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,577:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:08:42,581:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=5.622e-01, with an active set of 169 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,592:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:08:42,602:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.807e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,603:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:08:42,615:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.262e-01, with an active set of 122 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,616:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=4.347e-01, with an active set of 61 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,618:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 216 iterations, i.e. alpha=4.706e-01, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,621:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:08:42,622:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 222 iterations, i.e. alpha=4.618e-01, with an active set of 189 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,625:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=4.377e-01, with an active set of 194 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,627:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=4.052e-01, with an active set of 196 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,627:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=2.964e-01, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,629:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=3.716e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,629:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=3.639e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,632:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=3.598e-01, with an active set of 203 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,632:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=3.160e-01, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,633:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=3.452e-01, with an active set of 203 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,633:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=1.363e-01, with an active set of 167 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,633:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=3.392e-01, with an active set of 203 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,635:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=3.245e-01, with an active set of 205 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,638:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=2.805e-01, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,638:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=2.805e-01, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,639:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=3.073e-01, with an active set of 211 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,644:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=3.055e-01, with an active set of 218 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,645:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=2.673e-01, with an active set of 220 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,646:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.549e-01, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,651:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.837e-01, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,653:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 189 iterations, i.e. alpha=1.272e-01, with an active set of 179 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,654:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=1.683e-01, with an active set of 146 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,656:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 162 iterations, i.e. alpha=1.484e-01, with an active set of 157 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,658:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.378e-01, with an active set of 158 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,645:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=2.662e-01, with an active set of 220 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,660:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=2.448e-01, with an active set of 220 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,660:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 201 iterations, i.e. alpha=1.493e-01, with an active set of 185 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,660:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=2.373e-01, with an active set of 220 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,661:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 201 iterations, i.e. alpha=1.305e-01, with an active set of 185 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,661:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.326e-01, with an active set of 166 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,662:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=2.337e-01, with an active set of 222 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,662:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=2.334e-01, with an active set of 222 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,663:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=2.216e-01, with an active set of 223 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,664:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 178 iterations, i.e. alpha=1.225e-01, with an active set of 169 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,664:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=2.140e-01, with an active set of 224 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,665:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=1.279e-01, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,666:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 183 iterations, i.e. alpha=1.170e-01, with an active set of 173 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,667:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=3.039e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,667:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=2.559e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,669:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.331e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,669:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=1.144e-01, with an active set of 174 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,669:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.263e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,670:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=1.687e-01, with an active set of 146 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,671:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 216 iterations, i.e. alpha=1.227e-01, with an active set of 196 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,671:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=2.172e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,672:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 189 iterations, i.e. alpha=1.107e-01, with an active set of 179 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,672:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 189 iterations, i.e. alpha=1.103e-01, with an active set of 179 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,672:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=2.000e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,672:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 189 iterations, i.e. alpha=1.046e-01, with an active set of 179 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,672:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.991e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,673:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.932e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,673:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.916e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,673:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.805e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,673:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.782e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,674:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.723e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,674:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.679e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,675:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=1.433e-01, with an active set of 183 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,677:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 224 iterations, i.e. alpha=1.187e-01, with an active set of 202 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,678:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 200 iterations, i.e. alpha=8.793e-02, with an active set of 187 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,679:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.670e-01, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,679:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 201 iterations, i.e. alpha=8.708e-02, with an active set of 188 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,679:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.637e-01, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,680:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.594e-01, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,680:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.441e-01, with an active set of 233 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,681:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.268e-01, with an active set of 164 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,681:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=8.341e-02, with an active set of 191 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,682:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=1.511e-01, with an active set of 234 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,682:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 205 iterations, i.e. alpha=8.227e-02, with an active set of 192 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,683:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=1.486e-01, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,683:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=1.409e-01, with an active set of 207 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,683:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=1.276e-01, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,683:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=8.083e-02, with an active set of 193 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,683:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=1.149e-01, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,684:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=1.094e-01, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,685:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=1.091e-01, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,686:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=1.070e-01, with an active set of 234 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,687:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=7.598e-02, with an active set of 195 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,687:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=9.752e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,688:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=8.994e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,688:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=8.994e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,689:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=1.115e-01, with an active set of 197 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,689:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=8.321e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,689:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=1.327e-01, with an active set of 211 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,690:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 212 iterations, i.e. alpha=6.765e-02, with an active set of 198 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,690:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=1.199e+00, with an active set of 168 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,690:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 212 iterations, i.e. alpha=6.630e-02, with an active set of 198 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,690:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 212 iterations, i.e. alpha=6.407e-02, with an active set of 198 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,691:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=1.447e-01, with an active set of 212 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,691:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 212 iterations, i.e. alpha=6.297e-02, with an active set of 198 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,691:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=1.261e-01, with an active set of 212 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,692:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 213 iterations, i.e. alpha=6.241e-02, with an active set of 199 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,692:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=1.239e-01, with an active set of 213 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,692:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=1.239e-01, with an active set of 213 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,693:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 183 iterations, i.e. alpha=6.310e-01, with an active set of 171 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,693:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 214 iterations, i.e. alpha=6.094e-02, with an active set of 200 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,694:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 214 iterations, i.e. alpha=5.813e-02, with an active set of 200 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,694:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=1.168e-01, with an active set of 215 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,694:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=7.816e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,695:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=7.794e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,695:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=6.407e-01, with an active set of 173 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,696:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=6.067e-01, with an active set of 173 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,696:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 178 iterations, i.e. alpha=1.801e+00, with an active set of 146 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,697:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=7.405e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,697:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=1.135e-01, with an active set of 218 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,697:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=7.151e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,697:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=6.538e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,697:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=5.684e-02, with an active set of 204 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,698:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=6.470e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,698:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 251 iterations, i.e. alpha=1.130e-01, with an active set of 219 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,698:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=6.385e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,698:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=6.038e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,698:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 251 iterations, i.e. alpha=1.114e-01, with an active set of 219 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,699:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 251 iterations, i.e. alpha=1.094e-01, with an active set of 219 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,699:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 192 iterations, i.e. alpha=5.516e-01, with an active set of 177 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,699:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=5.241e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,699:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.848e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,699:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 222 iterations, i.e. alpha=6.461e-02, with an active set of 206 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,700:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 222 iterations, i.e. alpha=5.188e-02, with an active set of 206 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,700:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=5.455e-01, with an active set of 178 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,700:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 222 iterations, i.e. alpha=5.107e-02, with an active set of 206 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,703:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=5.227e-01, with an active set of 181 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,704:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=9.997e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,705:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=4.936e-02, with an active set of 209 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,705:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=1.755e+00, with an active set of 160 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,706:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 201 iterations, i.e. alpha=5.483e-01, with an active set of 183 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,706:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=9.914e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,706:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 202 iterations, i.e. alpha=5.005e-01, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,707:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=9.839e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,707:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=4.843e-02, with an active set of 212 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,707:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=4.836e-02, with an active set of 212 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,707:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=4.619e-01, with an active set of 185 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,708:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=4.762e-02, with an active set of 212 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,708:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=9.563e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,709:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=4.611e-02, with an active set of 213 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,709:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=9.506e-02, with an active set of 225 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,709:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=4.568e-02, with an active set of 213 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,709:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=4.460e-01, with an active set of 188 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,712:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=1.050e-01, with an active set of 215 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,712:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=4.411e-01, with an active set of 189 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,713:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=5.097e-02, with an active set of 216 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,714:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=4.951e-02, with an active set of 216 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,714:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=7.334e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 9.003e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,715:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=7.091e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,715:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=1.899e+00, with an active set of 169 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,716:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.431e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,716:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.189e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,717:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=4.403e-02, with an active set of 220 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,717:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.128e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,717:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=4.049e-02, with an active set of 220 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,717:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.115e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,718:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 212 iterations, i.e. alpha=1.798e+00, with an active set of 174 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,719:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 213 iterations, i.e. alpha=1.794e+00, with an active set of 175 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,719:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=8.195e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,719:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=8.306e+06, with an active set of 186 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,720:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=7.114e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,720:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=3.888e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,720:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=7.032e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,720:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=3.828e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,721:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=3.799e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,721:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=5.032e+06, with an active set of 188 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,721:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 216 iterations, i.e. alpha=1.775e+00, with an active set of 178 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,721:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=3.585e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,721:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=3.767e-02, with an active set of 220 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,722:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=3.431e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,722:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=3.421e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,722:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=3.111e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,722:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 231 iterations, i.e. alpha=4.436e+06, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,722:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=2.901e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,723:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=2.708e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,723:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=1.748e+00, with an active set of 181 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,723:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=2.666e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,723:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=2.270e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,723:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=9.187e-02, with an active set of 221 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,724:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.957e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,724:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.454e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,725:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=3.936e-02, with an active set of 221 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,725:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.299e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,725:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.202e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,726:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.140e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,726:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=7.560e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,726:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 214 iterations, i.e. alpha=4.226e-01, with an active set of 195 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,726:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=7.471e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,726:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=6.003e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,726:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=3.202e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,727:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=5.770e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,727:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=3.185e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,727:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=4.437e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,727:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=4.071e-01, with an active set of 196 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,727:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=3.153e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,727:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=3.886e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,727:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=3.030e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,727:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=4.066e-01, with an active set of 196 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,727:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=3.808e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,728:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=2.945e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,728:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=4.054e-01, with an active set of 196 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,728:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=3.798e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,728:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=4.324e+06, with an active set of 198 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,728:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=3.099e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,728:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=2.902e-02, with an active set of 223 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,729:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=2.976e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,729:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=2.679e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,729:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=2.347e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,729:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=2.346e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,730:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=2.300e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,730:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.992e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,730:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.606e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,730:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=3.898e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,730:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.595e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,731:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.547e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,731:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.490e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,731:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=3.838e-01, with an active set of 200 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,731:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.255e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,732:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.176e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,732:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=2.714e-02, with an active set of 226 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,732:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=8.963e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,732:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=1.014e+07, with an active set of 202 regressors, and the smallest cholesky pivot element being 9.828e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,732:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=2.459e-02, with an active set of 226 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,732:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=2.445e-02, with an active set of 226 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,732:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=8.167e+06, with an active set of 202 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,733:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=3.607e-01, with an active set of 202 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,733:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=5.376e+06, with an active set of 203 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,733:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=2.321e-02, with an active set of 227 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,734:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=2.292e-02, with an active set of 227 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,734:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=2.268e-02, with an active set of 227 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,735:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 251 iterations, i.e. alpha=4.933e+06, with an active set of 204 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,736:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 251 iterations, i.e. alpha=4.900e+06, with an active set of 204 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,737:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=3.439e-01, with an active set of 207 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,737:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=1.611e+00, with an active set of 201 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,738:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=2.138e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,738:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.975e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,738:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.915e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,738:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.903e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,738:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 231 iterations, i.e. alpha=3.280e-01, with an active set of 209 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,739:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.854e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,739:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.710e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,739:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.608e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,740:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 233 iterations, i.e. alpha=3.219e-01, with an active set of 210 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,740:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=1.585e+00, with an active set of 204 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,740:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.602e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,741:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.571e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,741:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.482e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,741:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.460e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,741:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.359e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,742:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.280e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,742:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.248e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,742:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=3.102e-01, with an active set of 213 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,742:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.238e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,743:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.197e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,743:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.140e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,743:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.104e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,743:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.055e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,743:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=8.726e+06, with an active set of 211 regressors, and the smallest cholesky pivot element being 9.828e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,744:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.053e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,744:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=9.480e-03, with an active set of 230 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,744:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=7.098e+06, with an active set of 211 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,744:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=3.054e-01, with an active set of 216 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,744:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=8.256e-03, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,744:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=5.960e+06, with an active set of 211 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,744:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=7.514e-03, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,744:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=2.925e-01, with an active set of 216 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,744:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=6.851e-03, with an active set of 230 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,745:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=2.729e-01, with an active set of 216 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,745:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=6.079e-03, with an active set of 230 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,745:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=6.029e-03, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,745:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=5.644e+06, with an active set of 212 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,745:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=5.870e-03, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,745:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=5.340e+06, with an active set of 212 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,746:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=2.617e-01, with an active set of 217 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,746:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.507e+00, with an active set of 210 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,747:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=4.837e-03, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,747:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=4.657e-03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,747:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=2.523e-01, with an active set of 219 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,747:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=3.382e-03, with an active set of 231 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,748:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=2.976e-03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,748:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=1.938e-03, with an active set of 231 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,748:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=5.251e+06, with an active set of 216 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,748:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=2.328e-01, with an active set of 220 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,748:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=1.929e-03, with an active set of 231 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,748:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=1.650e-03, with an active set of 231 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,748:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=2.265e-01, with an active set of 220 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,749:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=1.618e-03, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,749:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=1.606e-03, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,749:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=1.582e-03, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,749:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=1.507e-03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,749:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=2.223e-01, with an active set of 221 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,750:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=1.178e-03, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,750:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=1.001e-03, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,750:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=2.128e-01, with an active set of 221 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,750:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=9.394e-04, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,750:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=5.159e+06, with an active set of 217 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,750:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=2.084e-01, with an active set of 221 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,750:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=9.112e-04, with an active set of 231 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,750:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=2.057e-01, with an active set of 221 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,750:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=9.032e-04, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,751:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=2.033e-01, with an active set of 221 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,751:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=7.481e-04, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,751:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=4.963e+06, with an active set of 218 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,751:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=7.394e-04, with an active set of 231 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,752:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=7.128e-04, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,752:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=6.654e-04, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,753:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=6.304e-01, with an active set of 222 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,753:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=3.391e-01, with an active set of 222 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,754:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=4.931e+06, with an active set of 220 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,754:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=6.569e-04, with an active set of 232 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,754:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=2.068e-01, with an active set of 223 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,754:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=5.977e-04, with an active set of 232 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,754:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=1.304e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,755:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=1.971e-01, with an active set of 223 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,755:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=5.607e-04, with an active set of 232 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,755:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=1.912e-01, with an active set of 223 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,755:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=4.742e+06, with an active set of 222 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,755:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=1.897e-01, with an active set of 223 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,756:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=5.250e-04, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,756:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=1.584e+01, with an active set of 213 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,756:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=4.093e-04, with an active set of 233 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,756:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=1.298e+01, with an active set of 213 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,756:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=3.510e-04, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,757:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=2.903e-04, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,757:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=9.323e+00, with an active set of 213 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,757:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=1.888e-01, with an active set of 225 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,757:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=2.549e-04, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,757:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=9.292e+00, with an active set of 213 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,757:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=6.253e+06, with an active set of 223 regressors, and the smallest cholesky pivot element being 9.828e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,757:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=1.782e-01, with an active set of 225 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,757:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=9.154e+00, with an active set of 213 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,757:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=2.283e-04, with an active set of 233 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,757:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=1.716e-01, with an active set of 225 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,758:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=1.966e-04, with an active set of 233 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,759:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.661e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,759:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=8.361e+00, with an active set of 215 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,759:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=4.606e+03, with an active set of 232 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,759:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.585e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,760:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.578e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,760:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=2.710e+03, with an active set of 232 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,760:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.551e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,760:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=2.307e+03, with an active set of 232 regressors, and the smallest cholesky pivot element being 9.003e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,760:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.442e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,760:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=2.066e+03, with an active set of 232 regressors, and the smallest cholesky pivot element being 8.229e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,761:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=8.294e+00, with an active set of 217 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,761:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.335e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,761:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 289 iterations, i.e. alpha=1.851e+03, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,761:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=7.964e+00, with an active set of 217 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,761:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.320e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,762:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 289 iterations, i.e. alpha=1.589e+03, with an active set of 233 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,762:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=7.754e+00, with an active set of 217 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,762:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.266e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,762:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.208e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,762:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=7.697e+00, with an active set of 217 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,762:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.128e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,762:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.521e+03, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,763:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=7.669e+00, with an active set of 217 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,763:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.064e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,763:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.519e+03, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,763:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.509e+03, with an active set of 234 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,763:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.052e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,763:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.026e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,764:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=1.022e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,764:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=1.422e+03, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,764:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=8.738e-02, with an active set of 227 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,765:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=8.294e-02, with an active set of 227 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,765:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=4.036e+08, with an active set of 225 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,765:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=1.277e+03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,765:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=1.256e+03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,765:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=3.102e+08, with an active set of 225 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,765:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=7.394e+00, with an active set of 220 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,766:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.975e+08, with an active set of 225 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,766:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=7.197e+00, with an active set of 220 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,766:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=8.192e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,766:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.960e+08, with an active set of 225 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,766:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.179e+03, with an active set of 237 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,766:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=7.601e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,766:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.910e+08, with an active set of 225 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,766:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.052e+03, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,767:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.008e+03, with an active set of 237 regressors, and the smallest cholesky pivot element being 8.229e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,767:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=6.743e+00, with an active set of 221 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,767:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=9.996e+02, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,767:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=5.736e+00, with an active set of 221 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,767:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=8.986e+02, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,768:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=8.624e+02, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,768:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 299 iterations, i.e. alpha=1.741e+08, with an active set of 227 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,769:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=7.495e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,769:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=7.413e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,769:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=2.105e-04, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,770:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=7.873e+02, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,770:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=6.563e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,770:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=1.866e-04, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,770:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=5.426e+00, with an active set of 224 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,770:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=7.854e+02, with an active set of 237 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,770:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=6.361e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,770:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=1.845e-04, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,770:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 301 iterations, i.e. alpha=1.863e+08, with an active set of 228 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,771:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=7.587e+02, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,771:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 301 iterations, i.e. alpha=1.705e+08, with an active set of 228 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,771:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=7.421e+02, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,771:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=6.806e+02, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,771:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 301 iterations, i.e. alpha=1.612e+08, with an active set of 228 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,771:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.694e-04, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,771:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=5.189e+00, with an active set of 225 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,771:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=6.218e+02, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,771:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 301 iterations, i.e. alpha=1.555e+08, with an active set of 228 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,771:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.587e-04, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,772:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=5.936e+02, with an active set of 237 regressors, and the smallest cholesky pivot element being 9.246e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,772:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=5.175e+00, with an active set of 225 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,772:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.531e-04, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,772:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 301 iterations, i.e. alpha=1.299e+08, with an active set of 228 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,772:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.514e-04, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,772:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=5.202e+02, with an active set of 237 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,773:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.312e-04, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,773:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=5.850e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,773:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=4.959e+00, with an active set of 225 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,773:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.268e-04, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,773:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=5.845e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,773:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=4.901e+00, with an active set of 225 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,773:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.138e-04, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,773:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.028e-04, with an active set of 235 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,773:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=4.885e+00, with an active set of 225 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,774:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=8.742e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,774:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=4.324e+02, with an active set of 238 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,774:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=6.955e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,774:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=4.075e+02, with an active set of 238 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,774:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=6.863e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,774:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=1.161e+08, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,774:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=4.807e+00, with an active set of 226 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,774:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=6.648e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,775:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=1.159e+08, with an active set of 229 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,775:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=3.032e+02, with an active set of 238 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,775:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=4.743e+00, with an active set of 226 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,775:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=6.246e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,775:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.941e+02, with an active set of 238 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,775:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=1.038e+08, with an active set of 229 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,775:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=4.629e+00, with an active set of 226 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,775:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=5.139e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,775:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=9.797e+07, with an active set of 229 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,775:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=4.548e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,775:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=5.123e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,775:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=9.684e+07, with an active set of 229 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,776:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=3.811e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,776:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=9.054e+07, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,776:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=3.240e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,776:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=2.577e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,776:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.391e+00, with an active set of 227 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,776:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=2.311e+02, with an active set of 240 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,776:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=4.993e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=2.050e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=8.040e+07, with an active set of 229 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=2.215e+02, with an active set of 240 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.340e+00, with an active set of 227 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=4.831e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.973e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=7.863e+07, with an active set of 229 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.952e+02, with an active set of 240 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.749e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.219e+00, with an active set of 227 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=7.810e+07, with an active set of 229 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.817e+02, with an active set of 240 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.516e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=7.504e+07, with an active set of 229 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.155e+02, with an active set of 240 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,778:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.430e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,778:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=7.367e+07, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,778:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.153e+02, with an active set of 240 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,778:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.377e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,778:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=7.292e+07, with an active set of 229 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,778:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=8.146e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,778:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.340e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,778:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.261e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,778:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=3.952e+00, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,779:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=7.595e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 9.246e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,779:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=3.873e+00, with an active set of 228 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,779:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=4.580e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,779:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.058e-05, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,779:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=3.834e+00, with an active set of 228 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,779:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=4.351e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,779:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=9.229e-06, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,779:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=4.774e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,779:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 306 iterations, i.e. alpha=6.906e+07, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,780:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=8.253e-06, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,780:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=4.770e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,780:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=7.893e-06, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,780:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 306 iterations, i.e. alpha=6.759e+07, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,780:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=4.050e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,780:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=4.321e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,780:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=7.433e-06, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,781:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=3.957e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,781:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=5.772e-06, with an active set of 235 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,781:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.718e+00, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,781:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=3.913e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,781:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=3.570e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,781:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.270e+00, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,781:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=6.712e+07, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,781:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=3.599e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,781:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=3.548e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,781:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=3.519e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,781:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=5.706e+07, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,782:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=3.474e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,782:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=9.048e-07, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,782:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=5.170e+07, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,782:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=3.491e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,782:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=3.448e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,782:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=3.228e+00, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,782:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=4.939e+07, with an active set of 231 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,782:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=3.085e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,782:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=3.016e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,782:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=4.824e+07, with an active set of 231 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,782:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.792e+00, with an active set of 231 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,783:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=2.486e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,783:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=2.336e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,783:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=2.352e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,783:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=4.191e+07, with an active set of 231 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,783:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.569e+00, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,783:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=2.229e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,783:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=2.276e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,783:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=2.072e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,783:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=2.095e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 9.246e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,783:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.484e+00, with an active set of 231 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,783:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.816e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 9.246e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,783:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.966e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,783:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=3.638e+07, with an active set of 231 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,784:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.473e+00, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,784:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.461e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,784:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.864e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,784:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=3.618e+07, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,784:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.454e+00, with an active set of 231 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,784:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=3.194e+07, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,785:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=2.992e+07, with an active set of 231 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,785:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.243e+00, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,784:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.804e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,785:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.117e+00, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,785:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.732e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,786:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.693e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,786:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.678e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,786:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 310 iterations, i.e. alpha=2.336e+07, with an active set of 232 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,787:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.668e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,787:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 310 iterations, i.e. alpha=2.315e+07, with an active set of 232 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,787:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.749e+00, with an active set of 232 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,787:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.114e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,787:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.033e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,787:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.707e+00, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,788:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=9.516e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,788:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.605e+00, with an active set of 232 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,788:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=2.681e+07, with an active set of 233 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,789:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=8.846e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,789:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=2.113e+07, with an active set of 233 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,789:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=8.519e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,789:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 289 iterations, i.e. alpha=1.590e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 9.599e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,789:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=2.072e+07, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,789:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=8.236e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,789:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=2.017e+07, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,789:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 289 iterations, i.e. alpha=1.506e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,790:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=6.849e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,790:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=1.871e+07, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,790:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 289 iterations, i.e. alpha=1.374e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,790:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=6.556e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,790:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.129e+01, with an active set of 240 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,790:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=1.733e+07, with an active set of 233 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,790:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 289 iterations, i.e. alpha=1.209e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,790:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=6.287e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,791:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=5.939e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,791:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=8.000e+00, with an active set of 240 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,791:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 289 iterations, i.e. alpha=1.160e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,791:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=5.527e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,791:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=1.659e+07, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,791:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 289 iterations, i.e. alpha=1.159e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,791:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=6.705e+00, with an active set of 240 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,791:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=1.337e+07, with an active set of 233 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,792:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=3.669e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,792:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=1.004e+07, with an active set of 233 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,792:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=3.598e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,792:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 289 iterations, i.e. alpha=1.124e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,792:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=9.290e+06, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,792:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=3.483e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,792:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=8.908e+06, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,792:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=2.917e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,793:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=8.686e+06, with an active set of 233 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,793:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=7.524e+06, with an active set of 233 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,793:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=7.446e+06, with an active set of 233 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,793:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=2.152e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,793:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.096e+00, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,794:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=6.724e+06, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,794:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.747e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,794:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=6.699e+06, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,794:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=8.643e-01, with an active set of 234 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,794:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.592e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,794:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=6.378e+06, with an active set of 233 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,794:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=8.529e-01, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,794:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.553e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,794:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=5.609e+06, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,795:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=8.204e-01, with an active set of 234 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,795:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.188e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,795:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=5.606e+06, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,795:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.012e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,795:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=5.170e+06, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,795:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=8.367e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,795:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=5.056e+06, with an active set of 233 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,796:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=3.444e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,796:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=7.940e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,796:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=4.908e+06, with an active set of 233 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,796:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=2.462e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,796:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=4.732e+06, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,796:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=7.657e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,796:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.946e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,796:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=7.528e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,796:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.878e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,797:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.488e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,797:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=6.141e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,797:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.434e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,797:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=5.787e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,797:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.315e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,797:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=5.769e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,798:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.312e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,798:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=5.400e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,798:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.311e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,798:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.150e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,799:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.144e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,799:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=5.250e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,799:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.107e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,799:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.079e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,799:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=5.050e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,799:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.038e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,800:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=4.603e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,800:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=9.690e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,800:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=8.850e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,800:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=4.224e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,800:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=8.329e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,800:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=4.205e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,801:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=7.960e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,801:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=4.093e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,801:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=4.058e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,801:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=7.777e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,802:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=3.415e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,802:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=7.614e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,802:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=3.363e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 9.599e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,803:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=7.453e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,803:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=2.892e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,803:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=7.095e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,803:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=2.170e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,802:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=6.650e+00, with an active set of 240 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,804:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=2.060e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,804:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=6.345e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,804:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=1.812e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,804:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=6.229e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,804:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=1.660e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,804:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=5.766e+00, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,805:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=5.191e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,805:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=1.309e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,805:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=3.461e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,805:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=1.042e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,805:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.473e+00, with an active set of 240 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,805:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=3.201e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,806:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=2.769e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,806:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=9.985e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,806:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=2.087e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,806:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=9.962e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,806:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=9.080e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,807:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=9.001e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,807:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=8.834e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,808:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=6.650e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,808:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=6.432e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,808:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=6.323e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,809:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=6.175e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,809:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=5.469e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,809:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=3.993e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,809:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=3.933e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,810:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=2.673e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,811:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=3.025e-02, with an active set of 237 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,812:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.396e-02, with an active set of 237 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,812:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.352e-02, with an active set of 237 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,813:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=2.231e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,814:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=2.170e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,814:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.950e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,814:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.869e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,814:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.816e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,815:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.762e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,815:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.469e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,815:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.312e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,816:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.311e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,816:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.249e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,816:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.224e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,817:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.165e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,817:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.107e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,818:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.097e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,818:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.096e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,819:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.024e-02, with an active set of 238 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,819:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=9.498e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,819:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=7.200e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,820:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=6.459e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,820:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=6.424e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,821:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=6.291e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,821:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=5.119e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,822:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=4.964e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,822:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=4.632e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,823:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=4.454e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,823:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=4.214e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,823:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=4.050e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,823:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=3.871e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,824:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=3.220e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,824:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.220e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,824:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.141e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,825:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.033e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,825:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=1.013e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,825:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=8.777e-04, with an active set of 238 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:42,825:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=7.224e-05, with an active set of 238 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,401:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:08:44,413:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=7.186e-01, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,416:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=5.778e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,435:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.371e-01, with an active set of 118 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,437:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=2.254e-01, with an active set of 122 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,441:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.819e-01, with an active set of 135 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,453:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.142e-01, with an active set of 171 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,456:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=1.018e-01, with an active set of 178 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,460:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 198 iterations, i.e. alpha=9.124e-02, with an active set of 188 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,463:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=7.986e-02, with an active set of 194 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,464:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=7.323e-02, with an active set of 196 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,465:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=7.426e-02, with an active set of 197 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,470:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 222 iterations, i.e. alpha=6.117e-02, with an active set of 206 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,471:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=6.055e-02, with an active set of 207 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,473:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 231 iterations, i.e. alpha=5.257e-02, with an active set of 212 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,475:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=5.734e-02, with an active set of 214 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,475:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=5.408e-02, with an active set of 214 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,475:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=4.740e-02, with an active set of 214 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,475:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=4.699e-02, with an active set of 214 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,476:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=4.568e-02, with an active set of 214 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,476:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=4.532e-02, with an active set of 215 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,477:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=4.413e-02, with an active set of 216 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,478:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=4.148e-02, with an active set of 219 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,479:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=3.989e-02, with an active set of 219 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,479:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=3.983e-02, with an active set of 219 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,481:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=4.348e-02, with an active set of 221 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,481:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=4.315e-02, with an active set of 221 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,482:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=3.990e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,482:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=3.900e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,482:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=3.796e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,485:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 251 iterations, i.e. alpha=3.616e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,485:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 251 iterations, i.e. alpha=2.926e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,486:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=3.167e-02, with an active set of 225 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,487:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=2.988e-02, with an active set of 225 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,487:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=2.564e-02, with an active set of 225 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,487:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=2.469e-02, with an active set of 225 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,488:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=2.219e-02, with an active set of 226 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,488:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=2.073e-02, with an active set of 226 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,489:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=1.743e-02, with an active set of 227 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,490:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=1.644e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,490:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=1.632e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,491:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=1.623e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,491:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=1.504e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,492:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.581e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,492:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.465e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,492:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.393e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,493:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.183e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,494:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.163e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,494:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.117e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,495:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.112e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,496:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.110e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,496:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.086e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,497:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.058e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,497:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.033e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,497:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=9.944e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,497:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=9.566e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,497:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=9.312e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,498:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=9.137e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,498:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=8.703e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,498:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=8.385e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,498:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=7.557e-03, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,499:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=6.010e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,499:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=5.761e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,500:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=4.926e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,503:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=4.697e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,503:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=4.674e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,503:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=4.663e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,504:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=4.184e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,504:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=3.692e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,504:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=3.598e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,504:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=3.067e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,504:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=2.724e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,505:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=2.419e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,506:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=2.395e-03, with an active set of 238 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,506:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=2.263e-03, with an active set of 239 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,506:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=2.074e-03, with an active set of 239 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,507:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.902e-03, with an active set of 239 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,507:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.668e-03, with an active set of 239 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,507:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.114e-03, with an active set of 239 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,507:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.052e-03, with an active set of 239 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,508:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.002e-03, with an active set of 239 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,508:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=9.310e-04, with an active set of 239 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,509:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=7.405e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,509:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=6.118e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,509:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=5.780e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,510:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=5.409e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,510:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=5.117e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,510:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=5.092e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,510:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=4.318e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,510:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=3.655e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,511:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=3.546e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,511:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=3.172e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,511:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=3.022e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,511:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.584e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,511:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.560e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,512:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.425e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,512:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.311e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,512:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.207e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,512:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.900e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,512:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.893e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,513:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.750e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,513:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.663e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,513:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.562e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,513:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.396e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,514:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.375e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,514:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.226e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,514:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.044e-04, with an active set of 240 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,514:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=9.955e-05, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,514:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=8.635e-05, with an active set of 240 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,514:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=8.482e-05, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,515:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=7.681e-05, with an active set of 240 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,515:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=3.307e-05, with an active set of 240 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,515:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.878e-05, with an active set of 240 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,515:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.559e-05, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,515:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=3.198e-06, with an active set of 240 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,531:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:08:44,539:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:08:44,544:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=6.352e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,551:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=6.698e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,555:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.132e-01, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,567:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=3.236e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,581:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.454e-01, with an active set of 147 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,584:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.106e-01, with an active set of 154 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,585:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=3.095e-01, with an active set of 155 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,589:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 183 iterations, i.e. alpha=3.451e-01, with an active set of 163 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,589:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=2.926e-01, with an active set of 166 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,594:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=2.596e-01, with an active set of 178 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,594:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 195 iterations, i.e. alpha=3.154e-01, with an active set of 174 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,595:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=3.077e-01, with an active set of 175 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,595:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 212 iterations, i.e. alpha=2.508e-01, with an active set of 180 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,596:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 213 iterations, i.e. alpha=2.484e-01, with an active set of 181 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,597:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 201 iterations, i.e. alpha=2.986e-01, with an active set of 179 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,597:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 201 iterations, i.e. alpha=2.932e-01, with an active set of 179 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,598:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=2.378e-01, with an active set of 187 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,599:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=2.315e-01, with an active set of 189 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,599:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 222 iterations, i.e. alpha=2.291e-01, with an active set of 190 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,601:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 226 iterations, i.e. alpha=2.060e-01, with an active set of 194 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,601:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 226 iterations, i.e. alpha=1.984e-01, with an active set of 194 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,603:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=3.318e-01, with an active set of 191 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,603:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=1.777e-01, with an active set of 196 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,603:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=3.183e-01, with an active set of 191 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,604:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=1.736e-01, with an active set of 196 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,605:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 231 iterations, i.e. alpha=1.620e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,605:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=1.551e-01, with an active set of 200 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,608:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=4.060e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,608:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=3.791e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,608:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=3.622e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,608:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=1.350e-01, with an active set of 205 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,609:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=1.340e-01, with an active set of 205 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,609:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 238 iterations, i.e. alpha=1.256e-01, with an active set of 206 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,610:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=1.210e-01, with an active set of 207 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,610:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=3.553e-01, with an active set of 203 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,611:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=1.171e-01, with an active set of 210 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,612:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=1.148e-01, with an active set of 210 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,612:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=1.129e-01, with an active set of 211 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,612:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=3.408e-01, with an active set of 207 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,612:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=3.372e-01, with an active set of 207 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,613:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=3.308e-01, with an active set of 207 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,613:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=3.145e-01, with an active set of 207 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,613:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=1.097e-01, with an active set of 212 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,613:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=3.094e-01, with an active set of 207 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,613:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=1.063e-01, with an active set of 212 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,613:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=3.074e-01, with an active set of 207 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,614:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=3.030e-01, with an active set of 208 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,615:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=2.931e-01, with an active set of 209 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,615:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=1.023e-01, with an active set of 216 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,616:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=1.013e-01, with an active set of 216 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,617:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=3.335e-01, with an active set of 211 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,617:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=3.226e-01, with an active set of 211 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,617:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=9.511e-02, with an active set of 218 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,618:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=3.041e-01, with an active set of 212 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,620:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=9.393e-02, with an active set of 220 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,620:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=8.365e-02, with an active set of 220 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,620:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=8.215e-02, with an active set of 220 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,620:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=8.157e-02, with an active set of 220 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,621:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=3.181e-01, with an active set of 215 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,621:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=3.167e-01, with an active set of 215 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,621:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=2.854e-01, with an active set of 215 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,621:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=7.126e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,622:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=6.488e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,622:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=6.456e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,622:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=6.309e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,623:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=6.226e-02, with an active set of 222 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,623:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=2.823e-01, with an active set of 219 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,624:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=2.690e-01, with an active set of 219 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,624:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=6.001e-02, with an active set of 224 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,625:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=2.971e-01, with an active set of 220 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,625:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=2.653e-01, with an active set of 220 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,625:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=6.430e-02, with an active set of 226 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,626:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=2.529e-01, with an active set of 221 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,626:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=2.476e-01, with an active set of 221 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,626:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=5.485e-02, with an active set of 227 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,626:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=2.461e-01, with an active set of 222 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,627:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=5.278e-02, with an active set of 227 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,627:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=5.074e-02, with an active set of 227 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,627:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=4.835e-02, with an active set of 227 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,627:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=2.290e-01, with an active set of 223 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,628:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=4.740e-02, with an active set of 228 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,628:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=2.030e-01, with an active set of 224 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,628:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=2.002e-01, with an active set of 224 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,629:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=4.680e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,629:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=4.671e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,629:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=2.345e-01, with an active set of 225 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,630:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=1.874e-01, with an active set of 225 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,630:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=1.828e-01, with an active set of 225 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,630:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=4.409e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,631:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.799e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,631:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.758e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,631:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.616e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,632:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 271 iterations, i.e. alpha=4.613e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,632:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=1.540e-01, with an active set of 228 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,633:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 271 iterations, i.e. alpha=4.586e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,634:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=3.288e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,634:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=3.182e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,634:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=3.065e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,634:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 271 iterations, i.e. alpha=1.535e-01, with an active set of 229 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,636:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=2.958e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,636:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.448e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,637:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.430e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,637:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.367e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,637:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.363e-01, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,638:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.347e-01, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,638:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.329e-01, with an active set of 231 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,639:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.301e-01, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,638:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=3.102e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,639:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.296e-01, with an active set of 231 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,639:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.743e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,639:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.208e-01, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,639:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.615e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,639:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.130e-01, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,639:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.110e-01, with an active set of 231 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,639:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.549e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,639:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.067e-01, with an active set of 231 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,640:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.324e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,640:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.314e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,640:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.295e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,640:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.288e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,640:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.034e-01, with an active set of 232 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,641:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.150e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,641:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.030e-01, with an active set of 232 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,641:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.115e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,641:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.020e-01, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,641:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.897e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,642:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=9.976e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,642:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=9.777e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,642:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=9.706e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,643:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=9.473e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,643:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=9.393e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,643:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=9.100e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,643:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=2.359e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,643:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=2.258e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,644:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=2.034e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,644:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=8.599e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,644:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.980e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,644:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=7.226e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,644:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.923e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,644:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=6.828e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,644:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=6.810e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,644:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.606e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,645:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=6.727e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,645:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.510e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,645:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=6.303e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,645:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.342e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,645:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=5.836e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,645:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.301e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,645:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=5.734e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,645:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=4.707e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,645:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.281e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,646:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=3.902e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,646:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.255e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,646:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=3.701e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,646:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.206e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,646:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=3.633e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,646:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.147e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,646:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=3.568e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,646:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.081e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,646:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=3.054e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,647:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=2.342e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,647:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=9.458e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,647:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=8.913e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,647:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=8.109e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,647:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=8.003e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,648:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=2.214e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,648:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=2.148e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,648:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=2.096e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,648:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.595e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,649:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.542e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,649:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.524e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,649:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.523e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,649:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.285e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,649:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.280e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,649:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=9.170e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,649:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.235e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,650:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.068e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,650:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=8.500e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,650:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=9.711e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,650:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=7.341e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,650:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=7.953e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,650:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=7.333e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,650:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=7.682e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,651:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=6.381e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,651:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=6.517e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,651:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=6.224e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,651:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=4.708e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,651:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=3.628e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,652:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=3.518e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,652:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=3.362e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,652:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=3.292e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,652:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=3.062e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,652:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=2.813e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,652:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=5.755e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,653:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=2.184e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,653:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.838e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,653:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.691e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,653:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=5.579e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,653:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.668e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,653:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=4.740e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,653:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.338e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,654:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.237e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,654:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=4.657e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,654:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.070e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,654:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=4.554e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,654:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.003e-03, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,654:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=4.364e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,654:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=8.066e-04, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,654:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=7.626e-04, with an active set of 235 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,654:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=4.319e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,655:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.391e-04, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,655:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=3.764e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,655:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=3.723e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,655:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=3.635e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,656:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=3.380e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,656:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=2.444e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,656:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=2.335e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,656:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=2.142e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,657:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=2.051e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,658:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=2.049e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,658:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=1.980e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,658:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=1.485e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,658:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=1.325e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,658:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=1.304e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,658:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=1.267e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,659:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=1.163e-03, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,659:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=9.749e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,659:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=8.912e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,659:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=8.708e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,659:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=6.796e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,660:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=6.576e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,660:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=2.965e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,660:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=2.632e-04, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,660:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=7.583e-05, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,660:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=3.598e-06, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:44,757:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:08:45,105:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:08:45,118:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=5.776e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,127:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=3.251e-01, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,143:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=2.503e-01, with an active set of 160 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,145:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=2.259e-01, with an active set of 168 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,147:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=2.259e-01, with an active set of 172 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,148:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 198 iterations, i.e. alpha=2.522e-01, with an active set of 175 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,149:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 200 iterations, i.e. alpha=2.334e-01, with an active set of 176 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,154:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 214 iterations, i.e. alpha=2.269e-01, with an active set of 185 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,155:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 216 iterations, i.e. alpha=2.169e-01, with an active set of 187 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,157:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 224 iterations, i.e. alpha=2.095e-01, with an active set of 193 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,158:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 226 iterations, i.e. alpha=2.072e-01, with an active set of 195 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,161:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=2.134e-01, with an active set of 204 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,163:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=1.937e-01, with an active set of 208 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,164:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=1.824e-01, with an active set of 210 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,166:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=1.784e-01, with an active set of 213 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,168:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.866e-01, with an active set of 216 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,190:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.843e-01, with an active set of 216 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,191:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=1.686e-01, with an active set of 219 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,192:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=1.638e-01, with an active set of 220 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,192:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=1.591e-01, with an active set of 220 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,192:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=1.531e-01, with an active set of 221 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,194:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=1.515e-01, with an active set of 225 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,194:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=1.455e-01, with an active set of 225 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,195:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.385e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,195:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.355e-01, with an active set of 226 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,196:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=1.284e-01, with an active set of 227 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,198:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.443e-01, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,198:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.429e-01, with an active set of 228 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,198:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.120e-01, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,199:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.111e-01, with an active set of 229 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,199:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.099e-01, with an active set of 229 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,199:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.015e-01, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,199:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=9.723e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,199:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=9.656e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,199:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=9.391e-02, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,200:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=8.646e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,200:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=8.548e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,200:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=8.362e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,201:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=7.342e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,201:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=7.286e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,202:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=6.966e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,202:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=6.954e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,203:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=7.879e-02, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,204:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=7.096e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,204:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=6.892e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,205:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=6.388e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,205:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=6.340e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,205:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=6.101e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,205:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=5.917e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,205:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=5.711e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,206:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=5.520e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,206:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.700e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,207:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=4.945e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,207:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=4.533e-02, with an active set of 234 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,207:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=4.401e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,208:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.775e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,208:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.775e-02, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,208:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=3.077e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,208:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=3.002e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,209:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.944e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,209:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.930e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,209:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.909e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,209:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.845e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,209:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.709e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,209:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.491e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,210:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.267e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,210:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.088e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,210:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=2.043e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,210:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.934e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,210:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.851e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,210:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.592e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,210:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.584e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,211:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.574e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,211:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.473e-02, with an active set of 236 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,211:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.353e-02, with an active set of 237 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,211:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.329e-02, with an active set of 237 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,212:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.160e-02, with an active set of 237 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,212:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.157e-02, with an active set of 237 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,212:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.030e-02, with an active set of 237 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,212:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=9.904e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,212:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=9.221e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,212:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=8.811e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,212:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=8.653e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,213:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=8.560e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,213:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=8.462e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,213:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=6.934e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,213:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=4.305e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,213:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=4.261e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,213:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=3.219e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,213:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=2.778e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,214:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=2.604e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,214:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=2.571e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,214:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=2.457e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,214:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=2.254e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,214:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=2.171e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,214:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=2.070e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,214:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.863e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,215:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.816e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,215:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.748e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,215:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.565e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,215:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.509e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,215:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.353e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,215:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.096e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,215:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.094e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,216:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.068e-03, with an active set of 237 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,216:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=6.378e-04, with an active set of 237 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,216:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=8.031e-05, with an active set of 237 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,216:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=2.979e-05, with an active set of 237 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:08:45,342:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:08:45,579:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:08:58,272:INFO:Calculating mean and std
2023-06-26 05:08:58,275:INFO:Creating metrics dataframe
2023-06-26 05:09:01,114:INFO:Uploading results into container
2023-06-26 05:09:01,115:INFO:Uploading model into container now
2023-06-26 05:09:01,116:INFO:_master_model_container: 6
2023-06-26 05:09:01,118:INFO:_display_container: 2
2023-06-26 05:09:01,118:INFO:LassoLars(random_state=4661)
2023-06-26 05:09:01,118:INFO:create_model() successfully completed......................................
2023-06-26 05:09:01,315:INFO:SubProcess create_model() end ==================================
2023-06-26 05:09:01,315:INFO:Creating metrics dataframe
2023-06-26 05:09:01,320:INFO:Initializing Orthogonal Matching Pursuit
2023-06-26 05:09:01,320:INFO:Total runtime is 2.7783029238382975 minutes
2023-06-26 05:09:01,320:INFO:SubProcess create_model() called ==================================
2023-06-26 05:09:01,321:INFO:Initializing create_model()
2023-06-26 05:09:01,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9C4C8E290>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:09:01,321:INFO:Checking exceptions
2023-06-26 05:09:01,321:INFO:Importing libraries
2023-06-26 05:09:01,321:INFO:Copying training dataset
2023-06-26 05:09:01,389:INFO:Defining folds
2023-06-26 05:09:01,389:INFO:Declaring metric variables
2023-06-26 05:09:01,390:INFO:Importing untrained model
2023-06-26 05:09:01,390:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-26 05:09:01,391:INFO:Starting cross validation
2023-06-26 05:09:01,431:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:09:04,447:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:09:04,460:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:09:04,514:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:09:04,607:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:09:04,669:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:09:04,962:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:09:05,594:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:09:05,891:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:09:05,892:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:09:05,995:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:09:06,080:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:09:22,357:INFO:Calculating mean and std
2023-06-26 05:09:22,358:WARNING:
2023-06-26 05:09:22,359:WARNING:
2023-06-26 05:09:22,359:WARNING:Processing:  26%|##########8                               | 21/81 [02:39<12:45, 12.76s/it]
2023-06-26 05:09:22,359:WARNING:[A[A
2023-06-26 05:09:22,359:INFO:Creating metrics dataframe
2023-06-26 05:09:24,722:WARNING:
2023-06-26 05:09:24,726:WARNING:
2023-06-26 05:09:24,726:WARNING:Processing:  27%|###########4                              | 22/81 [02:41<10:13, 10.40s/it]
2023-06-26 05:09:24,726:WARNING:[A[A
2023-06-26 05:09:24,726:INFO:Uploading results into container
2023-06-26 05:09:24,727:INFO:Uploading model into container now
2023-06-26 05:09:24,727:INFO:_master_model_container: 5
2023-06-26 05:09:24,728:INFO:_display_container: 2
2023-06-26 05:09:24,728:INFO:Lars(random_state=5040)
2023-06-26 05:09:24,729:INFO:create_model() successfully completed......................................
2023-06-26 05:09:24,982:INFO:SubProcess create_model() end ==================================
2023-06-26 05:09:24,982:INFO:Creating metrics dataframe
2023-06-26 05:09:24,988:INFO:Initializing Lasso Least Angle Regression
2023-06-26 05:09:24,988:INFO:Total runtime is 2.696239399909973 minutes
2023-06-26 05:09:24,989:INFO:SubProcess create_model() called ==================================
2023-06-26 05:09:24,991:INFO:Initializing create_model()
2023-06-26 05:09:25,004:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BAAF63E0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BD66AE00>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:09:25,004:INFO:Checking exceptions
2023-06-26 05:09:25,017:INFO:Importing libraries
2023-06-26 05:09:25,024:INFO:Copying training dataset
2023-06-26 05:09:25,077:WARNING:
2023-06-26 05:09:25,079:WARNING:
2023-06-26 05:09:25,079:WARNING:Processing:  28%|###########9                              | 23/81 [02:41<07:40,  7.94s/it]
2023-06-26 05:09:25,079:WARNING:[A[A
2023-06-26 05:09:25,079:INFO:Defining folds
2023-06-26 05:09:25,079:INFO:Declaring metric variables
2023-06-26 05:09:25,080:INFO:Importing untrained model
2023-06-26 05:09:25,080:INFO:Lasso Least Angle Regression Imported successfully
2023-06-26 05:09:25,080:INFO:Starting cross validation
2023-06-26 05:09:25,109:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:09:28,509:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:09:28,511:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:09:28,537:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:09:28,617:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:09:28,697:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:09:28,713:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:09:29,661:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:09:29,666:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:09:29,689:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:09:29,692:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:09:29,711:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:09:43,047:INFO:Calculating mean and std
2023-06-26 05:09:43,054:INFO:Creating metrics dataframe
2023-06-26 05:09:49,166:INFO:Uploading results into container
2023-06-26 05:09:49,166:INFO:Uploading model into container now
2023-06-26 05:09:49,167:INFO:_master_model_container: 7
2023-06-26 05:09:49,167:INFO:_display_container: 2
2023-06-26 05:09:49,168:INFO:OrthogonalMatchingPursuit()
2023-06-26 05:09:49,168:INFO:create_model() successfully completed......................................
2023-06-26 05:09:49,342:INFO:SubProcess create_model() end ==================================
2023-06-26 05:09:49,343:INFO:Creating metrics dataframe
2023-06-26 05:09:49,346:INFO:Initializing Bayesian Ridge
2023-06-26 05:09:49,347:INFO:Total runtime is 3.5787537693977356 minutes
2023-06-26 05:09:49,348:INFO:SubProcess create_model() called ==================================
2023-06-26 05:09:49,349:INFO:Initializing create_model()
2023-06-26 05:09:49,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9C4C8E290>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:09:49,349:INFO:Checking exceptions
2023-06-26 05:09:49,349:INFO:Importing libraries
2023-06-26 05:09:49,349:INFO:Copying training dataset
2023-06-26 05:09:49,376:INFO:Defining folds
2023-06-26 05:09:49,376:INFO:Declaring metric variables
2023-06-26 05:09:49,377:INFO:Importing untrained model
2023-06-26 05:09:49,377:INFO:Bayesian Ridge Imported successfully
2023-06-26 05:09:49,377:INFO:Starting cross validation
2023-06-26 05:09:49,396:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:09:52,649:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:10:02,219:INFO:Calculating mean and std
2023-06-26 05:10:02,220:WARNING:
2023-06-26 05:10:02,220:WARNING:
2023-06-26 05:10:02,220:WARNING:Processing:  31%|############9                             | 25/81 [03:19<11:29, 12.32s/it]
2023-06-26 05:10:02,221:WARNING:[A[A
2023-06-26 05:10:02,222:INFO:Creating metrics dataframe
2023-06-26 05:10:03,607:WARNING:
2023-06-26 05:10:03,607:WARNING:
2023-06-26 05:10:03,608:WARNING:Processing:  32%|#############4                            | 26/81 [03:20<09:00,  9.83s/it]
2023-06-26 05:10:03,608:WARNING:[A[A
2023-06-26 05:10:03,608:INFO:Uploading results into container
2023-06-26 05:10:03,608:INFO:Uploading model into container now
2023-06-26 05:10:03,609:INFO:_master_model_container: 6
2023-06-26 05:10:03,609:INFO:_display_container: 2
2023-06-26 05:10:03,609:INFO:LassoLars(random_state=5040)
2023-06-26 05:10:03,609:INFO:create_model() successfully completed......................................
2023-06-26 05:10:03,788:INFO:SubProcess create_model() end ==================================
2023-06-26 05:10:03,788:INFO:Creating metrics dataframe
2023-06-26 05:10:03,790:INFO:Initializing Orthogonal Matching Pursuit
2023-06-26 05:10:03,791:INFO:Total runtime is 3.3429555932680763 minutes
2023-06-26 05:10:03,791:INFO:SubProcess create_model() called ==================================
2023-06-26 05:10:03,791:INFO:Initializing create_model()
2023-06-26 05:10:03,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BAAF63E0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BD66AE00>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:10:03,792:INFO:Checking exceptions
2023-06-26 05:10:03,792:INFO:Importing libraries
2023-06-26 05:10:03,792:INFO:Copying training dataset
2023-06-26 05:10:03,814:WARNING:
2023-06-26 05:10:03,814:WARNING:
2023-06-26 05:10:03,814:WARNING:Processing:  33%|##############                            | 27/81 [03:20<06:43,  7.47s/it]
2023-06-26 05:10:03,814:WARNING:[A[A
2023-06-26 05:10:03,815:INFO:Defining folds
2023-06-26 05:10:03,815:INFO:Declaring metric variables
2023-06-26 05:10:03,815:INFO:Importing untrained model
2023-06-26 05:10:03,815:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-26 05:10:03,815:INFO:Starting cross validation
2023-06-26 05:10:03,828:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:10:04,246:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:10:04,275:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:10:04,319:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:10:04,441:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:10:04,466:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:10:04,521:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:10:05,249:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:10:05,271:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:10:05,343:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:10:05,377:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:10:05,388:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:10:15,626:INFO:Calculating mean and std
2023-06-26 05:10:15,628:INFO:Creating metrics dataframe
2023-06-26 05:10:17,236:INFO:Uploading results into container
2023-06-26 05:10:17,237:INFO:Uploading model into container now
2023-06-26 05:10:17,238:INFO:_master_model_container: 8
2023-06-26 05:10:17,246:INFO:_display_container: 2
2023-06-26 05:10:17,248:INFO:BayesianRidge()
2023-06-26 05:10:17,249:INFO:create_model() successfully completed......................................
2023-06-26 05:10:17,480:INFO:SubProcess create_model() end ==================================
2023-06-26 05:10:17,481:INFO:Creating metrics dataframe
2023-06-26 05:10:17,484:INFO:Initializing Passive Aggressive Regressor
2023-06-26 05:10:17,484:INFO:Total runtime is 4.04771134853363 minutes
2023-06-26 05:10:17,484:INFO:SubProcess create_model() called ==================================
2023-06-26 05:10:17,484:INFO:Initializing create_model()
2023-06-26 05:10:17,484:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9C4C8E290>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:10:17,484:INFO:Checking exceptions
2023-06-26 05:10:17,484:INFO:Importing libraries
2023-06-26 05:10:17,484:INFO:Copying training dataset
2023-06-26 05:10:17,515:INFO:Defining folds
2023-06-26 05:10:17,515:INFO:Declaring metric variables
2023-06-26 05:10:17,515:INFO:Importing untrained model
2023-06-26 05:10:17,515:INFO:Passive Aggressive Regressor Imported successfully
2023-06-26 05:10:17,516:INFO:Starting cross validation
2023-06-26 05:10:17,528:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:10:20,479:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:10:20,817:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:10:29,437:INFO:Calculating mean and std
2023-06-26 05:10:29,439:WARNING:
2023-06-26 05:10:29,439:WARNING:
2023-06-26 05:10:29,439:WARNING:Processing:  36%|###############                           | 29/81 [03:46<08:22,  9.67s/it]
2023-06-26 05:10:29,439:WARNING:[A[A
2023-06-26 05:10:29,439:INFO:Creating metrics dataframe
2023-06-26 05:10:31,446:WARNING:
2023-06-26 05:10:31,446:WARNING:
2023-06-26 05:10:31,447:WARNING:Processing:  37%|###############5                          | 30/81 [03:48<06:44,  7.93s/it]
2023-06-26 05:10:31,447:WARNING:[A[A
2023-06-26 05:10:31,451:INFO:Uploading results into container
2023-06-26 05:10:31,452:INFO:Uploading model into container now
2023-06-26 05:10:31,453:INFO:_master_model_container: 7
2023-06-26 05:10:31,453:INFO:_display_container: 2
2023-06-26 05:10:31,453:INFO:OrthogonalMatchingPursuit()
2023-06-26 05:10:31,453:INFO:create_model() successfully completed......................................
2023-06-26 05:10:31,621:INFO:SubProcess create_model() end ==================================
2023-06-26 05:10:31,622:INFO:Creating metrics dataframe
2023-06-26 05:10:31,624:INFO:Initializing Bayesian Ridge
2023-06-26 05:10:31,625:INFO:Total runtime is 3.806846753756205 minutes
2023-06-26 05:10:31,625:INFO:SubProcess create_model() called ==================================
2023-06-26 05:10:31,625:INFO:Initializing create_model()
2023-06-26 05:10:31,625:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BAAF63E0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BD66AE00>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:10:31,625:INFO:Checking exceptions
2023-06-26 05:10:31,625:INFO:Importing libraries
2023-06-26 05:10:31,625:INFO:Copying training dataset
2023-06-26 05:10:31,668:WARNING:
2023-06-26 05:10:31,669:WARNING:
2023-06-26 05:10:31,669:WARNING:Processing:  38%|################                          | 31/81 [03:48<05:01,  6.04s/it]
2023-06-26 05:10:31,669:WARNING:[A[A
2023-06-26 05:10:31,669:INFO:Defining folds
2023-06-26 05:10:31,669:INFO:Declaring metric variables
2023-06-26 05:10:31,669:INFO:Importing untrained model
2023-06-26 05:10:31,670:INFO:Bayesian Ridge Imported successfully
2023-06-26 05:10:31,670:INFO:Starting cross validation
2023-06-26 05:10:31,679:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:10:33,951:INFO:PyCaret RegressionExperiment
2023-06-26 05:10:33,951:INFO:Logging name: reg-default-name
2023-06-26 05:10:33,951:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-26 05:10:33,951:INFO:version 3.0.2
2023-06-26 05:10:33,951:INFO:Initializing setup()
2023-06-26 05:10:33,951:INFO:self.USI: 3387
2023-06-26 05:10:33,951:INFO:self._variable_keys: {'log_plots_param', 'target_param', 'pipeline', 'y_train', 'memory', 'USI', 'exp_id', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'X_test', 'transform_target_param', 'data', 'logging_param', '_ml_usecase', 'idx', 'n_jobs_param', 'y', 'X', '_available_plots', 'gpu_param', 'X_train', 'exp_name_log', 'seed', 'html_param', 'fold_shuffle_param'}
2023-06-26 05:10:33,951:INFO:Checking environment
2023-06-26 05:10:33,951:INFO:python_version: 3.10.4
2023-06-26 05:10:33,952:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2023-06-26 05:10:33,952:INFO:machine: AMD64
2023-06-26 05:10:33,952:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-26 05:10:33,957:INFO:Memory: svmem(total=7969243136, available=1133346816, percent=85.8, used=6835896320, free=1133346816)
2023-06-26 05:10:33,958:INFO:Physical Core: 6
2023-06-26 05:10:33,958:INFO:Logical Core: 6
2023-06-26 05:10:33,958:INFO:Checking libraries
2023-06-26 05:10:33,958:INFO:System:
2023-06-26 05:10:33,958:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2023-06-26 05:10:33,958:INFO:executable: C:\New folder\python.exe
2023-06-26 05:10:33,958:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-26 05:10:33,958:INFO:PyCaret required dependencies:
2023-06-26 05:10:33,958:INFO:                 pip: 23.1.2
2023-06-26 05:10:33,958:INFO:          setuptools: 58.1.0
2023-06-26 05:10:33,958:INFO:             pycaret: 3.0.2
2023-06-26 05:10:33,958:INFO:             IPython: 8.7.0
2023-06-26 05:10:33,958:INFO:          ipywidgets: 8.0.3
2023-06-26 05:10:33,958:INFO:                tqdm: 4.65.0
2023-06-26 05:10:33,958:INFO:               numpy: 1.23.5
2023-06-26 05:10:33,958:INFO:              pandas: 1.5.3
2023-06-26 05:10:33,958:INFO:              jinja2: 3.1.0
2023-06-26 05:10:33,958:INFO:               scipy: 1.9.1
2023-06-26 05:10:33,959:INFO:              joblib: 1.2.0
2023-06-26 05:10:33,959:INFO:             sklearn: 1.1.2
2023-06-26 05:10:33,959:INFO:                pyod: 1.1.0
2023-06-26 05:10:33,959:INFO:            imblearn: 0.10.1
2023-06-26 05:10:33,959:INFO:   category_encoders: 2.6.1
2023-06-26 05:10:33,959:INFO:            lightgbm: 3.3.5
2023-06-26 05:10:33,959:INFO:               numba: 0.57.1
2023-06-26 05:10:33,959:INFO:            requests: 2.28.1
2023-06-26 05:10:33,959:INFO:          matplotlib: 3.7.1
2023-06-26 05:10:33,959:INFO:          scikitplot: 0.3.7
2023-06-26 05:10:33,959:INFO:         yellowbrick: 1.5
2023-06-26 05:10:33,959:INFO:              plotly: 5.15.0
2023-06-26 05:10:33,959:INFO:             kaleido: 0.2.1
2023-06-26 05:10:33,959:INFO:         statsmodels: 0.14.0
2023-06-26 05:10:33,959:INFO:              sktime: 0.17.0
2023-06-26 05:10:33,959:INFO:               tbats: 1.1.3
2023-06-26 05:10:33,959:INFO:            pmdarima: 2.0.3
2023-06-26 05:10:33,959:INFO:              psutil: 5.9.4
2023-06-26 05:10:33,959:INFO:PyCaret optional dependencies:
2023-06-26 05:10:33,959:INFO:                shap: Not installed
2023-06-26 05:10:33,960:INFO:           interpret: Not installed
2023-06-26 05:10:33,960:INFO:                umap: Not installed
2023-06-26 05:10:33,960:INFO:    pandas_profiling: 4.3.1
2023-06-26 05:10:33,960:INFO:  explainerdashboard: Not installed
2023-06-26 05:10:33,960:INFO:             autoviz: Not installed
2023-06-26 05:10:33,960:INFO:           fairlearn: Not installed
2023-06-26 05:10:33,960:INFO:             xgboost: 1.7.5
2023-06-26 05:10:33,960:INFO:            catboost: Not installed
2023-06-26 05:10:33,960:INFO:              kmodes: Not installed
2023-06-26 05:10:33,960:INFO:             mlxtend: Not installed
2023-06-26 05:10:33,960:INFO:       statsforecast: Not installed
2023-06-26 05:10:33,960:INFO:        tune_sklearn: Not installed
2023-06-26 05:10:33,960:INFO:                 ray: Not installed
2023-06-26 05:10:33,960:INFO:            hyperopt: Not installed
2023-06-26 05:10:33,960:INFO:              optuna: Not installed
2023-06-26 05:10:33,960:INFO:               skopt: Not installed
2023-06-26 05:10:33,960:INFO:              mlflow: Not installed
2023-06-26 05:10:33,960:INFO:              gradio: Not installed
2023-06-26 05:10:33,960:INFO:             fastapi: Not installed
2023-06-26 05:10:33,960:INFO:             uvicorn: Not installed
2023-06-26 05:10:33,961:INFO:              m2cgen: Not installed
2023-06-26 05:10:33,961:INFO:           evidently: Not installed
2023-06-26 05:10:33,961:INFO:               fugue: Not installed
2023-06-26 05:10:33,961:INFO:           streamlit: 1.23.1
2023-06-26 05:10:33,961:INFO:             prophet: Not installed
2023-06-26 05:10:33,961:INFO:None
2023-06-26 05:10:33,961:INFO:Set up data.
2023-06-26 05:10:34,090:INFO:Set up train/test split.
2023-06-26 05:10:34,159:INFO:Set up index.
2023-06-26 05:10:34,160:INFO:Set up folding strategy.
2023-06-26 05:10:34,160:INFO:Assigning column types.
2023-06-26 05:10:34,176:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-26 05:10:34,177:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,182:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,191:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,282:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,337:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,338:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:10:34,341:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:10:34,341:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,347:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,352:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,490:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,491:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:10:34,494:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:10:34,495:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-26 05:10:34,500:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,506:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,587:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,639:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,640:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:10:34,643:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:10:34,648:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,672:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,795:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,849:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,851:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:10:34,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:10:34,868:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-26 05:10:34,879:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:10:34,964:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:10:35,016:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:10:35,017:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:10:35,022:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:10:35,034:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-26 05:10:35,123:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:10:35,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:10:35,177:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:10:35,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:10:35,181:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-26 05:10:35,268:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:10:35,318:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:10:35,318:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:10:35,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:10:35,409:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:10:35,458:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-26 05:10:35,459:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:10:35,462:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:10:35,464:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-26 05:10:35,550:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:10:35,598:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:10:35,602:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:10:35,720:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-26 05:10:35,767:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:10:35,771:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:10:35,772:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-26 05:10:35,900:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:10:35,903:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:10:36,089:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:10:36,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:10:36,097:INFO:Preparing preprocessing pipeline...
2023-06-26 05:10:36,097:INFO:Set up simple imputation.
2023-06-26 05:10:36,113:INFO:Set up encoding of ordinal features.
2023-06-26 05:10:36,126:INFO:Set up encoding of categorical features.
2023-06-26 05:10:37,055:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:10:38,192:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:10:39,247:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:10:40,146:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:10:41,950:INFO:Finished creating preprocessing pipeline.
2023-06-26 05:10:42,009:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Naman\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'Bsmt...
                                                                    'Condition1',
                                                                    'Condition2',
                                                                    'BldgType',
                                                                    'HouseStyle',
                                                                    'RoofStyle',
                                                                    'RoofMatl',
                                                                    'Exterior1st',
                                                                    'Exterior2nd',
                                                                    'MasVnrType',
                                                                    'ExterQual',
                                                                    'ExterCond',
                                                                    'Foundation',
                                                                    'BsmtQual',
                                                                    'BsmtCond',
                                                                    'BsmtExposure',
                                                                    'BsmtFinType1',
                                                                    'BsmtFinType2',
                                                                    'Heating',
                                                                    'HeatingQC',
                                                                    'Electrical',
                                                                    'KitchenQual',
                                                                    'Functional',
                                                                    'FireplaceQu', ...],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-06-26 05:10:42,009:INFO:Creating final display dataframe.
2023-06-26 05:10:44,832:INFO:Setup _display_container:                     Description             Value
0                    Session id               637
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape        (1460, 81)
4        Transformed data shape       (1460, 276)
5   Transformed train set shape       (1021, 276)
6    Transformed test set shape        (439, 276)
7              Ordinal features                 3
8              Numeric features                37
9          Categorical features                43
10     Rows with missing values            100.0%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              3387
2023-06-26 05:10:44,834:INFO:                    Description             Value
2023-06-26 05:10:44,834:INFO:0                    Session id               637
2023-06-26 05:10:44,834:INFO:1                        Target         SalePrice
2023-06-26 05:10:44,835:INFO:2                   Target type        Regression
2023-06-26 05:10:44,835:INFO:3           Original data shape        (1460, 81)
2023-06-26 05:10:44,835:INFO:4        Transformed data shape       (1460, 276)
2023-06-26 05:10:44,835:INFO:5   Transformed train set shape       (1021, 276)
2023-06-26 05:10:44,835:INFO:6    Transformed test set shape        (439, 276)
2023-06-26 05:10:44,836:INFO:7              Ordinal features                 3
2023-06-26 05:10:44,836:INFO:8              Numeric features                37
2023-06-26 05:10:44,836:INFO:9          Categorical features                43
2023-06-26 05:10:44,836:INFO:10     Rows with missing values            100.0%
2023-06-26 05:10:44,836:INFO:11                   Preprocess              True
2023-06-26 05:10:44,836:INFO:12              Imputation type            simple
2023-06-26 05:10:44,836:INFO:13           Numeric imputation              mean
2023-06-26 05:10:44,837:INFO:14       Categorical imputation              mode
2023-06-26 05:10:44,837:INFO:15     Maximum one-hot encoding                25
2023-06-26 05:10:44,837:INFO:16              Encoding method              None
2023-06-26 05:10:44,837:INFO:17               Fold Generator             KFold
2023-06-26 05:10:44,837:INFO:18                  Fold Number                10
2023-06-26 05:10:44,837:INFO:19                     CPU Jobs                -1
2023-06-26 05:10:44,837:INFO:20                      Use GPU             False
2023-06-26 05:10:44,837:INFO:21               Log Experiment             False
2023-06-26 05:10:44,837:INFO:22              Experiment Name  reg-default-name
2023-06-26 05:10:44,837:INFO:23                          USI              3387
2023-06-26 05:10:44,972:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:10:44,975:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:10:45,112:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-26 05:10:45,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-26 05:10:45,116:INFO:setup() successfully completed in 11.39s...............
2023-06-26 05:10:45,134:INFO:Initializing compare_models()
2023-06-26 05:10:45,135:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD331F30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD331F30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-26 05:10:45,136:INFO:Checking exceptions
2023-06-26 05:10:45,160:INFO:Preparing display monitor
2023-06-26 05:10:45,162:WARNING:
2023-06-26 05:10:45,162:WARNING:
2023-06-26 05:10:45,171:WARNING:
2023-06-26 05:10:45,171:WARNING:Processing:   0%|                                                   | 0/81 [00:00<?, ?it/s]
2023-06-26 05:10:45,171:WARNING:[A[A[A
2023-06-26 05:10:45,172:INFO:Initializing Linear Regression
2023-06-26 05:10:45,172:INFO:Total runtime is 0.0 minutes
2023-06-26 05:10:45,172:INFO:SubProcess create_model() called ==================================
2023-06-26 05:10:45,172:INFO:Initializing create_model()
2023-06-26 05:10:45,172:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD331F30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BAF61FF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:10:45,172:INFO:Checking exceptions
2023-06-26 05:10:45,172:INFO:Importing libraries
2023-06-26 05:10:45,172:INFO:Copying training dataset
2023-06-26 05:10:45,195:INFO:Defining folds
2023-06-26 05:10:45,196:INFO:Declaring metric variables
2023-06-26 05:10:45,196:INFO:Importing untrained model
2023-06-26 05:10:45,196:INFO:Linear Regression Imported successfully
2023-06-26 05:10:45,196:INFO:Starting cross validation
2023-06-26 05:10:45,219:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:10:47,561:INFO:Calculating mean and std
2023-06-26 05:10:47,575:INFO:Creating metrics dataframe
2023-06-26 05:10:48,072:INFO:Uploading results into container
2023-06-26 05:10:48,073:INFO:Uploading model into container now
2023-06-26 05:10:48,074:INFO:_master_model_container: 9
2023-06-26 05:10:48,075:INFO:_display_container: 2
2023-06-26 05:10:48,077:INFO:PassiveAggressiveRegressor(random_state=4661)
2023-06-26 05:10:48,077:INFO:create_model() successfully completed......................................
2023-06-26 05:10:48,354:INFO:SubProcess create_model() end ==================================
2023-06-26 05:10:48,355:INFO:Creating metrics dataframe
2023-06-26 05:10:48,358:INFO:Initializing Huber Regressor
2023-06-26 05:10:48,359:INFO:Total runtime is 4.562283198038736 minutes
2023-06-26 05:10:48,359:INFO:SubProcess create_model() called ==================================
2023-06-26 05:10:48,359:INFO:Initializing create_model()
2023-06-26 05:10:48,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9C4C8E290>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:10:48,360:INFO:Checking exceptions
2023-06-26 05:10:48,360:INFO:Importing libraries
2023-06-26 05:10:48,360:INFO:Copying training dataset
2023-06-26 05:10:48,395:INFO:Defining folds
2023-06-26 05:10:48,395:INFO:Declaring metric variables
2023-06-26 05:10:48,396:INFO:Importing untrained model
2023-06-26 05:10:48,396:INFO:Huber Regressor Imported successfully
2023-06-26 05:10:48,396:INFO:Starting cross validation
2023-06-26 05:10:48,433:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:10:48,963:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:10:48,978:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:10:49,148:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:10:52,185:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:10:52,652:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:10:53,456:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 2.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:10:53,824:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 4.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:10:53,853:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 4.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:10:54,329:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 5.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:10:54,398:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:10:55,200:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:10:55,616:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:10:56,429:INFO:Calculating mean and std
2023-06-26 05:10:56,447:WARNING:
2023-06-26 05:10:56,465:WARNING:
2023-06-26 05:10:56,466:WARNING:Processing:  41%|#################1                        | 33/81 [04:13<06:55,  8.65s/it]
2023-06-26 05:10:56,466:WARNING:[A[A
2023-06-26 05:10:56,466:INFO:Creating metrics dataframe
2023-06-26 05:10:56,709:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 2.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:10:56,787:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:10:58,809:WARNING:
2023-06-26 05:10:58,810:WARNING:
2023-06-26 05:10:58,814:WARNING:Processing:  42%|#################6                        | 34/81 [04:15<05:39,  7.23s/it]
2023-06-26 05:10:58,815:WARNING:[A[A
2023-06-26 05:10:58,816:INFO:Uploading results into container
2023-06-26 05:10:58,824:INFO:Uploading model into container now
2023-06-26 05:10:58,866:INFO:_master_model_container: 8
2023-06-26 05:10:58,868:INFO:_display_container: 2
2023-06-26 05:10:58,874:INFO:BayesianRidge()
2023-06-26 05:10:58,876:INFO:create_model() successfully completed......................................
2023-06-26 05:10:59,747:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 2.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:11:00,007:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:11:00,475:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 2.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:11:00,664:INFO:SubProcess create_model() end ==================================
2023-06-26 05:11:00,668:INFO:Creating metrics dataframe
2023-06-26 05:11:00,728:INFO:Initializing Passive Aggressive Regressor
2023-06-26 05:11:00,728:INFO:Total runtime is 4.291910501321157 minutes
2023-06-26 05:11:00,730:INFO:SubProcess create_model() called ==================================
2023-06-26 05:11:00,732:INFO:Initializing create_model()
2023-06-26 05:11:00,732:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BAAF63E0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BD66AE00>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:11:00,733:INFO:Checking exceptions
2023-06-26 05:11:00,733:INFO:Importing libraries
2023-06-26 05:11:00,734:INFO:Copying training dataset
2023-06-26 05:11:00,975:WARNING:
2023-06-26 05:11:00,976:WARNING:
2023-06-26 05:11:00,977:WARNING:Processing:  43%|##################1                       | 35/81 [04:17<04:35,  5.99s/it]
2023-06-26 05:11:00,980:WARNING:[A[A
2023-06-26 05:11:00,981:INFO:Defining folds
2023-06-26 05:11:00,982:INFO:Declaring metric variables
2023-06-26 05:11:00,986:INFO:Importing untrained model
2023-06-26 05:11:00,990:INFO:Passive Aggressive Regressor Imported successfully
2023-06-26 05:11:00,992:INFO:Starting cross validation
2023-06-26 05:11:01,085:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:11:01,336:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 2.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:11:01,614:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:11:02,290:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 5.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:02,420:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 5.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:02,420:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:02,674:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:11:03,002:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:11:03,178:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:11:03,329:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:11:03,377:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:03,890:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:04,131:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:11:04,242:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:11:04,319:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:04,612:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:11:04,812:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:06,930:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:11:07,200:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:11:07,295:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:11:08,139:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:11:09,365:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:09,712:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 2.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:11:10,259:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 2.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:11:10,345:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 5.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:10,381:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:11:11,287:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:11,332:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 2.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:11:11,386:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:11,645:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:12,339:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:12,371:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:12,430:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:29,228:INFO:Calculating mean and std
2023-06-26 05:11:29,228:WARNING:
2023-06-26 05:11:29,228:WARNING:
2023-06-26 05:11:29,228:WARNING:
2023-06-26 05:11:29,228:WARNING:Processing:   6%|##6                                        | 5/81 [00:44<11:09,  8.81s/it]
2023-06-26 05:11:29,228:WARNING:[A[A[A
2023-06-26 05:11:29,228:INFO:Creating metrics dataframe
2023-06-26 05:11:31,602:WARNING:
2023-06-26 05:11:31,602:WARNING:
2023-06-26 05:11:31,602:WARNING:
2023-06-26 05:11:31,602:WARNING:Processing:   7%|###1                                       | 6/81 [00:46<09:13,  7.38s/it]
2023-06-26 05:11:31,602:WARNING:[A[A[A
2023-06-26 05:11:31,602:INFO:Uploading results into container
2023-06-26 05:11:31,603:INFO:Uploading model into container now
2023-06-26 05:11:31,604:INFO:_master_model_container: 1
2023-06-26 05:11:31,604:INFO:_display_container: 2
2023-06-26 05:11:31,604:INFO:LinearRegression(n_jobs=-1)
2023-06-26 05:11:31,604:INFO:create_model() successfully completed......................................
2023-06-26 05:11:31,882:INFO:SubProcess create_model() end ==================================
2023-06-26 05:11:31,882:INFO:Creating metrics dataframe
2023-06-26 05:11:31,889:INFO:Initializing Lasso Regression
2023-06-26 05:11:31,889:INFO:Total runtime is 0.7786140124003093 minutes
2023-06-26 05:11:31,889:INFO:SubProcess create_model() called ==================================
2023-06-26 05:11:31,890:INFO:Initializing create_model()
2023-06-26 05:11:31,890:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD331F30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BAF61FF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:11:31,890:INFO:Checking exceptions
2023-06-26 05:11:31,890:INFO:Importing libraries
2023-06-26 05:11:31,890:INFO:Copying training dataset
2023-06-26 05:11:31,919:WARNING:
2023-06-26 05:11:31,919:WARNING:
2023-06-26 05:11:31,919:WARNING:
2023-06-26 05:11:31,920:WARNING:Processing:   9%|###7                                       | 7/81 [00:46<07:00,  5.68s/it]
2023-06-26 05:11:31,920:WARNING:[A[A[A
2023-06-26 05:11:31,920:INFO:Defining folds
2023-06-26 05:11:31,920:INFO:Declaring metric variables
2023-06-26 05:11:31,920:INFO:Importing untrained model
2023-06-26 05:11:31,921:INFO:Lasso Regression Imported successfully
2023-06-26 05:11:31,921:INFO:Starting cross validation
2023-06-26 05:11:31,935:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:11:36,000:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.567e+10, tolerance: 5.701e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:11:36,017:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.754e+11, tolerance: 5.794e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:11:36,065:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.824e+11, tolerance: 5.673e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:11:36,070:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.183e+10, tolerance: 5.479e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:11:36,218:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+09, tolerance: 5.513e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:11:36,223:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e+10, tolerance: 5.605e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:11:37,002:INFO:Calculating mean and std
2023-06-26 05:11:37,025:INFO:Creating metrics dataframe
2023-06-26 05:11:38,596:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:40,410:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:11:40,607:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:11:40,817:INFO:Uploading results into container
2023-06-26 05:11:40,824:INFO:Uploading model into container now
2023-06-26 05:11:40,829:INFO:_master_model_container: 10
2023-06-26 05:11:40,831:INFO:_display_container: 2
2023-06-26 05:11:40,833:INFO:HuberRegressor()
2023-06-26 05:11:40,834:INFO:create_model() successfully completed......................................
2023-06-26 05:11:41,804:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:41,960:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:11:42,069:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:11:42,188:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:11:42,190:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 5.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:42,451:INFO:SubProcess create_model() end ==================================
2023-06-26 05:11:42,467:INFO:Creating metrics dataframe
2023-06-26 05:11:42,471:INFO:Initializing K Neighbors Regressor
2023-06-26 05:11:42,472:INFO:Total runtime is 5.4641726255416865 minutes
2023-06-26 05:11:42,473:INFO:SubProcess create_model() called ==================================
2023-06-26 05:11:42,473:INFO:Initializing create_model()
2023-06-26 05:11:42,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9C4C8E290>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:11:42,474:INFO:Checking exceptions
2023-06-26 05:11:42,474:INFO:Importing libraries
2023-06-26 05:11:42,475:INFO:Copying training dataset
2023-06-26 05:11:42,531:INFO:Defining folds
2023-06-26 05:11:42,532:INFO:Declaring metric variables
2023-06-26 05:11:42,532:INFO:Importing untrained model
2023-06-26 05:11:42,533:INFO:K Neighbors Regressor Imported successfully
2023-06-26 05:11:42,534:INFO:Starting cross validation
2023-06-26 05:11:42,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:11:42,750:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:11:42,816:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:11:43,130:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+11, tolerance: 5.767e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:11:43,333:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e+11, tolerance: 5.306e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:11:43,580:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e+10, tolerance: 5.516e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:11:44,511:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:45,479:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:46,640:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:47,767:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:48,177:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:11:48,403:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:11:49,243:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:11:49,878:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:11:50,422:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:11:50,486:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:11:50,542:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:11:57,938:INFO:Calculating mean and std
2023-06-26 05:11:57,939:WARNING:
2023-06-26 05:11:57,939:WARNING:
2023-06-26 05:11:57,939:WARNING:Processing:  46%|###################1                      | 37/81 [05:14<11:11, 15.25s/it]
2023-06-26 05:11:57,939:WARNING:[A[A
2023-06-26 05:11:57,939:INFO:Creating metrics dataframe
2023-06-26 05:12:00,343:WARNING:
2023-06-26 05:12:00,343:WARNING:
2023-06-26 05:12:00,344:WARNING:Processing:  47%|###################7                      | 38/81 [05:17<08:50, 12.33s/it]
2023-06-26 05:12:00,344:WARNING:[A[A
2023-06-26 05:12:00,344:INFO:Uploading results into container
2023-06-26 05:12:00,344:INFO:Uploading model into container now
2023-06-26 05:12:00,345:INFO:_master_model_container: 9
2023-06-26 05:12:00,346:INFO:_display_container: 2
2023-06-26 05:12:00,346:INFO:PassiveAggressiveRegressor(random_state=5040)
2023-06-26 05:12:00,346:INFO:create_model() successfully completed......................................
2023-06-26 05:12:00,557:INFO:SubProcess create_model() end ==================================
2023-06-26 05:12:00,557:INFO:Creating metrics dataframe
2023-06-26 05:12:00,561:INFO:Initializing Huber Regressor
2023-06-26 05:12:00,561:INFO:Total runtime is 5.289115806420644 minutes
2023-06-26 05:12:00,561:INFO:SubProcess create_model() called ==================================
2023-06-26 05:12:00,561:INFO:Initializing create_model()
2023-06-26 05:12:00,561:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BAAF63E0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BD66AE00>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:12:00,562:INFO:Checking exceptions
2023-06-26 05:12:00,562:INFO:Importing libraries
2023-06-26 05:12:00,562:INFO:Copying training dataset
2023-06-26 05:12:00,581:WARNING:
2023-06-26 05:12:00,581:WARNING:
2023-06-26 05:12:00,582:WARNING:Processing:  48%|####################2                     | 39/81 [05:17<06:33,  9.37s/it]
2023-06-26 05:12:00,582:WARNING:[A[A
2023-06-26 05:12:00,582:INFO:Defining folds
2023-06-26 05:12:00,582:INFO:Declaring metric variables
2023-06-26 05:12:00,583:INFO:Importing untrained model
2023-06-26 05:12:00,583:INFO:Huber Regressor Imported successfully
2023-06-26 05:12:00,583:INFO:Starting cross validation
2023-06-26 05:12:00,596:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:12:01,516:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:12:01,642:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:12:01,685:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:12:01,705:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:12:01,829:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:12:01,857:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:12:03,350:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:12:03,355:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:12:03,368:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:12:03,400:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-26 05:12:08,196:WARNING:Generate report structure:   0%|                                     | 0/1 [00:00<?, ?it/s]
2023-06-26 05:12:23,210:INFO:Calculating mean and std
2023-06-26 05:12:23,211:WARNING:
2023-06-26 05:12:23,211:WARNING:
2023-06-26 05:12:23,212:WARNING:
2023-06-26 05:12:23,212:WARNING:Processing:  11%|####7                                      | 9/81 [01:38<16:35, 13.82s/it]
2023-06-26 05:12:23,212:WARNING:[A[A[A
2023-06-26 05:12:23,212:INFO:Creating metrics dataframe
2023-06-26 05:12:25,475:WARNING:
2023-06-26 05:12:25,476:WARNING:
2023-06-26 05:12:25,476:WARNING:
2023-06-26 05:12:25,476:WARNING:Processing:  12%|#####1                                    | 10/81 [01:40<13:16, 11.21s/it]
2023-06-26 05:12:25,476:WARNING:[A[A[A
2023-06-26 05:12:25,476:INFO:Uploading results into container
2023-06-26 05:12:25,477:INFO:Uploading model into container now
2023-06-26 05:12:25,477:INFO:_master_model_container: 2
2023-06-26 05:12:25,478:INFO:_display_container: 2
2023-06-26 05:12:25,478:INFO:Lasso(random_state=637)
2023-06-26 05:12:25,478:INFO:create_model() successfully completed......................................
2023-06-26 05:12:25,700:INFO:SubProcess create_model() end ==================================
2023-06-26 05:12:25,701:INFO:Creating metrics dataframe
2023-06-26 05:12:25,704:INFO:Initializing Ridge Regression
2023-06-26 05:12:25,705:INFO:Total runtime is 1.675557541847229 minutes
2023-06-26 05:12:25,706:INFO:SubProcess create_model() called ==================================
2023-06-26 05:12:25,706:INFO:Initializing create_model()
2023-06-26 05:12:25,707:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD331F30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BAF61FF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:12:25,707:INFO:Checking exceptions
2023-06-26 05:12:25,717:INFO:Importing libraries
2023-06-26 05:12:25,717:INFO:Copying training dataset
2023-06-26 05:12:25,742:WARNING:
2023-06-26 05:12:25,742:WARNING:
2023-06-26 05:12:25,742:WARNING:
2023-06-26 05:12:25,742:WARNING:Processing:  14%|#####7                                    | 11/81 [01:40<09:58,  8.55s/it]
2023-06-26 05:12:25,742:WARNING:[A[A[A
2023-06-26 05:12:25,743:INFO:Defining folds
2023-06-26 05:12:25,743:INFO:Declaring metric variables
2023-06-26 05:12:25,743:INFO:Importing untrained model
2023-06-26 05:12:25,743:INFO:Ridge Regression Imported successfully
2023-06-26 05:12:25,743:INFO:Starting cross validation
2023-06-26 05:12:25,756:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:12:30,010:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:12:37,780:INFO:Calculating mean and std
2023-06-26 05:12:37,782:INFO:Creating metrics dataframe
2023-06-26 05:12:38,994:WARNING:Generate report structure: 100%|#############################| 1/1 [00:30<00:00, 30.80s/it]
2023-06-26 05:12:38,994:WARNING:Generate report structure: 100%|#############################| 1/1 [00:30<00:00, 30.80s/it]
2023-06-26 05:12:38,994:WARNING:
2023-06-26 05:12:39,325:INFO:Uploading results into container
2023-06-26 05:12:39,326:INFO:Uploading model into container now
2023-06-26 05:12:39,326:INFO:_master_model_container: 11
2023-06-26 05:12:39,326:INFO:_display_container: 2
2023-06-26 05:12:39,326:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-26 05:12:39,327:INFO:create_model() successfully completed......................................
2023-06-26 05:12:39,530:INFO:SubProcess create_model() end ==================================
2023-06-26 05:12:39,530:INFO:Creating metrics dataframe
2023-06-26 05:12:39,533:INFO:Initializing Decision Tree Regressor
2023-06-26 05:12:39,534:INFO:Total runtime is 6.415212404727935 minutes
2023-06-26 05:12:39,534:INFO:SubProcess create_model() called ==================================
2023-06-26 05:12:39,534:INFO:Initializing create_model()
2023-06-26 05:12:39,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9C4C8E290>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:12:39,536:INFO:Checking exceptions
2023-06-26 05:12:39,536:INFO:Importing libraries
2023-06-26 05:12:39,536:INFO:Copying training dataset
2023-06-26 05:12:39,559:INFO:Defining folds
2023-06-26 05:12:39,559:INFO:Declaring metric variables
2023-06-26 05:12:39,560:INFO:Importing untrained model
2023-06-26 05:12:39,560:INFO:Decision Tree Regressor Imported successfully
2023-06-26 05:12:39,560:INFO:Starting cross validation
2023-06-26 05:12:39,574:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:12:45,342:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:13:08,289:INFO:Calculating mean and std
2023-06-26 05:13:08,291:WARNING:
2023-06-26 05:13:08,291:WARNING:
2023-06-26 05:13:08,291:WARNING:Processing:  51%|#####################2                    | 41/81 [06:25<12:58, 19.45s/it]
2023-06-26 05:13:08,291:WARNING:[A[A
2023-06-26 05:13:08,291:INFO:Creating metrics dataframe
2023-06-26 05:13:08,477:WARNING:
2023-06-26 05:13:08,478:WARNING:
2023-06-26 05:13:08,478:WARNING:Processing:  52%|#####################7                    | 42/81 [06:25<09:47, 15.07s/it]
2023-06-26 05:13:08,478:WARNING:[A[A
2023-06-26 05:13:08,478:INFO:Uploading results into container
2023-06-26 05:13:08,478:INFO:Uploading model into container now
2023-06-26 05:13:08,479:INFO:_master_model_container: 10
2023-06-26 05:13:08,479:INFO:_display_container: 2
2023-06-26 05:13:08,479:INFO:HuberRegressor()
2023-06-26 05:13:08,479:INFO:create_model() successfully completed......................................
2023-06-26 05:13:08,624:INFO:SubProcess create_model() end ==================================
2023-06-26 05:13:08,624:INFO:Creating metrics dataframe
2023-06-26 05:13:08,628:INFO:Initializing K Neighbors Regressor
2023-06-26 05:13:08,628:INFO:Total runtime is 6.423572325706481 minutes
2023-06-26 05:13:08,628:INFO:SubProcess create_model() called ==================================
2023-06-26 05:13:08,628:INFO:Initializing create_model()
2023-06-26 05:13:08,629:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BAAF63E0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BD66AE00>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:13:08,629:INFO:Checking exceptions
2023-06-26 05:13:08,629:INFO:Importing libraries
2023-06-26 05:13:08,629:INFO:Copying training dataset
2023-06-26 05:13:08,652:WARNING:
2023-06-26 05:13:08,652:WARNING:
2023-06-26 05:13:08,652:WARNING:Processing:  53%|######################2                   | 43/81 [06:25<07:13, 11.42s/it]
2023-06-26 05:13:08,652:WARNING:[A[A
2023-06-26 05:13:08,652:INFO:Defining folds
2023-06-26 05:13:08,652:INFO:Declaring metric variables
2023-06-26 05:13:08,652:INFO:Importing untrained model
2023-06-26 05:13:08,653:INFO:K Neighbors Regressor Imported successfully
2023-06-26 05:13:08,653:INFO:Starting cross validation
2023-06-26 05:13:08,661:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:13:09,629:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:13:10,364:INFO:Calculating mean and std
2023-06-26 05:13:10,365:WARNING:
2023-06-26 05:13:10,365:WARNING:
2023-06-26 05:13:10,365:WARNING:
2023-06-26 05:13:10,365:WARNING:Processing:  16%|######7                                   | 13/81 [02:25<16:05, 14.20s/it]
2023-06-26 05:13:10,365:WARNING:[A[A[A
2023-06-26 05:13:10,365:INFO:Creating metrics dataframe
2023-06-26 05:13:10,550:WARNING:
2023-06-26 05:13:10,550:WARNING:
2023-06-26 05:13:10,550:WARNING:
2023-06-26 05:13:10,550:WARNING:Processing:  17%|#######2                                  | 14/81 [02:25<12:18, 11.02s/it]
2023-06-26 05:13:10,550:WARNING:[A[A[A
2023-06-26 05:13:10,550:INFO:Uploading results into container
2023-06-26 05:13:10,551:INFO:Uploading model into container now
2023-06-26 05:13:10,551:INFO:_master_model_container: 3
2023-06-26 05:13:10,551:INFO:_display_container: 2
2023-06-26 05:13:10,551:INFO:Ridge(random_state=637)
2023-06-26 05:13:10,551:INFO:create_model() successfully completed......................................
2023-06-26 05:13:10,715:INFO:SubProcess create_model() end ==================================
2023-06-26 05:13:10,715:INFO:Creating metrics dataframe
2023-06-26 05:13:10,718:INFO:Initializing Elastic Net
2023-06-26 05:13:10,719:INFO:Total runtime is 2.4257857322692873 minutes
2023-06-26 05:13:10,719:INFO:SubProcess create_model() called ==================================
2023-06-26 05:13:10,719:INFO:Initializing create_model()
2023-06-26 05:13:10,719:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD331F30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BAF61FF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:13:10,719:INFO:Checking exceptions
2023-06-26 05:13:10,719:INFO:Importing libraries
2023-06-26 05:13:10,719:INFO:Copying training dataset
2023-06-26 05:13:10,741:WARNING:
2023-06-26 05:13:10,741:WARNING:
2023-06-26 05:13:10,741:WARNING:
2023-06-26 05:13:10,741:WARNING:Processing:  19%|#######7                                  | 15/81 [02:25<09:12,  8.37s/it]
2023-06-26 05:13:10,741:WARNING:[A[A[A
2023-06-26 05:13:10,741:INFO:Defining folds
2023-06-26 05:13:10,741:INFO:Declaring metric variables
2023-06-26 05:13:10,742:INFO:Importing untrained model
2023-06-26 05:13:10,742:INFO:Elastic Net Imported successfully
2023-06-26 05:13:10,742:INFO:Starting cross validation
2023-06-26 05:13:10,750:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:13:11,490:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.628e+11, tolerance: 5.605e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:13:11,563:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.505e+11, tolerance: 5.701e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:13:11,565:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.415e+11, tolerance: 5.513e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:13:11,566:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.430e+11, tolerance: 5.794e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:13:12,162:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:13:12,484:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.613e+11, tolerance: 5.673e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:13:12,498:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.921e+11, tolerance: 5.479e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:13:12,958:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:13:13,214:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:13:13,345:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:13:13,931:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:13:13,964:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:13:15,813:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:13:16,013:WARNING:Summarize dataset:   0%|                                             | 0/5 [00:00<?, ?it/s]
2023-06-26 05:13:16,054:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:13:16,394:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:13:16,549:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:13:16,656:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:13:16,667:WARNING:Summarize dataset:   0%|               | 0/19 [00:00<?, ?it/s, Describe variable:CryoSleep]
2023-06-26 05:13:16,684:WARNING:Summarize dataset:   5%|3      | 1/19 [00:00<00:12,  1.49it/s, Describe variable:CryoSleep]
2023-06-26 05:13:16,710:WARNING:Summarize dataset:   5%|5          | 1/19 [00:00<00:12,  1.49it/s, Describe variable:Cabin]
2023-06-26 05:13:16,716:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:13:16,722:WARNING:Summarize dataset:  11%|6     | 2/19 [00:00<00:11,  1.49it/s, Describe variable:HomePlanet]
2023-06-26 05:13:16,723:WARNING:Summarize dataset:  16%|##           | 3/19 [00:00<00:10,  1.49it/s, Describe variable:VIP]
2023-06-26 05:13:16,740:WARNING:Summarize dataset:  21%|#    | 4/19 [00:00<00:10,  1.49it/s, Describe variable:PassengerId]
2023-06-26 05:13:16,742:WARNING:Summarize dataset:  26%|#3   | 5/19 [00:00<00:09,  1.49it/s, Describe variable:Destination]
2023-06-26 05:13:16,742:WARNING:Summarize dataset:  32%|##2    | 6/19 [00:00<00:08,  1.49it/s, Describe variable:FoodCourt]
2023-06-26 05:13:16,743:WARNING:Summarize dataset:  37%|#4  | 7/19 [00:00<00:08,  1.49it/s, Describe variable:ShoppingMall]
2023-06-26 05:13:16,744:WARNING:Summarize dataset:  42%|##1  | 8/19 [00:00<00:07,  1.49it/s, Describe variable:Transported]
2023-06-26 05:13:16,744:WARNING:Summarize dataset:  47%|##3  | 9/19 [00:00<00:06,  1.49it/s, Describe variable:RoomService]
2023-06-26 05:13:16,748:WARNING:Summarize dataset:  53%|######3     | 10/19 [00:00<00:06,  1.49it/s, Describe variable:Spa]
2023-06-26 05:13:16,749:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:13:16,749:WARNING:Summarize dataset:  58%|######9     | 11/19 [00:00<00:05,  1.49it/s, Describe variable:Age]
2023-06-26 05:13:16,780:WARNING:Summarize dataset:  63%|#####6   | 12/19 [00:00<00:04,  1.49it/s, Describe variable:VRDeck]
2023-06-26 05:13:16,781:WARNING:Summarize dataset:  68%|#######5   | 13/19 [00:00<00:04,  1.49it/s, Describe variable:Name]
2023-06-26 05:13:16,782:WARNING:Summarize dataset:  74%|###########    | 14/19 [00:00<00:03,  1.49it/s, Get variable types]
2023-06-26 05:13:16,783:WARNING:Summarize dataset:  71%|#####  | 15/21 [00:00<00:04,  1.49it/s, Calculate auto correlation]
2023-06-26 05:13:17,479:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:13:17,665:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.650e+11, tolerance: 5.767e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:13:17,683:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.350e+11, tolerance: 5.516e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:13:17,785:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.122e+11, tolerance: 5.306e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:13:17,787:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.107e+11, tolerance: 5.263e+08
  model = cd_fast.enet_coordinate_descent(

2023-06-26 05:13:17,880:WARNING:Summarize dataset:  76%|#####3 | 16/21 [00:01<00:00,  9.43it/s, Calculate auto correlation]
2023-06-26 05:13:17,881:WARNING:Summarize dataset:  76%|###########4   | 16/21 [00:01<00:00,  9.43it/s, Get scatter matrix]
2023-06-26 05:13:17,881:WARNING:Summarize dataset:  28%|####7            | 16/57 [00:01<00:04,  9.43it/s, scatter Age, Age]
2023-06-26 05:13:18,030:WARNING:Summarize dataset:  30%|#####            | 17/57 [00:02<00:04,  9.12it/s, scatter Age, Age]
2023-06-26 05:13:18,030:WARNING:Summarize dataset:  30%|##6      | 17/57 [00:02<00:04,  9.12it/s, scatter RoomService, Age]
2023-06-26 05:13:18,189:WARNING:Summarize dataset:  32%|##8      | 18/57 [00:02<00:04,  8.70it/s, scatter RoomService, Age]
2023-06-26 05:13:18,189:WARNING:Summarize dataset:  32%|###4       | 18/57 [00:02<00:04,  8.70it/s, scatter FoodCourt, Age]
2023-06-26 05:13:18,321:WARNING:Summarize dataset:  33%|###6       | 19/57 [00:02<00:04,  8.54it/s, scatter FoodCourt, Age]
2023-06-26 05:13:18,321:WARNING:Summarize dataset:  33%|##6     | 19/57 [00:02<00:04,  8.54it/s, scatter ShoppingMall, Age]
2023-06-26 05:13:18,452:WARNING:Summarize dataset:  35%|##8     | 20/57 [00:02<00:04,  8.38it/s, scatter ShoppingMall, Age]
2023-06-26 05:13:18,452:WARNING:Summarize dataset:  35%|#####9           | 20/57 [00:02<00:04,  8.38it/s, scatter Spa, Age]
2023-06-26 05:13:18,577:WARNING:Summarize dataset:  37%|######2          | 21/57 [00:02<00:04,  8.30it/s, scatter Spa, Age]
2023-06-26 05:13:18,577:WARNING:Summarize dataset:  37%|#####1        | 21/57 [00:02<00:04,  8.30it/s, scatter VRDeck, Age]
2023-06-26 05:13:18,688:WARNING:Summarize dataset:  39%|#####4        | 22/57 [00:02<00:04,  8.44it/s, scatter VRDeck, Age]
2023-06-26 05:13:18,688:WARNING:Summarize dataset:  39%|###4     | 22/57 [00:02<00:04,  8.44it/s, scatter Age, RoomService]
2023-06-26 05:13:18,810:WARNING:Summarize dataset:  40%|###6     | 23/57 [00:02<00:04,  8.38it/s, scatter Age, RoomService]
2023-06-26 05:13:18,810:WARNING:Summarize dataset:  40%|4| 23/57 [00:02<00:04,  8.38it/s, scatter RoomService, RoomService]
2023-06-26 05:13:18,941:WARNING:Summarize dataset:  42%|4| 24/57 [00:02<00:04,  8.18it/s, scatter RoomService, RoomService]
2023-06-26 05:13:18,941:WARNING:Summarize dataset:  42%|#2 | 24/57 [00:02<00:04,  8.18it/s, scatter FoodCourt, RoomService]
2023-06-26 05:13:19,064:WARNING:Summarize dataset:  44%|#3 | 25/57 [00:03<00:03,  8.17it/s, scatter FoodCourt, RoomService]
2023-06-26 05:13:19,065:WARNING:Summarize dataset:  44%|4| 25/57 [00:03<00:03,  8.17it/s, scatter ShoppingMall, RoomService
2023-06-26 05:13:19,198:WARNING:Summarize dataset:  46%|4| 26/57 [00:03<00:03,  7.96it/s, scatter ShoppingMall, RoomService
2023-06-26 05:13:19,198:WARNING:Summarize dataset:  46%|####1    | 26/57 [00:03<00:03,  7.96it/s, scatter Spa, RoomService]
2023-06-26 05:13:19,325:WARNING:Summarize dataset:  47%|####2    | 27/57 [00:03<00:03,  7.95it/s, scatter Spa, RoomService]
2023-06-26 05:13:19,326:WARNING:Summarize dataset:  47%|##8   | 27/57 [00:03<00:03,  7.95it/s, scatter VRDeck, RoomService]
2023-06-26 05:13:19,447:WARNING:Summarize dataset:  49%|##9   | 28/57 [00:03<00:03,  8.01it/s, scatter VRDeck, RoomService]
2023-06-26 05:13:19,447:WARNING:Summarize dataset:  49%|#####4     | 28/57 [00:03<00:03,  8.01it/s, scatter Age, FoodCourt]
2023-06-26 05:13:19,566:WARNING:Summarize dataset:  51%|#####5     | 29/57 [00:03<00:03,  8.12it/s, scatter Age, FoodCourt]
2023-06-26 05:13:19,566:WARNING:Summarize dataset:  51%|#5 | 29/57 [00:03<00:03,  8.12it/s, scatter RoomService, FoodCourt]
2023-06-26 05:13:20,499:WARNING:Summarize dataset:  53%|#5 | 30/57 [00:04<00:09,  2.78it/s, scatter RoomService, FoodCourt]
2023-06-26 05:13:20,502:WARNING:Summarize dataset:  53%|##6  | 30/57 [00:04<00:09,  2.78it/s, scatter FoodCourt, FoodCourt]
2023-06-26 05:13:21,494:WARNING:Summarize dataset:  54%|##7  | 31/57 [00:05<00:14,  1.83it/s, scatter FoodCourt, FoodCourt]
2023-06-26 05:13:21,497:WARNING:Summarize dataset:  54%|# | 31/57 [00:05<00:14,  1.83it/s, scatter ShoppingMall, FoodCourt]
2023-06-26 05:13:22,723:WARNING:Summarize dataset:  56%|#1| 32/57 [00:06<00:18,  1.34it/s, scatter ShoppingMall, FoodCourt]
2023-06-26 05:13:22,725:WARNING:Summarize dataset:  56%|######1    | 32/57 [00:06<00:18,  1.34it/s, scatter Spa, FoodCourt]
2023-06-26 05:13:23,653:WARNING:Summarize dataset:  58%|######3    | 33/57 [00:07<00:19,  1.24it/s, scatter Spa, FoodCourt]
2023-06-26 05:13:23,653:WARNING:Summarize dataset:  58%|####6   | 33/57 [00:07<00:19,  1.24it/s, scatter VRDeck, FoodCourt]
2023-06-26 05:13:23,764:WARNING:Summarize dataset:  60%|####7   | 34/57 [00:07<00:13,  1.68it/s, scatter VRDeck, FoodCourt]
2023-06-26 05:13:23,764:WARNING:Summarize dataset:  60%|####7   | 34/57 [00:07<00:13,  1.68it/s, scatter Age, ShoppingMall]
2023-06-26 05:13:23,891:WARNING:Summarize dataset:  61%|####9   | 35/57 [00:07<00:10,  2.19it/s, scatter Age, ShoppingMall]
2023-06-26 05:13:23,891:WARNING:Summarize dataset:  61%|6| 35/57 [00:07<00:10,  2.19it/s, scatter RoomService, ShoppingMall
2023-06-26 05:13:24,027:WARNING:Summarize dataset:  63%|6| 36/57 [00:08<00:07,  2.77it/s, scatter RoomService, ShoppingMall
2023-06-26 05:13:24,027:WARNING:Summarize dataset:  63%|#2| 36/57 [00:08<00:07,  2.77it/s, scatter FoodCourt, ShoppingMall]
2023-06-26 05:13:24,161:WARNING:Summarize dataset:  65%|#2| 37/57 [00:08<00:05,  3.41it/s, scatter FoodCourt, ShoppingMall]
2023-06-26 05:13:24,162:WARNING:Summarize dataset:  65%|6| 37/57 [00:08<00:05,  3.41it/s, scatter ShoppingMall, ShoppingMal
2023-06-26 05:13:24,306:WARNING:Summarize dataset:  67%|6| 38/57 [00:08<00:04,  4.03it/s, scatter ShoppingMall, ShoppingMal
2023-06-26 05:13:24,306:WARNING:Summarize dataset:  67%|#####3  | 38/57 [00:08<00:04,  4.03it/s, scatter Spa, ShoppingMall]
2023-06-26 05:13:24,442:WARNING:Summarize dataset:  68%|#####4  | 39/57 [00:08<00:03,  4.65it/s, scatter Spa, ShoppingMall]
2023-06-26 05:13:24,442:WARNING:Summarize dataset:  68%|###4 | 39/57 [00:08<00:03,  4.65it/s, scatter VRDeck, ShoppingMall]
2023-06-26 05:13:24,576:WARNING:Summarize dataset:  70%|###5 | 40/57 [00:08<00:03,  5.25it/s, scatter VRDeck, ShoppingMall]
2023-06-26 05:13:24,576:WARNING:Summarize dataset:  70%|###########9     | 40/57 [00:08<00:03,  5.25it/s, scatter Age, Spa]
2023-06-26 05:13:24,705:WARNING:Summarize dataset:  72%|############2    | 41/57 [00:08<00:02,  5.81it/s, scatter Age, Spa]
2023-06-26 05:13:24,705:WARNING:Summarize dataset:  72%|######4  | 41/57 [00:08<00:02,  5.81it/s, scatter RoomService, Spa]
2023-06-26 05:13:24,838:WARNING:Summarize dataset:  74%|######6  | 42/57 [00:08<00:02,  6.24it/s, scatter RoomService, Spa]
2023-06-26 05:13:24,838:WARNING:Summarize dataset:  74%|########1  | 42/57 [00:08<00:02,  6.24it/s, scatter FoodCourt, Spa]
2023-06-26 05:13:24,961:WARNING:Summarize dataset:  75%|########2  | 43/57 [00:08<00:02,  6.70it/s, scatter FoodCourt, Spa]
2023-06-26 05:13:24,961:WARNING:Summarize dataset:  75%|######  | 43/57 [00:08<00:02,  6.70it/s, scatter ShoppingMall, Spa]
2023-06-26 05:13:25,106:WARNING:Summarize dataset:  77%|######1 | 44/57 [00:09<00:01,  6.76it/s, scatter ShoppingMall, Spa]
2023-06-26 05:13:25,106:WARNING:Summarize dataset:  77%|#############1   | 44/57 [00:09<00:01,  6.76it/s, scatter Spa, Spa]
2023-06-26 05:13:25,230:WARNING:Summarize dataset:  79%|#############4   | 45/57 [00:09<00:01,  7.12it/s, scatter Spa, Spa]
2023-06-26 05:13:25,230:WARNING:Summarize dataset:  79%|###########   | 45/57 [00:09<00:01,  7.12it/s, scatter VRDeck, Spa]
2023-06-26 05:13:25,361:WARNING:Summarize dataset:  81%|###########2  | 46/57 [00:09<00:01,  7.26it/s, scatter VRDeck, Spa]
2023-06-26 05:13:25,361:WARNING:Summarize dataset:  81%|###########2  | 46/57 [00:09<00:01,  7.26it/s, scatter Age, VRDeck]
2023-06-26 05:13:25,476:WARNING:Summarize dataset:  82%|###########5  | 47/57 [00:09<00:01,  7.63it/s, scatter Age, VRDeck]
2023-06-26 05:13:25,476:WARNING:Summarize dataset:  82%|####9 | 47/57 [00:09<00:01,  7.63it/s, scatter RoomService, VRDeck]
2023-06-26 05:13:25,609:WARNING:Summarize dataset:  84%|##### | 48/57 [00:09<00:01,  7.59it/s, scatter RoomService, VRDeck]
2023-06-26 05:13:25,610:WARNING:Summarize dataset:  84%|######7 | 48/57 [00:09<00:01,  7.59it/s, scatter FoodCourt, VRDeck]
2023-06-26 05:13:25,727:WARNING:Summarize dataset:  86%|######8 | 49/57 [00:09<00:01,  7.84it/s, scatter FoodCourt, VRDeck]
2023-06-26 05:13:25,728:WARNING:Summarize dataset:  86%|####2| 49/57 [00:09<00:01,  7.84it/s, scatter ShoppingMall, VRDeck]
2023-06-26 05:13:25,868:WARNING:Summarize dataset:  88%|####3| 50/57 [00:09<00:00,  7.60it/s, scatter ShoppingMall, VRDeck]
2023-06-26 05:13:25,869:WARNING:Summarize dataset:  88%|############2 | 50/57 [00:09<00:00,  7.60it/s, scatter Spa, VRDeck]
2023-06-26 05:13:25,993:WARNING:Summarize dataset:  89%|############5 | 51/57 [00:09<00:00,  7.72it/s, scatter Spa, VRDeck]
2023-06-26 05:13:25,993:WARNING:Summarize dataset:  89%|#########8 | 51/57 [00:09<00:00,  7.72it/s, scatter VRDeck, VRDeck]
2023-06-26 05:13:26,108:WARNING:Summarize dataset:  91%|########## | 52/57 [00:10<00:00,  7.98it/s, scatter VRDeck, VRDeck]
2023-06-26 05:13:26,108:WARNING:Summarize dataset:  91%|########2| 52/57 [00:10<00:00,  7.98it/s, Get dataframe statistics]
2023-06-26 05:13:26,109:WARNING:Summarize dataset:  88%|############3 | 53/60 [00:10<00:00,  7.98it/s, Missing diagram bar]
2023-06-26 05:13:26,450:WARNING:Summarize dataset:  90%|############6 | 54/60 [00:10<00:00,  6.85it/s, Missing diagram bar]
2023-06-26 05:13:26,450:WARNING:Summarize dataset:  90%|#########9 | 54/60 [00:10<00:00,  6.85it/s, Missing diagram matrix]
2023-06-26 05:13:26,599:WARNING:Summarize dataset:  92%|########## | 55/60 [00:10<00:00,  6.81it/s, Missing diagram matrix]
2023-06-26 05:13:26,599:WARNING:Summarize dataset:  92%|#########1| 55/60 [00:10<00:00,  6.81it/s, Missing diagram heatmap]
2023-06-26 05:13:26,860:WARNING:Summarize dataset:  93%|#########3| 56/60 [00:10<00:00,  5.65it/s, Missing diagram heatmap]
2023-06-26 05:13:26,861:WARNING:Summarize dataset:  93%|####################5 | 56/60 [00:10<00:00,  5.65it/s, Take sample]
2023-06-26 05:13:26,861:WARNING:Summarize dataset:  95%|############3| 57/60 [00:10<00:00,  5.65it/s, Detecting duplicates]
2023-06-26 05:13:26,869:WARNING:Summarize dataset:  97%|######################2| 58/60 [00:10<00:00,  5.65it/s, Get alerts]
2023-06-26 05:13:26,869:WARNING:Summarize dataset:  98%|########8| 59/60 [00:10<00:00,  5.65it/s, Get reproduction details]
2023-06-26 05:13:26,870:WARNING:Summarize dataset: 100%|########################| 60/60 [00:10<00:00,  5.65it/s, Completed]
2023-06-26 05:13:26,870:WARNING:Summarize dataset: 100%|########################| 60/60 [00:10<00:00,  5.53it/s, Completed]
2023-06-26 05:13:26,870:WARNING:
2023-06-26 05:13:26,872:WARNING:Generate report structure:   0%|                                     | 0/1 [00:00<?, ?it/s]
2023-06-26 05:13:27,237:INFO:Calculating mean and std
2023-06-26 05:13:27,241:INFO:Creating metrics dataframe
2023-06-26 05:13:30,502:INFO:Uploading results into container
2023-06-26 05:13:30,503:INFO:Uploading model into container now
2023-06-26 05:13:30,504:INFO:_master_model_container: 12
2023-06-26 05:13:30,504:INFO:_display_container: 2
2023-06-26 05:13:30,505:INFO:DecisionTreeRegressor(random_state=4661)
2023-06-26 05:13:30,505:INFO:create_model() successfully completed......................................
2023-06-26 05:13:30,695:INFO:SubProcess create_model() end ==================================
2023-06-26 05:13:30,696:INFO:Creating metrics dataframe
2023-06-26 05:13:30,699:INFO:Initializing Random Forest Regressor
2023-06-26 05:13:30,700:INFO:Total runtime is 7.267976395289103 minutes
2023-06-26 05:13:30,701:INFO:SubProcess create_model() called ==================================
2023-06-26 05:13:30,702:INFO:Initializing create_model()
2023-06-26 05:13:30,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9C4C8E290>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:13:30,702:INFO:Checking exceptions
2023-06-26 05:13:30,702:INFO:Importing libraries
2023-06-26 05:13:30,702:INFO:Copying training dataset
2023-06-26 05:13:30,776:INFO:Defining folds
2023-06-26 05:13:30,776:INFO:Declaring metric variables
2023-06-26 05:13:30,778:INFO:Importing untrained model
2023-06-26 05:13:30,778:INFO:Random Forest Regressor Imported successfully
2023-06-26 05:13:30,779:INFO:Starting cross validation
2023-06-26 05:13:30,790:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:13:31,448:WARNING:Generate report structure: 100%|#############################| 1/1 [00:04<00:00,  4.58s/it]
2023-06-26 05:13:31,448:WARNING:Generate report structure: 100%|#############################| 1/1 [00:04<00:00,  4.58s/it]
2023-06-26 05:13:31,448:WARNING:
2023-06-26 05:13:31,449:WARNING:Render HTML:   0%|                                                   | 0/1 [00:00<?, ?it/s]
2023-06-26 05:13:32,178:WARNING:Render HTML: 100%|###########################################| 1/1 [00:00<00:00,  1.37it/s]
2023-06-26 05:13:32,179:WARNING:Render HTML: 100%|###########################################| 1/1 [00:00<00:00,  1.37it/s]
2023-06-26 05:13:32,179:WARNING:
2023-06-26 05:13:37,329:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 3.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:13:37,588:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 3.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:13:39,989:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:13:40,564:INFO:Calculating mean and std
2023-06-26 05:13:40,564:WARNING:
2023-06-26 05:13:40,564:WARNING:
2023-06-26 05:13:40,564:WARNING:Processing:  56%|#######################3                  | 45/81 [06:57<07:58, 13.29s/it]
2023-06-26 05:13:40,565:WARNING:[A[A
2023-06-26 05:13:40,565:INFO:Creating metrics dataframe
2023-06-26 05:13:41,159:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:13:41,191:WARNING:
2023-06-26 05:13:41,191:WARNING:
2023-06-26 05:13:41,192:WARNING:Processing:  57%|#######################8                  | 46/81 [06:57<06:04, 10.41s/it]
2023-06-26 05:13:41,192:WARNING:[A[A
2023-06-26 05:13:41,192:INFO:Uploading results into container
2023-06-26 05:13:41,192:INFO:Uploading model into container now
2023-06-26 05:13:41,193:INFO:_master_model_container: 11
2023-06-26 05:13:41,193:INFO:_display_container: 2
2023-06-26 05:13:41,193:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-26 05:13:41,193:INFO:create_model() successfully completed......................................
2023-06-26 05:13:41,521:INFO:SubProcess create_model() end ==================================
2023-06-26 05:13:41,521:INFO:Creating metrics dataframe
2023-06-26 05:13:41,524:INFO:Initializing Decision Tree Regressor
2023-06-26 05:13:41,524:INFO:Total runtime is 6.971834623813629 minutes
2023-06-26 05:13:41,524:INFO:SubProcess create_model() called ==================================
2023-06-26 05:13:41,525:INFO:Initializing create_model()
2023-06-26 05:13:41,525:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BAAF63E0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BD66AE00>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:13:41,525:INFO:Checking exceptions
2023-06-26 05:13:41,525:INFO:Importing libraries
2023-06-26 05:13:41,525:INFO:Copying training dataset
2023-06-26 05:13:41,565:WARNING:
2023-06-26 05:13:41,565:WARNING:
2023-06-26 05:13:41,565:WARNING:Processing:  58%|########################3                 | 47/81 [06:58<04:30,  7.95s/it]
2023-06-26 05:13:41,565:WARNING:[A[A
2023-06-26 05:13:41,565:INFO:Defining folds
2023-06-26 05:13:41,565:INFO:Declaring metric variables
2023-06-26 05:13:41,565:INFO:Importing untrained model
2023-06-26 05:13:41,566:INFO:Decision Tree Regressor Imported successfully
2023-06-26 05:13:41,566:INFO:Starting cross validation
2023-06-26 05:13:41,573:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:13:46,863:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 3.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:13:47,092:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:13:47,102:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:13:47,187:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 6.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:13:48,402:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:13:48,470:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:13:48,600:INFO:Calculating mean and std
2023-06-26 05:13:48,601:WARNING:
2023-06-26 05:13:48,601:WARNING:
2023-06-26 05:13:48,601:WARNING:
2023-06-26 05:13:48,601:WARNING:Processing:  21%|########8                                 | 17/81 [03:03<13:33, 12.71s/it]
2023-06-26 05:13:48,601:WARNING:[A[A[A
2023-06-26 05:13:48,601:INFO:Creating metrics dataframe
2023-06-26 05:13:48,611:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:13:48,842:WARNING:
2023-06-26 05:13:48,843:WARNING:
2023-06-26 05:13:48,843:WARNING:
2023-06-26 05:13:48,843:WARNING:Processing:  22%|#########3                                | 18/81 [03:03<10:22,  9.88s/it]
2023-06-26 05:13:48,843:WARNING:[A[A[A
2023-06-26 05:13:48,843:INFO:Uploading results into container
2023-06-26 05:13:48,844:INFO:Uploading model into container now
2023-06-26 05:13:48,844:INFO:_master_model_container: 4
2023-06-26 05:13:48,844:INFO:_display_container: 2
2023-06-26 05:13:48,845:INFO:ElasticNet(random_state=637)
2023-06-26 05:13:48,845:INFO:create_model() successfully completed......................................
2023-06-26 05:13:49,040:INFO:SubProcess create_model() end ==================================
2023-06-26 05:13:49,041:INFO:Creating metrics dataframe
2023-06-26 05:13:49,044:INFO:Initializing Least Angle Regression
2023-06-26 05:13:49,044:INFO:Total runtime is 3.064530638853709 minutes
2023-06-26 05:13:49,045:INFO:SubProcess create_model() called ==================================
2023-06-26 05:13:49,045:INFO:Initializing create_model()
2023-06-26 05:13:49,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD331F30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BAF61FF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:13:49,046:INFO:Checking exceptions
2023-06-26 05:13:49,046:INFO:Importing libraries
2023-06-26 05:13:49,046:INFO:Copying training dataset
2023-06-26 05:13:49,088:WARNING:
2023-06-26 05:13:49,088:WARNING:
2023-06-26 05:13:49,088:WARNING:
2023-06-26 05:13:49,088:WARNING:Processing:  23%|#########8                                | 19/81 [03:03<07:46,  7.52s/it]
2023-06-26 05:13:49,088:WARNING:[A[A[A
2023-06-26 05:13:49,088:INFO:Defining folds
2023-06-26 05:13:49,088:INFO:Declaring metric variables
2023-06-26 05:13:49,088:INFO:Importing untrained model
2023-06-26 05:13:49,088:INFO:Least Angle Regression Imported successfully
2023-06-26 05:13:49,089:INFO:Starting cross validation
2023-06-26 05:13:49,098:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:13:50,930:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:13:51,660:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:13:52,195:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:13:52,592:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:13:52,628:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:13:53,369:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:13:53,952:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:13:54,736:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 3.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:13:54,876:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:13:54,895:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=7.272e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,898:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=5.642e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,915:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:13:54,919:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=7.021e+01, with an active set of 148 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,921:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.972e+01, with an active set of 152 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,921:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=6.944e+01, with an active set of 153 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,923:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.852e+01, with an active set of 158 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,925:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=6.543e+01, with an active set of 162 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,926:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 185 iterations, i.e. alpha=6.465e+01, with an active set of 165 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,928:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 192 iterations, i.e. alpha=6.164e+01, with an active set of 171 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,929:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 192 iterations, i.e. alpha=6.138e+01, with an active set of 171 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,930:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 195 iterations, i.e. alpha=6.112e+01, with an active set of 174 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,930:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=9.539e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,932:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 200 iterations, i.e. alpha=6.084e+01, with an active set of 178 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,932:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 201 iterations, i.e. alpha=5.998e+01, with an active set of 179 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,933:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 202 iterations, i.e. alpha=5.758e+01, with an active set of 180 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,933:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 202 iterations, i.e. alpha=5.653e+01, with an active set of 180 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,934:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=6.217e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,934:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=5.566e+01, with an active set of 181 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,935:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=5.538e+01, with an active set of 182 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,937:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=5.244e+01, with an active set of 188 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,937:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=5.227e+01, with an active set of 188 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,938:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=5.190e+01, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,939:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 213 iterations, i.e. alpha=4.938e+01, with an active set of 191 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,939:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 213 iterations, i.e. alpha=4.733e+01, with an active set of 191 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,940:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=4.700e+01, with an active set of 193 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,942:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=4.649e+01, with an active set of 198 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,943:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=5.227e+01, with an active set of 200 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,943:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=4.059e+01, with an active set of 200 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,945:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 226 iterations, i.e. alpha=3.999e+01, with an active set of 202 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,945:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=3.947e+01, with an active set of 204 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,947:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=3.692e+01, with an active set of 208 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,947:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=3.627e+01, with an active set of 208 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,948:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=3.567e+01, with an active set of 208 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,948:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 233 iterations, i.e. alpha=3.485e+01, with an active set of 209 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,949:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 233 iterations, i.e. alpha=3.443e+01, with an active set of 209 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,950:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=5.448e+01, with an active set of 141 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,950:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=3.410e+01, with an active set of 212 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,951:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=3.317e+01, with an active set of 213 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,952:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=3.275e+01, with an active set of 213 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,953:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=3.233e+01, with an active set of 215 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,953:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=3.200e+01, with an active set of 215 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,954:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.160e+01, with an active set of 156 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,957:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=5.454e+01, with an active set of 163 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,959:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 191 iterations, i.e. alpha=5.242e+01, with an active set of 168 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,960:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=5.027e+01, with an active set of 173 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,962:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 201 iterations, i.e. alpha=4.859e+01, with an active set of 177 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,964:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=7.284e+01, with an active set of 181 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,968:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=1.695e+03, with an active set of 186 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,969:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=9.854e+02, with an active set of 188 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,970:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=8.636e+02, with an active set of 189 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,971:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=8.204e+02, with an active set of 190 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,972:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=7.087e+02, with an active set of 191 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,973:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=7.485e+02, with an active set of 193 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,977:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=7.142e+02, with an active set of 200 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,978:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=7.055e+02, with an active set of 200 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,980:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=6.988e+02, with an active set of 203 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,982:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=6.709e+02, with an active set of 206 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,982:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=6.640e+02, with an active set of 207 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,983:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=6.562e+02, with an active set of 207 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,984:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=6.345e+02, with an active set of 208 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,987:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=5.972e+02, with an active set of 211 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,988:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=5.695e+02, with an active set of 213 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,988:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=5.665e+02, with an active set of 213 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,990:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=1.065e+04, with an active set of 216 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,991:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=3.965e+03, with an active set of 216 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,991:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=3.802e+03, with an active set of 216 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,993:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=3.504e+03, with an active set of 218 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,994:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=3.296e+03, with an active set of 219 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,995:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=3.185e+03, with an active set of 219 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,995:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=3.181e+03, with an active set of 219 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,995:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=3.047e+03, with an active set of 220 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,996:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=2.896e+03, with an active set of 222 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,997:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=2.878e+03, with an active set of 222 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,997:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=2.745e+03, with an active set of 222 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,998:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.557e+03, with an active set of 223 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,998:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.556e+03, with an active set of 223 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:54,998:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.464e+03, with an active set of 223 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,000:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 271 iterations, i.e. alpha=2.288e+03, with an active set of 225 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,000:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 271 iterations, i.e. alpha=2.182e+03, with an active set of 225 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,001:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=2.115e+03, with an active set of 226 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,003:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.854e+03, with an active set of 227 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,004:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.733e+03, with an active set of 228 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,005:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.595e+03, with an active set of 229 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,005:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.575e+03, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,006:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.570e+03, with an active set of 229 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,006:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.550e+03, with an active set of 229 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,006:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=1.506e+03, with an active set of 229 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,007:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=1.426e+03, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,008:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.369e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,009:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.364e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,010:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.353e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,010:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.130e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,010:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.112e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,010:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.070e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 8.229e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,010:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=9.655e+02, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,011:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=8.464e+02, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,011:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=7.905e+02, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,011:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=7.897e+02, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,012:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=7.488e+02, with an active set of 232 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,012:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=6.767e+02, with an active set of 232 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,013:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=6.204e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,013:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:13:55,013:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=6.026e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,013:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=5.793e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,013:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=5.718e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,014:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=5.689e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,014:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=5.242e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,014:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=5.148e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,014:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=4.765e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,015:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=4.751e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,015:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=4.530e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,015:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=4.099e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,015:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=3.323e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 9.714e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,015:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=3.154e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,016:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=2.875e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,016:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=2.368e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,018:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=2.041e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,019:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=1.891e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,019:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=1.722e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,020:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=1.509e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,020:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=1.464e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,020:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=1.070e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,021:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=1.052e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,021:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=9.354e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,021:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=8.741e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,021:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=8.379e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,021:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=7.010e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,022:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=5.473e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,022:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=4.795e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 8.229e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,022:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=4.550e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,022:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=3.639e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,023:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=3.590e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,023:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=3.514e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,023:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=3.294e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,024:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=3.038e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,024:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=2.696e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,024:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=1.688e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,024:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=8.058e+00, with an active set of 233 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,033:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=7.955e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,038:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=6.923e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,043:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=6.472e+01, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,054:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:13:55,054:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=3.146e+02, with an active set of 145 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,055:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=3.142e+02, with an active set of 145 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,069:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=3.630e+02, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,070:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=3.786e+02, with an active set of 194 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,070:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=3.667e+02, with an active set of 194 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,073:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=9.309e+01, with an active set of 49 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,074:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=4.499e+02, with an active set of 201 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,076:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=4.273e+02, with an active set of 204 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,077:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=4.220e+02, with an active set of 206 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,078:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=6.433e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,078:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=6.432e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,087:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=5.284e+01, with an active set of 110 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,087:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=5.279e+01, with an active set of 110 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,091:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=5.033e+01, with an active set of 121 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,093:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=4.832e+01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,095:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=4.478e+01, with an active set of 138 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,096:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=4.452e+01, with an active set of 139 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,097:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=4.468e+01, with an active set of 142 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,101:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=4.276e+01, with an active set of 150 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,102:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.135e+01, with an active set of 152 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,104:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.036e+01, with an active set of 158 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,106:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=3.948e+01, with an active set of 163 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,106:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=3.919e+01, with an active set of 165 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,107:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 185 iterations, i.e. alpha=3.895e+01, with an active set of 166 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,107:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 185 iterations, i.e. alpha=3.877e+01, with an active set of 166 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,109:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 189 iterations, i.e. alpha=3.763e+01, with an active set of 170 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,109:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 190 iterations, i.e. alpha=3.759e+01, with an active set of 171 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,111:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 195 iterations, i.e. alpha=3.697e+01, with an active set of 175 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,119:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=4.172e+02, with an active set of 184 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,120:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=4.521e+02, with an active set of 185 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,121:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=3.049e+02, with an active set of 188 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,126:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=3.910e+04, with an active set of 196 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,131:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=1.092e+08, with an active set of 200 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,136:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=1.088e+08, with an active set of 208 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,141:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.196e+08, with an active set of 218 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,143:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 297 iterations, i.e. alpha=2.209e+08, with an active set of 220 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,144:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 298 iterations, i.e. alpha=1.816e+08, with an active set of 221 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,145:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 301 iterations, i.e. alpha=1.615e+08, with an active set of 222 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,146:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 301 iterations, i.e. alpha=1.588e+08, with an active set of 222 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,147:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=1.590e+08, with an active set of 224 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,151:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 311 iterations, i.e. alpha=1.580e+08, with an active set of 229 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,151:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 311 iterations, i.e. alpha=1.567e+08, with an active set of 229 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,151:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 311 iterations, i.e. alpha=1.509e+08, with an active set of 229 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,152:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 311 iterations, i.e. alpha=1.405e+08, with an active set of 229 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,152:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 311 iterations, i.e. alpha=1.376e+08, with an active set of 229 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,153:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 315 iterations, i.e. alpha=1.666e+08, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,154:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 316 iterations, i.e. alpha=1.474e+08, with an active set of 232 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,154:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 316 iterations, i.e. alpha=1.412e+08, with an active set of 232 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,155:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 316 iterations, i.e. alpha=1.353e+08, with an active set of 232 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,155:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 316 iterations, i.e. alpha=1.240e+08, with an active set of 232 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,155:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 316 iterations, i.e. alpha=1.117e+08, with an active set of 232 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,156:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 317 iterations, i.e. alpha=1.110e+08, with an active set of 233 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:55,283:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:13:55,503:INFO:Calculating mean and std
2023-06-26 05:13:55,504:INFO:Creating metrics dataframe
2023-06-26 05:13:55,650:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:13:55,715:INFO:Uploading results into container
2023-06-26 05:13:55,716:INFO:Uploading model into container now
2023-06-26 05:13:55,717:INFO:_master_model_container: 13
2023-06-26 05:13:55,717:INFO:_display_container: 2
2023-06-26 05:13:55,717:INFO:RandomForestRegressor(n_jobs=-1, random_state=4661)
2023-06-26 05:13:55,717:INFO:create_model() successfully completed......................................
2023-06-26 05:13:55,900:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:13:55,917:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:13:55,924:INFO:SubProcess create_model() end ==================================
2023-06-26 05:13:55,924:INFO:Creating metrics dataframe
2023-06-26 05:13:55,927:INFO:Initializing Extra Trees Regressor
2023-06-26 05:13:55,927:INFO:Total runtime is 7.6884264270464575 minutes
2023-06-26 05:13:55,928:INFO:SubProcess create_model() called ==================================
2023-06-26 05:13:55,928:INFO:Initializing create_model()
2023-06-26 05:13:55,928:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9C4C8E290>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:13:55,928:INFO:Checking exceptions
2023-06-26 05:13:55,928:INFO:Importing libraries
2023-06-26 05:13:55,928:INFO:Copying training dataset
2023-06-26 05:13:55,965:INFO:Defining folds
2023-06-26 05:13:55,965:INFO:Declaring metric variables
2023-06-26 05:13:55,966:INFO:Importing untrained model
2023-06-26 05:13:55,966:INFO:Extra Trees Regressor Imported successfully
2023-06-26 05:13:55,966:INFO:Starting cross validation
2023-06-26 05:13:55,981:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:13:56,101:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:13:56,145:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:13:56,159:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=7.426e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,161:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=5.385e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,171:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=2.079e+01, with an active set of 112 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,177:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 139 iterations, i.e. alpha=1.664e+01, with an active set of 134 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,180:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=1.441e+01, with an active set of 145 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,186:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.192e+01, with an active set of 162 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,188:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=1.042e+01, with an active set of 167 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,189:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=9.640e+00, with an active set of 171 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,191:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 185 iterations, i.e. alpha=9.375e+00, with an active set of 175 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,193:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 188 iterations, i.e. alpha=8.968e+00, with an active set of 177 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,194:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 190 iterations, i.e. alpha=9.182e+00, with an active set of 178 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,195:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 195 iterations, i.e. alpha=8.310e+00, with an active set of 182 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,196:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 195 iterations, i.e. alpha=8.302e+00, with an active set of 182 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,215:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=1.084e+12, with an active set of 213 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,215:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=9.646e+11, with an active set of 214 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,217:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 271 iterations, i.e. alpha=9.849e+11, with an active set of 216 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,219:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=9.137e+11, with an active set of 219 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,219:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=8.943e+11, with an active set of 219 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,219:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=8.335e+11, with an active set of 219 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,220:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=8.303e+11, with an active set of 222 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,222:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=3.321e+12, with an active set of 223 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,223:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=2.521e+12, with an active set of 223 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,223:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=2.433e+12, with an active set of 223 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,223:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=2.191e+12, with an active set of 223 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,223:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=2.162e+12, with an active set of 223 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,224:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.998e+12, with an active set of 226 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,225:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.947e+12, with an active set of 226 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,225:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.708e+12, with an active set of 227 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,226:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.706e+12, with an active set of 228 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,226:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.704e+12, with an active set of 228 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,227:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.652e+12, with an active set of 228 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,227:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.620e+12, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,227:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.453e+12, with an active set of 228 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,227:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.368e+12, with an active set of 228 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,227:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.221e+12, with an active set of 228 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,227:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.212e+12, with an active set of 228 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,228:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.116e+12, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,229:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.050e+12, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,229:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.046e+12, with an active set of 230 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,229:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.037e+12, with an active set of 230 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,229:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.024e+12, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,229:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.018e+12, with an active set of 230 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,229:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=9.185e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,230:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=8.603e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,230:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=8.524e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,230:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=8.185e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,230:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=7.631e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,230:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=7.553e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,230:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=7.284e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,231:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=7.101e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,231:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=6.711e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,231:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=6.391e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,231:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=6.238e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,231:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=5.602e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,231:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=5.556e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,231:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=5.486e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,232:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=5.105e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,232:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=4.934e+11, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,233:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=4.352e+11, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,233:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=3.892e+11, with an active set of 231 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,234:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=3.396e+11, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,234:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.867e+11, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,234:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.764e+11, with an active set of 231 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,234:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.656e+11, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,235:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=2.644e+11, with an active set of 232 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,235:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=2.554e+11, with an active set of 232 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,235:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=2.518e+11, with an active set of 232 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,236:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=2.330e+11, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,236:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=2.303e+11, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,236:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=2.274e+11, with an active set of 232 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,236:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=2.036e+11, with an active set of 232 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,236:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=1.832e+11, with an active set of 232 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,237:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.798e+11, with an active set of 233 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,237:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.787e+11, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,237:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.665e+11, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,238:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.515e+11, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,238:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.483e+11, with an active set of 233 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,238:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.439e+11, with an active set of 233 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,238:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.437e+11, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,238:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.423e+11, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,239:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.233e+11, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,239:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.143e+11, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,239:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.072e+11, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,239:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=9.476e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,240:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=7.092e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,240:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=6.978e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,240:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=6.975e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,240:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=6.051e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,241:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=5.539e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,241:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=5.400e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,242:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=5.386e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,242:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=5.093e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,242:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=5.010e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,242:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=4.063e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,243:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=3.990e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 8.816e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,243:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=3.903e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,243:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=3.588e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,243:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=3.444e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,243:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=3.081e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,244:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=3.032e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,244:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.760e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,244:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.516e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,244:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.461e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,244:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.196e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,245:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.113e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,245:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.956e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,245:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.929e+10, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,245:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=2.196e+09, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,245:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=1.545e+09, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,246:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=8.219e+08, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,246:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 293 iterations, i.e. alpha=5.011e+07, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,399:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:13:56,411:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:13:56,416:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=9.622e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,416:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=9.444e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,422:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=6.965e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,424:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=7.874e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,425:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=6.279e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,430:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=4.362e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,431:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:13:56,440:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=2.887e+01, with an active set of 124 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,441:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 137 iterations, i.e. alpha=2.751e+01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,448:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=7.711e+01, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,449:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.233e+01, with an active set of 158 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,450:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.188e+01, with an active set of 158 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,451:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=3.158e+01, with an active set of 160 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,453:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=3.031e+01, with an active set of 166 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,454:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=7.763e+01, with an active set of 91 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,455:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=2.633e+01, with an active set of 175 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,459:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=8.097e+01, with an active set of 109 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,459:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=2.808e+01, with an active set of 183 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,459:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=2.568e+01, with an active set of 183 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,461:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 214 iterations, i.e. alpha=2.499e+01, with an active set of 188 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,461:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 214 iterations, i.e. alpha=2.470e+01, with an active set of 188 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,464:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=2.309e+01, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,465:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.763e+02, with an active set of 92 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,466:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 226 iterations, i.e. alpha=2.124e+01, with an active set of 197 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,466:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=1.612e+02, with an active set of 94 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,466:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.769e+01, with an active set of 138 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,467:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=2.094e+01, with an active set of 200 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,467:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=2.023e+01, with an active set of 200 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,469:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=7.711e+01, with an active set of 144 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,470:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=2.018e+01, with an active set of 205 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,471:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=1.935e+01, with an active set of 205 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,472:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=1.930e+01, with an active set of 206 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,474:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=1.494e+02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,475:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=1.457e+02, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,476:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 191 iterations, i.e. alpha=8.270e+01, with an active set of 165 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,480:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=1.088e+02, with an active set of 176 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,482:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=5.712e+07, with an active set of 214 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,482:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=1.386e+02, with an active set of 142 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,484:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.372e+02, with an active set of 145 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,485:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=5.970e+07, with an active set of 217 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,486:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=1.022e+02, with an active set of 191 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,486:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=9.809e+01, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,487:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 226 iterations, i.e. alpha=9.680e+01, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,487:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=6.677e+07, with an active set of 221 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,488:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 188 iterations, i.e. alpha=1.253e+02, with an active set of 161 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,489:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=6.454e+07, with an active set of 224 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,489:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=6.159e+07, with an active set of 224 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,489:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=5.834e+07, with an active set of 224 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,489:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=5.522e+07, with an active set of 224 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,490:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=5.408e+07, with an active set of 224 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,490:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 195 iterations, i.e. alpha=1.204e+02, with an active set of 168 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,491:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=5.338e+07, with an active set of 227 regressors, and the smallest cholesky pivot element being 8.878e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,491:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=5.141e+07, with an active set of 227 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,491:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 238 iterations, i.e. alpha=9.230e+01, with an active set of 204 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,492:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 200 iterations, i.e. alpha=1.173e+02, with an active set of 173 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,492:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=4.916e+07, with an active set of 229 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,493:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=9.409e+01, with an active set of 208 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,493:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 205 iterations, i.e. alpha=1.117e+02, with an active set of 178 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,493:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=9.106e+01, with an active set of 208 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,493:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=9.090e+01, with an active set of 208 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,494:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 289 iterations, i.e. alpha=6.310e+07, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,495:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=6.204e+07, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,495:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=6.039e+07, with an active set of 232 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,495:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=8.846e+01, with an active set of 212 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,495:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 212 iterations, i.e. alpha=1.052e+02, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,496:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=8.695e+01, with an active set of 212 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,496:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=8.614e+01, with an active set of 212 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,497:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=9.175e+01, with an active set of 213 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,498:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=9.064e+01, with an active set of 213 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,498:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=8.552e+01, with an active set of 213 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,504:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=8.265e+01, with an active set of 221 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,521:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 214 iterations, i.e. alpha=1.022e+02, with an active set of 186 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,521:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 214 iterations, i.e. alpha=1.016e+02, with an active set of 186 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,523:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=9.658e+01, with an active set of 189 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,523:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=9.658e+01, with an active set of 189 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,523:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=9.573e+01, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,523:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=9.552e+01, with an active set of 189 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,523:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=9.460e+01, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,524:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=9.359e+01, with an active set of 189 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,525:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=9.230e+01, with an active set of 192 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,526:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 224 iterations, i.e. alpha=8.973e+01, with an active set of 195 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,538:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:13:56,544:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=2.354e+03, with an active set of 203 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,545:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=2.245e+03, with an active set of 204 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,550:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=2.037e+03, with an active set of 213 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,550:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=2.023e+03, with an active set of 213 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,550:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=1.843e+03, with an active set of 213 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,552:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.045e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,553:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=9.347e+01, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,554:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=1.799e+03, with an active set of 215 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,556:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=1.798e+03, with an active set of 218 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,557:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 271 iterations, i.e. alpha=1.788e+03, with an active set of 219 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,558:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.674e+03, with an active set of 220 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,558:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.627e+03, with an active set of 220 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,558:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.610e+03, with an active set of 220 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,559:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.593e+03, with an active set of 220 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,559:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.480e+03, with an active set of 220 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,559:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=1.473e+03, with an active set of 220 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,560:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=5.034e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,562:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=2.051e+03, with an active set of 223 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,562:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=2.047e+03, with an active set of 223 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,563:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.934e+03, with an active set of 224 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,564:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.924e+03, with an active set of 224 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,565:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=1.729e+03, with an active set of 227 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,566:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.688e+03, with an active set of 229 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,567:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=1.572e+03, with an active set of 229 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,574:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.540e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,575:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.359e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,576:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.348e+03, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,576:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.261e+03, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,576:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.191e+03, with an active set of 232 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,576:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=1.101e+03, with an active set of 232 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,577:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=1.046e+03, with an active set of 233 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,577:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=9.547e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,578:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=9.422e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,578:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=9.358e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,578:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=9.010e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,578:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=8.204e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,579:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=7.815e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,579:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=7.626e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,579:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=7.483e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,579:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=6.776e+02, with an active set of 233 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,580:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=6.521e+02, with an active set of 236 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,581:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=5.327e+02, with an active set of 236 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,581:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=5.024e+02, with an active set of 236 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,581:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=4.889e+02, with an active set of 236 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,582:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=4.326e+02, with an active set of 236 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,582:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=3.062e+02, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,582:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.842e+02, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,583:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=2.698e+02, with an active set of 237 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,583:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=2.556e+02, with an active set of 237 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,583:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=2.177e+02, with an active set of 237 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,583:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=2.034e+02, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,589:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 298 iterations, i.e. alpha=2.810e+02, with an active set of 240 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,590:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=6.732e+01, with an active set of 113 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,590:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=6.676e+01, with an active set of 114 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,591:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 303 iterations, i.e. alpha=2.759e+02, with an active set of 243 regressors, and the smallest cholesky pivot element being 8.816e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,591:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=6.437e+01, with an active set of 117 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,592:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=6.377e+01, with an active set of 117 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,615:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=6.278e+01, with an active set of 125 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,627:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 224 iterations, i.e. alpha=2.509e+02, with an active set of 162 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,631:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=2.693e+02, with an active set of 173 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,632:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=2.644e+02, with an active set of 175 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,638:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=2.654e+02, with an active set of 192 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,640:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=2.622e+02, with an active set of 197 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,716:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-26 05:13:56,733:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=8.897e+01, with an active set of 49 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,736:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=6.696e+01, with an active set of 58 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,747:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=4.012e+01, with an active set of 102 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,755:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 139 iterations, i.e. alpha=6.430e+01, with an active set of 110 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,758:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=6.358e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,758:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=6.356e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,764:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=6.322e+01, with an active set of 133 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,765:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.209e+01, with an active set of 138 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,767:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=6.146e+01, with an active set of 143 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,768:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 183 iterations, i.e. alpha=6.023e+01, with an active set of 144 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,770:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 188 iterations, i.e. alpha=5.768e+01, with an active set of 148 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,774:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 205 iterations, i.e. alpha=5.685e+01, with an active set of 163 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,775:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 205 iterations, i.e. alpha=5.683e+01, with an active set of 163 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,777:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=5.675e+01, with an active set of 167 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,779:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=5.633e+01, with an active set of 173 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,781:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=5.732e+01, with an active set of 180 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,782:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=5.707e+01, with an active set of 184 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:56,794:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=2.196e+05, with an active set of 208 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:13:57,459:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:13:59,909:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:14:00,226:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 2.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:14:02,454:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 3.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:14:02,752:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 2.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:14:02,753:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 2.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:14:02,800:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 2.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:14:02,818:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 5.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:03,125:INFO:PyCaret RegressionExperiment
2023-06-26 05:14:03,125:INFO:Logging name: reg-default-name
2023-06-26 05:14:03,125:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-26 05:14:03,125:INFO:version 3.0.2
2023-06-26 05:14:03,125:INFO:Initializing setup()
2023-06-26 05:14:03,125:INFO:self.USI: b600
2023-06-26 05:14:03,126:INFO:self._variable_keys: {'log_plots_param', 'target_param', 'pipeline', 'y_train', 'memory', 'USI', 'exp_id', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'X_test', 'transform_target_param', 'data', 'logging_param', '_ml_usecase', 'idx', 'n_jobs_param', 'y', 'X', '_available_plots', 'gpu_param', 'X_train', 'exp_name_log', 'seed', 'html_param', 'fold_shuffle_param'}
2023-06-26 05:14:03,126:INFO:Checking environment
2023-06-26 05:14:03,126:INFO:python_version: 3.10.4
2023-06-26 05:14:03,126:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2023-06-26 05:14:03,126:INFO:machine: AMD64
2023-06-26 05:14:03,126:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-26 05:14:03,131:INFO:Memory: svmem(total=7969243136, available=1025597440, percent=87.1, used=6943645696, free=1025597440)
2023-06-26 05:14:03,131:INFO:Physical Core: 6
2023-06-26 05:14:03,131:INFO:Logical Core: 6
2023-06-26 05:14:03,131:INFO:Checking libraries
2023-06-26 05:14:03,131:INFO:System:
2023-06-26 05:14:03,132:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2023-06-26 05:14:03,132:INFO:executable: C:\New folder\python.exe
2023-06-26 05:14:03,132:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-26 05:14:03,132:INFO:PyCaret required dependencies:
2023-06-26 05:14:03,132:INFO:                 pip: 23.1.2
2023-06-26 05:14:03,132:INFO:          setuptools: 58.1.0
2023-06-26 05:14:03,132:INFO:             pycaret: 3.0.2
2023-06-26 05:14:03,132:INFO:             IPython: 8.7.0
2023-06-26 05:14:03,132:INFO:          ipywidgets: 8.0.3
2023-06-26 05:14:03,132:INFO:                tqdm: 4.65.0
2023-06-26 05:14:03,132:INFO:               numpy: 1.23.5
2023-06-26 05:14:03,132:INFO:              pandas: 1.5.3
2023-06-26 05:14:03,132:INFO:              jinja2: 3.1.0
2023-06-26 05:14:03,132:INFO:               scipy: 1.9.1
2023-06-26 05:14:03,132:INFO:              joblib: 1.2.0
2023-06-26 05:14:03,132:INFO:             sklearn: 1.1.2
2023-06-26 05:14:03,132:INFO:                pyod: 1.1.0
2023-06-26 05:14:03,132:INFO:            imblearn: 0.10.1
2023-06-26 05:14:03,132:INFO:   category_encoders: 2.6.1
2023-06-26 05:14:03,132:INFO:            lightgbm: 3.3.5
2023-06-26 05:14:03,133:INFO:               numba: 0.57.1
2023-06-26 05:14:03,133:INFO:            requests: 2.28.1
2023-06-26 05:14:03,133:INFO:          matplotlib: 3.7.1
2023-06-26 05:14:03,133:INFO:          scikitplot: 0.3.7
2023-06-26 05:14:03,133:INFO:         yellowbrick: 1.5
2023-06-26 05:14:03,133:INFO:              plotly: 5.15.0
2023-06-26 05:14:03,133:INFO:             kaleido: 0.2.1
2023-06-26 05:14:03,133:INFO:         statsmodels: 0.14.0
2023-06-26 05:14:03,133:INFO:              sktime: 0.17.0
2023-06-26 05:14:03,133:INFO:               tbats: 1.1.3
2023-06-26 05:14:03,133:INFO:            pmdarima: 2.0.3
2023-06-26 05:14:03,133:INFO:              psutil: 5.9.4
2023-06-26 05:14:03,133:INFO:PyCaret optional dependencies:
2023-06-26 05:14:03,133:INFO:                shap: Not installed
2023-06-26 05:14:03,133:INFO:           interpret: Not installed
2023-06-26 05:14:03,133:INFO:                umap: Not installed
2023-06-26 05:14:03,133:INFO:    pandas_profiling: 4.3.1
2023-06-26 05:14:03,133:INFO:  explainerdashboard: Not installed
2023-06-26 05:14:03,133:INFO:             autoviz: Not installed
2023-06-26 05:14:03,134:INFO:           fairlearn: Not installed
2023-06-26 05:14:03,134:INFO:             xgboost: 1.7.5
2023-06-26 05:14:03,134:INFO:            catboost: Not installed
2023-06-26 05:14:03,134:INFO:              kmodes: Not installed
2023-06-26 05:14:03,134:INFO:             mlxtend: Not installed
2023-06-26 05:14:03,134:INFO:       statsforecast: Not installed
2023-06-26 05:14:03,134:INFO:        tune_sklearn: Not installed
2023-06-26 05:14:03,134:INFO:                 ray: Not installed
2023-06-26 05:14:03,134:INFO:            hyperopt: Not installed
2023-06-26 05:14:03,134:INFO:              optuna: Not installed
2023-06-26 05:14:03,134:INFO:               skopt: Not installed
2023-06-26 05:14:03,134:INFO:              mlflow: Not installed
2023-06-26 05:14:03,134:INFO:              gradio: Not installed
2023-06-26 05:14:03,134:INFO:             fastapi: Not installed
2023-06-26 05:14:03,134:INFO:             uvicorn: Not installed
2023-06-26 05:14:03,134:INFO:              m2cgen: Not installed
2023-06-26 05:14:03,134:INFO:           evidently: Not installed
2023-06-26 05:14:03,134:INFO:               fugue: Not installed
2023-06-26 05:14:03,134:INFO:           streamlit: 1.23.1
2023-06-26 05:14:03,134:INFO:             prophet: Not installed
2023-06-26 05:14:03,134:INFO:None
2023-06-26 05:14:03,134:INFO:Set up data.
2023-06-26 05:14:04,064:INFO:Calculating mean and std
2023-06-26 05:14:04,065:WARNING:
2023-06-26 05:14:04,065:WARNING:
2023-06-26 05:14:04,065:WARNING:Processing:  60%|#########################4                | 49/81 [07:20<04:57,  9.31s/it]
2023-06-26 05:14:04,065:WARNING:[A[A
2023-06-26 05:14:04,065:INFO:Creating metrics dataframe
2023-06-26 05:14:04,546:WARNING:
2023-06-26 05:14:04,546:WARNING:
2023-06-26 05:14:04,546:WARNING:Processing:  62%|#########################9                | 50/81 [07:21<03:46,  7.30s/it]
2023-06-26 05:14:04,546:WARNING:[A[A
2023-06-26 05:14:04,546:INFO:Uploading results into container
2023-06-26 05:14:04,547:INFO:Uploading model into container now
2023-06-26 05:14:04,548:INFO:_master_model_container: 12
2023-06-26 05:14:04,548:INFO:_display_container: 2
2023-06-26 05:14:04,548:INFO:DecisionTreeRegressor(random_state=5040)
2023-06-26 05:14:04,548:INFO:create_model() successfully completed......................................
2023-06-26 05:14:04,902:INFO:SubProcess create_model() end ==================================
2023-06-26 05:14:04,902:INFO:Creating metrics dataframe
2023-06-26 05:14:04,905:INFO:Initializing Random Forest Regressor
2023-06-26 05:14:04,905:INFO:Total runtime is 7.361522205670674 minutes
2023-06-26 05:14:04,905:INFO:SubProcess create_model() called ==================================
2023-06-26 05:14:04,905:INFO:Initializing create_model()
2023-06-26 05:14:04,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BAAF63E0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BD66AE00>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:14:04,906:INFO:Checking exceptions
2023-06-26 05:14:04,906:INFO:Importing libraries
2023-06-26 05:14:04,906:INFO:Copying training dataset
2023-06-26 05:14:04,923:WARNING:
2023-06-26 05:14:04,923:WARNING:
2023-06-26 05:14:04,923:WARNING:Processing:  63%|##########################4               | 51/81 [07:21<02:48,  5.60s/it]
2023-06-26 05:14:04,923:WARNING:[A[A
2023-06-26 05:14:04,923:INFO:Defining folds
2023-06-26 05:14:04,923:INFO:Declaring metric variables
2023-06-26 05:14:04,924:INFO:Importing untrained model
2023-06-26 05:14:04,924:INFO:Random Forest Regressor Imported successfully
2023-06-26 05:14:04,924:INFO:Starting cross validation
2023-06-26 05:14:04,967:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:14:05,070:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:14:05,142:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:05,520:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:14:07,606:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:14:07,664:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:14:07,820:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:14:09,033:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:14:10,776:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:14:10,881:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:14:11,244:INFO:Calculating mean and std
2023-06-26 05:14:11,244:WARNING:
2023-06-26 05:14:11,245:WARNING:
2023-06-26 05:14:11,245:WARNING:
2023-06-26 05:14:11,245:WARNING:Processing:  26%|##########8                               | 21/81 [03:26<08:59,  8.99s/it]
2023-06-26 05:14:11,245:WARNING:[A[A[A
2023-06-26 05:14:11,245:INFO:Creating metrics dataframe
2023-06-26 05:14:11,389:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 5.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:11,558:WARNING:
2023-06-26 05:14:11,559:WARNING:
2023-06-26 05:14:11,559:WARNING:
2023-06-26 05:14:11,559:WARNING:Processing:  27%|###########4                              | 22/81 [03:26<06:53,  7.01s/it]
2023-06-26 05:14:11,559:WARNING:[A[A[A
2023-06-26 05:14:11,559:INFO:Uploading results into container
2023-06-26 05:14:11,560:INFO:Uploading model into container now
2023-06-26 05:14:11,560:INFO:_master_model_container: 5
2023-06-26 05:14:11,560:INFO:_display_container: 2
2023-06-26 05:14:11,560:INFO:Lars(random_state=637)
2023-06-26 05:14:11,560:INFO:create_model() successfully completed......................................
2023-06-26 05:14:11,765:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:11,835:INFO:SubProcess create_model() end ==================================
2023-06-26 05:14:11,835:INFO:Creating metrics dataframe
2023-06-26 05:14:11,839:INFO:Initializing Lasso Least Angle Regression
2023-06-26 05:14:11,839:INFO:Total runtime is 3.444442729155223 minutes
2023-06-26 05:14:11,839:INFO:SubProcess create_model() called ==================================
2023-06-26 05:14:11,839:INFO:Initializing create_model()
2023-06-26 05:14:11,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD331F30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9BAF61FF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:14:11,839:INFO:Checking exceptions
2023-06-26 05:14:11,840:INFO:Importing libraries
2023-06-26 05:14:11,840:INFO:Copying training dataset
2023-06-26 05:14:11,860:WARNING:
2023-06-26 05:14:11,860:WARNING:
2023-06-26 05:14:11,860:WARNING:
2023-06-26 05:14:11,860:WARNING:Processing:  28%|###########9                              | 23/81 [03:26<05:11,  5.37s/it]
2023-06-26 05:14:11,860:WARNING:[A[A[A
2023-06-26 05:14:11,860:INFO:Defining folds
2023-06-26 05:14:11,860:INFO:Declaring metric variables
2023-06-26 05:14:11,861:INFO:Importing untrained model
2023-06-26 05:14:11,861:INFO:Lasso Least Angle Regression Imported successfully
2023-06-26 05:14:11,861:INFO:Starting cross validation
2023-06-26 05:14:11,885:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:14:13,050:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:13,259:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:14:13,880:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:14:14,158:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:14:18,059:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 3.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:14:18,847:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:14:19,012:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:14:19,278:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 7.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:19,296:INFO:PyCaret RegressionExperiment
2023-06-26 05:14:19,296:INFO:Logging name: reg-default-name
2023-06-26 05:14:19,296:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-26 05:14:19,296:INFO:version 3.0.2
2023-06-26 05:14:19,296:INFO:Initializing setup()
2023-06-26 05:14:19,296:INFO:self.USI: e21e
2023-06-26 05:14:19,296:INFO:self._variable_keys: {'log_plots_param', 'target_param', 'pipeline', 'y_train', 'memory', 'USI', 'exp_id', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'X_test', 'transform_target_param', 'data', 'logging_param', '_ml_usecase', 'idx', 'n_jobs_param', 'y', 'X', '_available_plots', 'gpu_param', 'X_train', 'exp_name_log', 'seed', 'html_param', 'fold_shuffle_param'}
2023-06-26 05:14:19,297:INFO:Checking environment
2023-06-26 05:14:19,297:INFO:python_version: 3.10.4
2023-06-26 05:14:19,297:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2023-06-26 05:14:19,297:INFO:machine: AMD64
2023-06-26 05:14:19,297:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-26 05:14:19,302:INFO:Memory: svmem(total=7969243136, available=948404224, percent=88.1, used=7020838912, free=948404224)
2023-06-26 05:14:19,302:INFO:Physical Core: 6
2023-06-26 05:14:19,302:INFO:Logical Core: 6
2023-06-26 05:14:19,302:INFO:Checking libraries
2023-06-26 05:14:19,302:INFO:System:
2023-06-26 05:14:19,302:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2023-06-26 05:14:19,302:INFO:executable: C:\New folder\python.exe
2023-06-26 05:14:19,302:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-26 05:14:19,302:INFO:PyCaret required dependencies:
2023-06-26 05:14:19,302:INFO:                 pip: 23.1.2
2023-06-26 05:14:19,302:INFO:          setuptools: 58.1.0
2023-06-26 05:14:19,302:INFO:             pycaret: 3.0.2
2023-06-26 05:14:19,302:INFO:             IPython: 8.7.0
2023-06-26 05:14:19,302:INFO:          ipywidgets: 8.0.3
2023-06-26 05:14:19,302:INFO:                tqdm: 4.65.0
2023-06-26 05:14:19,302:INFO:               numpy: 1.23.5
2023-06-26 05:14:19,302:INFO:              pandas: 1.5.3
2023-06-26 05:14:19,302:INFO:              jinja2: 3.1.0
2023-06-26 05:14:19,303:INFO:               scipy: 1.9.1
2023-06-26 05:14:19,303:INFO:              joblib: 1.2.0
2023-06-26 05:14:19,303:INFO:             sklearn: 1.1.2
2023-06-26 05:14:19,303:INFO:                pyod: 1.1.0
2023-06-26 05:14:19,303:INFO:            imblearn: 0.10.1
2023-06-26 05:14:19,303:INFO:   category_encoders: 2.6.1
2023-06-26 05:14:19,303:INFO:            lightgbm: 3.3.5
2023-06-26 05:14:19,303:INFO:               numba: 0.57.1
2023-06-26 05:14:19,303:INFO:            requests: 2.28.1
2023-06-26 05:14:19,303:INFO:          matplotlib: 3.7.1
2023-06-26 05:14:19,303:INFO:          scikitplot: 0.3.7
2023-06-26 05:14:19,303:INFO:         yellowbrick: 1.5
2023-06-26 05:14:19,303:INFO:              plotly: 5.15.0
2023-06-26 05:14:19,303:INFO:             kaleido: 0.2.1
2023-06-26 05:14:19,303:INFO:         statsmodels: 0.14.0
2023-06-26 05:14:19,303:INFO:              sktime: 0.17.0
2023-06-26 05:14:19,303:INFO:               tbats: 1.1.3
2023-06-26 05:14:19,303:INFO:            pmdarima: 2.0.3
2023-06-26 05:14:19,303:INFO:              psutil: 5.9.4
2023-06-26 05:14:19,303:INFO:PyCaret optional dependencies:
2023-06-26 05:14:19,303:INFO:                shap: Not installed
2023-06-26 05:14:19,303:INFO:           interpret: Not installed
2023-06-26 05:14:19,303:INFO:                umap: Not installed
2023-06-26 05:14:19,303:INFO:    pandas_profiling: 4.3.1
2023-06-26 05:14:19,303:INFO:  explainerdashboard: Not installed
2023-06-26 05:14:19,303:INFO:             autoviz: Not installed
2023-06-26 05:14:19,303:INFO:           fairlearn: Not installed
2023-06-26 05:14:19,303:INFO:             xgboost: 1.7.5
2023-06-26 05:14:19,303:INFO:            catboost: Not installed
2023-06-26 05:14:19,304:INFO:              kmodes: Not installed
2023-06-26 05:14:19,304:INFO:             mlxtend: Not installed
2023-06-26 05:14:19,304:INFO:       statsforecast: Not installed
2023-06-26 05:14:19,304:INFO:        tune_sklearn: Not installed
2023-06-26 05:14:19,304:INFO:                 ray: Not installed
2023-06-26 05:14:19,304:INFO:            hyperopt: Not installed
2023-06-26 05:14:19,304:INFO:              optuna: Not installed
2023-06-26 05:14:19,304:INFO:               skopt: Not installed
2023-06-26 05:14:19,304:INFO:              mlflow: Not installed
2023-06-26 05:14:19,304:INFO:              gradio: Not installed
2023-06-26 05:14:19,304:INFO:             fastapi: Not installed
2023-06-26 05:14:19,304:INFO:             uvicorn: Not installed
2023-06-26 05:14:19,304:INFO:              m2cgen: Not installed
2023-06-26 05:14:19,304:INFO:           evidently: Not installed
2023-06-26 05:14:19,304:INFO:               fugue: Not installed
2023-06-26 05:14:19,304:INFO:           streamlit: 1.23.1
2023-06-26 05:14:19,304:INFO:             prophet: Not installed
2023-06-26 05:14:19,304:INFO:None
2023-06-26 05:14:19,304:INFO:Set up data.
2023-06-26 05:14:19,963:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:20,234:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:20,451:INFO:Calculating mean and std
2023-06-26 05:14:20,647:INFO:Creating metrics dataframe
2023-06-26 05:14:20,961:INFO:Uploading results into container
2023-06-26 05:14:20,962:INFO:Uploading model into container now
2023-06-26 05:14:20,962:INFO:_master_model_container: 14
2023-06-26 05:14:20,962:INFO:_display_container: 2
2023-06-26 05:14:20,963:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4661)
2023-06-26 05:14:20,963:INFO:create_model() successfully completed......................................
2023-06-26 05:14:21,290:INFO:SubProcess create_model() end ==================================
2023-06-26 05:14:21,290:INFO:Creating metrics dataframe
2023-06-26 05:14:21,293:INFO:Initializing AdaBoost Regressor
2023-06-26 05:14:21,293:INFO:Total runtime is 8.111196271578471 minutes
2023-06-26 05:14:21,293:INFO:SubProcess create_model() called ==================================
2023-06-26 05:14:21,294:INFO:Initializing create_model()
2023-06-26 05:14:21,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B9BD287E50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B9C4C8E290>, model_only=True, return_train_score=False, kwargs={})
2023-06-26 05:14:21,294:INFO:Checking exceptions
2023-06-26 05:14:21,294:INFO:Importing libraries
2023-06-26 05:14:21,294:INFO:Copying training dataset
2023-06-26 05:14:21,356:INFO:Defining folds
2023-06-26 05:14:21,356:INFO:Declaring metric variables
2023-06-26 05:14:21,361:INFO:Importing untrained model
2023-06-26 05:14:21,361:INFO:AdaBoost Regressor Imported successfully
2023-06-26 05:14:21,362:INFO:Starting cross validation
2023-06-26 05:14:21,369:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-26 05:14:21,617:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:22,279:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:14:24,897:WARNING:Summarize dataset:   0%|                                             | 0/5 [00:00<?, ?it/s]
2023-06-26 05:14:26,550:WARNING:Summarize dataset:   0%|               | 0/19 [00:01<?, ?it/s, Describe variable:CryoSleep]
2023-06-26 05:14:26,555:WARNING:Summarize dataset:   5%|3      | 1/19 [00:01<00:29,  1.65s/it, Describe variable:CryoSleep]
2023-06-26 05:14:26,826:WARNING:Summarize dataset:   5%|6            | 1/19 [00:01<00:29,  1.65s/it, Describe variable:VIP]
2023-06-26 05:14:26,842:WARNING:Summarize dataset:  11%|#3           | 2/19 [00:01<00:14,  1.17it/s, Describe variable:VIP]
2023-06-26 05:14:26,843:WARNING:Summarize dataset:  11%|6     | 2/19 [00:01<00:14,  1.17it/s, Describe variable:HomePlanet]
2023-06-26 05:14:26,848:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:14:26,854:WARNING:Summarize dataset:  16%|#7         | 3/19 [00:01<00:13,  1.17it/s, Describe variable:Cabin]
2023-06-26 05:14:26,861:WARNING:Summarize dataset:  21%|#    | 4/19 [00:01<00:12,  1.17it/s, Describe variable:Destination]
2023-06-26 05:14:26,863:WARNING:Summarize dataset:  26%|#3   | 5/19 [00:01<00:11,  1.17it/s, Describe variable:PassengerId]
2023-06-26 05:14:26,876:WARNING:Summarize dataset:  32%|#5   | 6/19 [00:01<00:11,  1.17it/s, Describe variable:RoomService]
2023-06-26 05:14:26,878:WARNING:Summarize dataset:  37%|##5    | 7/19 [00:01<00:10,  1.17it/s, Describe variable:FoodCourt]
2023-06-26 05:14:26,880:WARNING:Summarize dataset:  42%|##1  | 8/19 [00:01<00:09,  1.17it/s, Describe variable:Transported]
2023-06-26 05:14:26,892:WARNING:Summarize dataset:  47%|######1      | 9/19 [00:01<00:08,  1.17it/s, Describe variable:Spa]
2023-06-26 05:14:26,894:WARNING:Summarize dataset:  53%|#5 | 10/19 [00:01<00:07,  1.17it/s, Describe variable:ShoppingMall]
2023-06-26 05:14:26,896:WARNING:Summarize dataset:  58%|######3    | 11/19 [00:01<00:06,  1.17it/s, Describe variable:Name]
2023-06-26 05:14:26,898:WARNING:Summarize dataset:  63%|#####6   | 12/19 [00:02<00:05,  1.17it/s, Describe variable:VRDeck]
2023-06-26 05:14:26,907:WARNING:Summarize dataset:  68%|########2   | 13/19 [00:02<00:05,  1.17it/s, Describe variable:Age]
2023-06-26 05:14:26,909:WARNING:Summarize dataset:  74%|###########    | 14/19 [00:02<00:04,  1.17it/s, Get variable types]
2023-06-26 05:14:26,910:WARNING:Summarize dataset:  71%|#####  | 15/21 [00:02<00:05,  1.17it/s, Calculate auto correlation]
2023-06-26 05:14:27,052:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 5.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:27,522:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:27,873:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 7.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:27,999:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:28,062:WARNING:Summarize dataset:  76%|#####3 | 16/21 [00:03<00:00,  6.80it/s, Calculate auto correlation]
2023-06-26 05:14:28,063:WARNING:Summarize dataset:  76%|###########4   | 16/21 [00:03<00:00,  6.80it/s, Get scatter matrix]
2023-06-26 05:14:28,063:WARNING:Summarize dataset:  28%|####7            | 16/57 [00:03<00:06,  6.80it/s, scatter Age, Age]
2023-06-26 05:14:28,279:WARNING:Summarize dataset:  30%|#####            | 17/57 [00:03<00:06,  6.53it/s, scatter Age, Age]
2023-06-26 05:14:28,280:WARNING:Summarize dataset:  30%|##6      | 17/57 [00:03<00:06,  6.53it/s, scatter RoomService, Age]
2023-06-26 05:14:28,547:WARNING:Summarize dataset:  32%|##8      | 18/57 [00:03<00:06,  6.04it/s, scatter RoomService, Age]
2023-06-26 05:14:28,580:WARNING:Summarize dataset:  32%|###4       | 18/57 [00:03<00:06,  6.04it/s, scatter FoodCourt, Age]
2023-06-26 05:14:28,807:WARNING:Summarize dataset:  33%|###6       | 19/57 [00:03<00:06,  5.61it/s, scatter FoodCourt, Age]
2023-06-26 05:14:28,807:WARNING:Summarize dataset:  33%|##6     | 19/57 [00:03<00:06,  5.61it/s, scatter ShoppingMall, Age]
2023-06-26 05:14:28,996:WARNING:Summarize dataset:  35%|##8     | 20/57 [00:04<00:06,  5.55it/s, scatter ShoppingMall, Age]
2023-06-26 05:14:28,996:WARNING:Summarize dataset:  35%|#####9           | 20/57 [00:04<00:06,  5.55it/s, scatter Spa, Age]
2023-06-26 05:14:29,230:WARNING:Summarize dataset:  37%|######2          | 21/57 [00:04<00:06,  5.26it/s, scatter Spa, Age]
2023-06-26 05:14:29,231:WARNING:Summarize dataset:  37%|#####1        | 21/57 [00:04<00:06,  5.26it/s, scatter VRDeck, Age]
2023-06-26 05:14:29,408:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:14:29,445:WARNING:Summarize dataset:  39%|#####4        | 22/57 [00:04<00:06,  5.11it/s, scatter VRDeck, Age]
2023-06-26 05:14:29,446:WARNING:Summarize dataset:  39%|###4     | 22/57 [00:04<00:06,  5.11it/s, scatter Age, RoomService]
2023-06-26 05:14:29,538:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.151e+01, with an active set of 147 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:29,544:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 188 iterations, i.e. alpha=8.400e+00, with an active set of 168 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:29,548:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 195 iterations, i.e. alpha=7.052e+00, with an active set of 173 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:29,569:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 208 iterations, alpha=5.568e+00, previous alpha=5.368e+00, with an active set of 185 regressors.
  warnings.warn(

2023-06-26 05:14:29,674:WARNING:Summarize dataset:  40%|###6     | 23/57 [00:04<00:06,  4.92it/s, scatter Age, RoomService]
2023-06-26 05:14:29,675:WARNING:Summarize dataset:  40%|4| 23/57 [00:04<00:06,  4.92it/s, scatter RoomService, RoomService]
2023-06-26 05:14:30,266:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:14:31,197:WARNING:Summarize dataset:  42%|4| 24/57 [00:06<00:17,  1.88it/s, scatter RoomService, RoomService]
2023-06-26 05:14:31,199:WARNING:Summarize dataset:  42%|#2 | 24/57 [00:06<00:17,  1.88it/s, scatter FoodCourt, RoomService]
2023-06-26 05:14:31,898:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:31,969:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:33,439:WARNING:Summarize dataset:  44%|#3 | 25/57 [00:08<00:31,  1.02it/s, scatter FoodCourt, RoomService]
2023-06-26 05:14:33,441:WARNING:Summarize dataset:  44%|4| 25/57 [00:08<00:31,  1.02it/s, scatter ShoppingMall, RoomService
2023-06-26 05:14:34,063:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:14:34,065:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 2.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:14:34,841:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:14:34,851:WARNING:Summarize dataset:  46%|4| 26/57 [00:09<00:34,  1.10s/it, scatter ShoppingMall, RoomService
2023-06-26 05:14:34,852:WARNING:Summarize dataset:  46%|####1    | 26/57 [00:09<00:34,  1.10s/it, scatter Spa, RoomService]
2023-06-26 05:14:34,978:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 6.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:35,040:WARNING:Summarize dataset:  47%|####2    | 27/57 [00:10<00:25,  1.19it/s, scatter Spa, RoomService]
2023-06-26 05:14:35,040:WARNING:Summarize dataset:  47%|##8   | 27/57 [00:10<00:25,  1.19it/s, scatter VRDeck, RoomService]
2023-06-26 05:14:35,140:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:14:35,198:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=1.078e+01, with an active set of 146 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:35,198:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=1.078e+01, with an active set of 146 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:35,212:WARNING:Summarize dataset:  49%|##9   | 28/57 [00:10<00:18,  1.54it/s, scatter VRDeck, RoomService]
2023-06-26 05:14:35,212:WARNING:Summarize dataset:  49%|#####4     | 28/57 [00:10<00:18,  1.54it/s, scatter Age, FoodCourt]
2023-06-26 05:14:35,218:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:14:35,219:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=5.419e+00, with an active set of 190 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:35,220:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 205 iterations, i.e. alpha=5.383e+00, with an active set of 191 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:35,223:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 209 iterations, alpha=4.614e+00, previous alpha=4.570e+00, with an active set of 194 regressors.
  warnings.warn(

2023-06-26 05:14:35,262:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=9.103e+00, with an active set of 159 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:35,270:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 198 iterations, i.e. alpha=6.957e+00, with an active set of 172 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:35,271:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 199 iterations, i.e. alpha=6.954e+00, with an active set of 173 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:35,271:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 199 iterations, i.e. alpha=6.954e+00, with an active set of 173 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:35,271:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 199 iterations, i.e. alpha=6.954e+00, with an active set of 173 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:35,273:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 202 iterations, alpha=6.531e+00, previous alpha=6.504e+00, with an active set of 175 regressors.
  warnings.warn(

2023-06-26 05:14:35,396:WARNING:Summarize dataset:  51%|#####5     | 29/57 [00:10<00:14,  1.94it/s, scatter Age, FoodCourt]
2023-06-26 05:14:35,396:WARNING:Summarize dataset:  51%|#5 | 29/57 [00:10<00:14,  1.94it/s, scatter RoomService, FoodCourt]
2023-06-26 05:14:35,536:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:14:35,576:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=1.371e+01, with an active set of 135 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:35,578:WARNING:Summarize dataset:  53%|#5 | 30/57 [00:10<00:11,  2.39it/s, scatter RoomService, FoodCourt]
2023-06-26 05:14:35,578:WARNING:Summarize dataset:  53%|##6  | 30/57 [00:10<00:11,  2.39it/s, scatter FoodCourt, FoodCourt]
2023-06-26 05:14:35,588:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=9.625e+00, with an active set of 157 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:35,607:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 224 iterations, i.e. alpha=3.629e+00, with an active set of 198 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:35,617:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=2.891e+00, with an active set of 203 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:35,619:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 241 iterations, alpha=2.570e+00, previous alpha=2.424e+00, with an active set of 206 regressors.
  warnings.warn(

2023-06-26 05:14:35,737:WARNING:Summarize dataset:  54%|##7  | 31/57 [00:10<00:08,  2.93it/s, scatter FoodCourt, FoodCourt]
2023-06-26 05:14:35,738:WARNING:Summarize dataset:  54%|# | 31/57 [00:10<00:08,  2.93it/s, scatter ShoppingMall, FoodCourt]
2023-06-26 05:14:35,902:WARNING:Summarize dataset:  56%|#1| 32/57 [00:11<00:07,  3.46it/s, scatter ShoppingMall, FoodCourt]
2023-06-26 05:14:35,902:WARNING:Summarize dataset:  56%|######1    | 32/57 [00:11<00:07,  3.46it/s, scatter Spa, FoodCourt]
2023-06-26 05:14:35,940:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:14:35,980:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=1.434e+01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:35,980:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=1.433e+01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:35,985:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=1.229e+01, with an active set of 141 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:35,986:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:14:36,004:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=7.163e+00, with an active set of 169 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,004:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=7.163e+00, with an active set of 169 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,005:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=7.085e+00, with an active set of 169 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,009:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 203 iterations, alpha=6.412e+00, previous alpha=6.306e+00, with an active set of 176 regressors.
  warnings.warn(

2023-06-26 05:14:36,032:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=1.325e+01, with an active set of 133 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,036:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.213e+01, with an active set of 139 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,036:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.212e+01, with an active set of 139 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,038:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 163 iterations, i.e. alpha=1.093e+01, with an active set of 143 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,045:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 175 iterations, alpha=8.858e+00, previous alpha=8.841e+00, with an active set of 154 regressors.
  warnings.warn(

2023-06-26 05:14:36,072:WARNING:Summarize dataset:  58%|######3    | 33/57 [00:11<00:06,  3.94it/s, scatter Spa, FoodCourt]
2023-06-26 05:14:36,072:WARNING:Summarize dataset:  58%|####6   | 33/57 [00:11<00:06,  3.94it/s, scatter VRDeck, FoodCourt]
2023-06-26 05:14:36,126:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:36,188:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:36,223:WARNING:Summarize dataset:  60%|####7   | 34/57 [00:11<00:05,  4.48it/s, scatter VRDeck, FoodCourt]
2023-06-26 05:14:36,223:WARNING:Summarize dataset:  60%|####7   | 34/57 [00:11<00:05,  4.48it/s, scatter Age, ShoppingMall]
2023-06-26 05:14:36,353:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:14:36,399:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=2.696e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,412:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.998e+01, with an active set of 110 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,418:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=1.773e+01, with an active set of 118 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,423:WARNING:Summarize dataset:  61%|####9   | 35/57 [00:11<00:04,  4.63it/s, scatter Age, ShoppingMall]
2023-06-26 05:14:36,423:WARNING:Summarize dataset:  61%|6| 35/57 [00:11<00:04,  4.63it/s, scatter RoomService, ShoppingMall
2023-06-26 05:14:36,440:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=9.201e+00, with an active set of 162 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,471:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 238 iterations, i.e. alpha=3.574e+00, with an active set of 198 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,472:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=3.487e+00, with an active set of 199 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,473:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=3.281e+00, with an active set of 200 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,474:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=3.199e+00, with an active set of 200 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,475:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=3.016e+00, with an active set of 200 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,476:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=2.728e+00, with an active set of 200 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,477:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=2.634e+00, with an active set of 201 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,477:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=2.621e+00, with an active set of 201 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:36,480:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 247 iterations, alpha=3.062e+00, previous alpha=2.348e+00, with an active set of 204 regressors.
  warnings.warn(

2023-06-26 05:14:36,612:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:36,641:WARNING:Summarize dataset:  63%|6| 36/57 [00:11<00:04,  4.62it/s, scatter RoomService, ShoppingMall
2023-06-26 05:14:36,641:WARNING:Summarize dataset:  63%|#2| 36/57 [00:11<00:04,  4.62it/s, scatter FoodCourt, ShoppingMall]
2023-06-26 05:14:36,776:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:14:36,777:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:36,791:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:14:37,296:WARNING:Summarize dataset:  65%|#2| 37/57 [00:12<00:06,  2.88it/s, scatter FoodCourt, ShoppingMall]
2023-06-26 05:14:37,299:WARNING:Summarize dataset:  65%|6| 37/57 [00:12<00:06,  2.88it/s, scatter ShoppingMall, ShoppingMal
2023-06-26 05:14:37,771:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=1.232e+01, with an active set of 135 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:38,047:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=1.138e+01, with an active set of 145 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:38,062:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.063e+01, with an active set of 149 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:38,074:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 162 iterations, i.e. alpha=1.016e+01, with an active set of 152 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:38,303:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 192 iterations, i.e. alpha=6.199e+00, with an active set of 166 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:38,668:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 192 iterations, i.e. alpha=6.889e+00, with an active set of 170 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:38,677:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=6.731e+00, with an active set of 172 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:38,679:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=6.716e+00, with an active set of 172 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:38,746:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 199 iterations, i.e. alpha=6.459e+00, with an active set of 177 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:38,757:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 222 iterations, i.e. alpha=2.922e+00, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:38,787:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 228 iterations, alpha=2.716e+00, previous alpha=2.715e+00, with an active set of 197 regressors.
  warnings.warn(

2023-06-26 05:14:38,811:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 207 iterations, alpha=4.937e+00, previous alpha=4.919e+00, with an active set of 184 regressors.
  warnings.warn(

2023-06-26 05:14:40,064:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:14:40,064:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:14:40,333:WARNING:Summarize dataset:  67%|6| 38/57 [00:15<00:21,  1.15s/it, scatter ShoppingMall, ShoppingMal
2023-06-26 05:14:40,335:WARNING:Summarize dataset:  67%|#####3  | 38/57 [00:15<00:21,  1.15s/it, scatter Spa, ShoppingMall]
2023-06-26 05:14:40,674:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 2.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:14:41,812:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 5.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:41,900:WARNING:Summarize dataset:  68%|#####4  | 39/57 [00:17<00:22,  1.28s/it, scatter Spa, ShoppingMall]
2023-06-26 05:14:41,900:WARNING:Summarize dataset:  68%|###4 | 39/57 [00:17<00:22,  1.28s/it, scatter VRDeck, ShoppingMall]
2023-06-26 05:14:41,921:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:14:42,060:WARNING:Summarize dataset:  70%|###5 | 40/57 [00:17<00:16,  1.06it/s, scatter VRDeck, ShoppingMall]
2023-06-26 05:14:42,060:WARNING:Summarize dataset:  70%|###########9     | 40/57 [00:17<00:16,  1.06it/s, scatter Age, Spa]
2023-06-26 05:14:42,246:WARNING:Summarize dataset:  72%|############2    | 41/57 [00:17<00:11,  1.40it/s, scatter Age, Spa]
2023-06-26 05:14:42,246:WARNING:Summarize dataset:  72%|######4  | 41/57 [00:17<00:11,  1.40it/s, scatter RoomService, Spa]
2023-06-26 05:14:42,249:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 2.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:14:42,378:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-26 05:14:42,486:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=1.440e+01, with an active set of 136 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:42,489:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=1.310e+01, with an active set of 140 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:42,498:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=7.768e+00, with an active set of 162 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:42,509:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=4.897e+00, with an active set of 183 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:42,510:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=4.847e+00, with an active set of 183 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:42,513:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 214 iterations, i.e. alpha=4.180e+00, with an active set of 190 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:42,522:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=3.717e+00, with an active set of 195 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-26 05:14:42,524:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 222 iterations, alpha=3.959e+00, previous alpha=3.619e+00, with an active set of 197 regressors.
  warnings.warn(

2023-06-26 05:14:42,526:WARNING:Summarize dataset:  74%|######6  | 42/57 [00:17<00:08,  1.71it/s, scatter RoomService, Spa]
2023-06-26 05:14:42,526:WARNING:Summarize dataset:  74%|########1  | 42/57 [00:17<00:08,  1.71it/s, scatter FoodCourt, Spa]
2023-06-26 05:14:42,733:WARNING:Summarize dataset:  75%|########2  | 43/57 [00:17<00:06,  2.12it/s, scatter FoodCourt, Spa]
2023-06-26 05:14:42,733:WARNING:Summarize dataset:  75%|######  | 43/57 [00:17<00:06,  2.12it/s, scatter ShoppingMall, Spa]
2023-06-26 05:14:42,904:WARNING:Summarize dataset:  77%|######1 | 44/57 [00:18<00:04,  2.62it/s, scatter ShoppingMall, Spa]
2023-06-26 05:14:42,905:WARNING:Summarize dataset:  77%|#############1   | 44/57 [00:18<00:04,  2.62it/s, scatter Spa, Spa]
2023-06-26 05:14:43,002:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:43,071:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:43,095:WARNING:Summarize dataset:  79%|#############4   | 45/57 [00:18<00:03,  3.08it/s, scatter Spa, Spa]
2023-06-26 05:14:43,095:WARNING:Summarize dataset:  79%|###########   | 45/57 [00:18<00:03,  3.08it/s, scatter VRDeck, Spa]
2023-06-26 05:14:43,305:WARNING:Summarize dataset:  81%|###########2  | 46/57 [00:18<00:03,  3.45it/s, scatter VRDeck, Spa]
2023-06-26 05:14:43,306:WARNING:Summarize dataset:  81%|###########2  | 46/57 [00:18<00:03,  3.45it/s, scatter Age, VRDeck]
2023-06-26 05:14:43,510:WARNING:Summarize dataset:  82%|###########5  | 47/57 [00:18<00:02,  3.78it/s, scatter Age, VRDeck]
2023-06-26 05:14:43,510:WARNING:Summarize dataset:  82%|####9 | 47/57 [00:18<00:02,  3.78it/s, scatter RoomService, VRDeck]
2023-06-26 05:14:43,701:WARNING:Summarize dataset:  84%|##### | 48/57 [00:18<00:02,  4.12it/s, scatter RoomService, VRDeck]
2023-06-26 05:14:43,701:WARNING:Summarize dataset:  84%|######7 | 48/57 [00:18<00:02,  4.12it/s, scatter FoodCourt, VRDeck]
2023-06-26 05:14:43,861:WARNING:Summarize dataset:  86%|######8 | 49/57 [00:18<00:01,  4.59it/s, scatter FoodCourt, VRDeck]
2023-06-26 05:14:43,862:WARNING:Summarize dataset:  86%|####2| 49/57 [00:18<00:01,  4.59it/s, scatter ShoppingMall, VRDeck]
2023-06-26 05:14:44,052:WARNING:Summarize dataset:  88%|####3| 50/57 [00:19<00:01,  4.77it/s, scatter ShoppingMall, VRDeck]
2023-06-26 05:14:44,052:WARNING:Summarize dataset:  88%|############2 | 50/57 [00:19<00:01,  4.77it/s, scatter Spa, VRDeck]
2023-06-26 05:14:44,233:WARNING:Summarize dataset:  89%|############5 | 51/57 [00:19<00:01,  4.97it/s, scatter Spa, VRDeck]
2023-06-26 05:14:44,233:WARNING:Summarize dataset:  89%|#########8 | 51/57 [00:19<00:01,  4.97it/s, scatter VRDeck, VRDeck]
2023-06-26 05:14:44,296:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:44,374:WARNING:Summarize dataset:  91%|########## | 52/57 [00:19<00:00,  5.46it/s, scatter VRDeck, VRDeck]
2023-06-26 05:14:44,375:WARNING:Summarize dataset:  91%|########2| 52/57 [00:19<00:00,  5.46it/s, Get dataframe statistics]
2023-06-26 05:14:44,376:WARNING:Summarize dataset:  88%|############3 | 53/60 [00:19<00:01,  5.46it/s, Missing diagram bar]
2023-06-26 05:14:45,055:WARNING:Summarize dataset:  90%|############6 | 54/60 [00:20<00:01,  3.92it/s, Missing diagram bar]
2023-06-26 05:14:45,056:WARNING:Summarize dataset:  90%|#########9 | 54/60 [00:20<00:01,  3.92it/s, Missing diagram matrix]
2023-06-26 05:14:45,854:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:46,074:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-26 05:14:46,496:WARNING:Summarize dataset:  92%|########## | 55/60 [00:21<00:02,  1.82it/s, Missing diagram matrix]
2023-06-26 05:14:46,499:WARNING:Summarize dataset:  92%|#########1| 55/60 [00:21<00:02,  1.82it/s, Missing diagram heatmap]
2023-06-26 05:14:47,504:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-26 05:14:47,521:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:48,065:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-26 05:14:49,762:WARNING:Summarize dataset:  93%|#########3| 56/60 [00:24<00:05,  1.26s/it, Missing diagram heatmap]
2023-06-26 05:14:49,763:WARNING:Summarize dataset:  93%|####################5 | 56/60 [00:24<00:05,  1.26s/it, Take sample]
2023-06-26 05:14:49,766:WARNING:Summarize dataset:  95%|############3| 57/60 [00:24<00:03,  1.26s/it, Detecting duplicates]
2023-06-26 05:14:49,840:WARNING:Summarize dataset:  97%|######################2| 58/60 [00:24<00:02,  1.26s/it, Get alerts]
2023-06-26 05:14:49,841:WARNING:Summarize dataset:  98%|########8| 59/60 [00:24<00:01,  1.26s/it, Get reproduction details]
2023-06-26 05:14:49,842:WARNING:Summarize dataset: 100%|########################| 60/60 [00:24<00:00,  1.26s/it, Completed]
2023-06-26 05:14:49,843:WARNING:Summarize dataset: 100%|########################| 60/60 [00:24<00:00,  2.41it/s, Completed]
2023-06-26 05:14:49,843:WARNING:
2023-06-26 05:14:49,858:WARNING:Generate report structure:   0%|                                     | 0/1 [00:00<?, ?it/s]
2023-06-26 05:14:49,871:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 2.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-26 05:14:49,880:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-26 05:14:50,115:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 5.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-29 12:51:33,862:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-29 12:51:33,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-29 12:51:33,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-29 12:51:33,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-29 12:51:35,903:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-29 12:51:39,098:WARNING:C:\New folder\lib\site-packages\numba\core\decorators.py:262: NumbaDeprecationWarning: [1mnumba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.[0m
  warnings.warn(msg, NumbaDeprecationWarning)

2023-06-29 12:51:39,178:WARNING:C:\New folder\lib\site-packages\visions\backends\shared\nan_handling.py:51: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def hasna(x: np.ndarray) -> bool:

2023-06-29 12:51:39,733:WARNING:C:\Users\Naman\Desktop\my_projects\automl_app\automl.py:5: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.
  import pandas_profiling

2023-06-29 12:53:02,801:INFO:PyCaret RegressionExperiment
2023-06-29 12:53:02,802:INFO:Logging name: reg-default-name
2023-06-29 12:53:02,802:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-29 12:53:02,803:INFO:version 3.0.2
2023-06-29 12:53:02,804:INFO:Initializing setup()
2023-06-29 12:53:02,805:INFO:self.USI: cc68
2023-06-29 12:53:02,806:INFO:self._variable_keys: {'seed', 'X', 'gpu_param', 'gpu_n_jobs_param', 'X_test', 'fold_generator', 'n_jobs_param', 'transform_target_param', 'data', 'fold_groups_param', 'log_plots_param', 'idx', 'y_train', 'X_train', 'y_test', 'html_param', 'y', '_available_plots', 'pipeline', 'logging_param', 'memory', 'target_param', 'exp_id', 'fold_shuffle_param', 'exp_name_log', '_ml_usecase', 'USI'}
2023-06-29 12:53:02,806:INFO:Checking environment
2023-06-29 12:53:02,806:INFO:python_version: 3.10.4
2023-06-29 12:53:02,807:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2023-06-29 12:53:02,807:INFO:machine: AMD64
2023-06-29 12:53:02,847:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-29 12:53:02,856:INFO:Memory: svmem(total=7969243136, available=780140544, percent=90.2, used=7189102592, free=780140544)
2023-06-29 12:53:02,856:INFO:Physical Core: 6
2023-06-29 12:53:02,856:INFO:Logical Core: 6
2023-06-29 12:53:02,856:INFO:Checking libraries
2023-06-29 12:53:02,856:INFO:System:
2023-06-29 12:53:02,857:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2023-06-29 12:53:02,857:INFO:executable: C:\New folder\python.exe
2023-06-29 12:53:02,857:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-29 12:53:02,857:INFO:PyCaret required dependencies:
2023-06-29 12:53:02,857:INFO:                 pip: 23.1.2
2023-06-29 12:53:02,857:INFO:          setuptools: 58.1.0
2023-06-29 12:53:02,857:INFO:             pycaret: 3.0.2
2023-06-29 12:53:02,857:INFO:             IPython: 8.7.0
2023-06-29 12:53:02,857:INFO:          ipywidgets: 8.0.3
2023-06-29 12:53:02,857:INFO:                tqdm: 4.65.0
2023-06-29 12:53:02,857:INFO:               numpy: 1.23.5
2023-06-29 12:53:02,857:INFO:              pandas: 1.5.3
2023-06-29 12:53:02,857:INFO:              jinja2: 3.1.0
2023-06-29 12:53:02,857:INFO:               scipy: 1.9.1
2023-06-29 12:53:02,857:INFO:              joblib: 1.2.0
2023-06-29 12:53:02,858:INFO:             sklearn: 1.1.2
2023-06-29 12:53:02,858:INFO:                pyod: 1.1.0
2023-06-29 12:53:02,858:INFO:            imblearn: 0.10.1
2023-06-29 12:53:02,858:INFO:   category_encoders: 2.6.1
2023-06-29 12:53:02,858:INFO:            lightgbm: 3.3.5
2023-06-29 12:53:02,858:INFO:               numba: 0.57.1
2023-06-29 12:53:02,858:INFO:            requests: 2.28.1
2023-06-29 12:53:02,858:INFO:          matplotlib: 3.7.1
2023-06-29 12:53:02,858:INFO:          scikitplot: 0.3.7
2023-06-29 12:53:02,858:INFO:         yellowbrick: 1.5
2023-06-29 12:53:02,858:INFO:              plotly: 5.15.0
2023-06-29 12:53:02,858:INFO:             kaleido: 0.2.1
2023-06-29 12:53:02,858:INFO:         statsmodels: 0.14.0
2023-06-29 12:53:02,858:INFO:              sktime: 0.17.0
2023-06-29 12:53:02,858:INFO:               tbats: 1.1.3
2023-06-29 12:53:02,858:INFO:            pmdarima: 2.0.3
2023-06-29 12:53:02,858:INFO:              psutil: 5.9.4
2023-06-29 12:53:02,858:INFO:PyCaret optional dependencies:
2023-06-29 12:53:02,874:INFO:                shap: Not installed
2023-06-29 12:53:02,875:INFO:           interpret: Not installed
2023-06-29 12:53:02,875:INFO:                umap: Not installed
2023-06-29 12:53:02,875:INFO:    pandas_profiling: 4.3.1
2023-06-29 12:53:02,875:INFO:  explainerdashboard: Not installed
2023-06-29 12:53:02,875:INFO:             autoviz: Not installed
2023-06-29 12:53:02,875:INFO:           fairlearn: Not installed
2023-06-29 12:53:02,875:INFO:             xgboost: 1.7.5
2023-06-29 12:53:02,875:INFO:            catboost: Not installed
2023-06-29 12:53:02,875:INFO:              kmodes: Not installed
2023-06-29 12:53:02,875:INFO:             mlxtend: Not installed
2023-06-29 12:53:02,875:INFO:       statsforecast: Not installed
2023-06-29 12:53:02,875:INFO:        tune_sklearn: Not installed
2023-06-29 12:53:02,875:INFO:                 ray: Not installed
2023-06-29 12:53:02,875:INFO:            hyperopt: Not installed
2023-06-29 12:53:02,875:INFO:              optuna: Not installed
2023-06-29 12:53:02,875:INFO:               skopt: Not installed
2023-06-29 12:53:02,875:INFO:              mlflow: Not installed
2023-06-29 12:53:02,876:INFO:              gradio: Not installed
2023-06-29 12:53:02,876:INFO:             fastapi: Not installed
2023-06-29 12:53:02,876:INFO:             uvicorn: Not installed
2023-06-29 12:53:02,876:INFO:              m2cgen: Not installed
2023-06-29 12:53:02,876:INFO:           evidently: Not installed
2023-06-29 12:53:02,876:INFO:               fugue: Not installed
2023-06-29 12:53:02,876:INFO:           streamlit: 1.23.1
2023-06-29 12:53:02,876:INFO:             prophet: Not installed
2023-06-29 12:53:02,876:INFO:None
2023-06-29 12:53:02,876:INFO:Set up data.
2023-06-29 12:53:02,890:INFO:Set up train/test split.
2023-06-29 12:53:02,902:INFO:Set up index.
2023-06-29 12:53:02,903:INFO:Set up folding strategy.
2023-06-29 12:53:02,903:INFO:Assigning column types.
2023-06-29 12:53:02,908:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-29 12:53:02,908:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-29 12:53:02,918:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-29 12:53:02,925:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-29 12:53:03,031:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-29 12:53:03,108:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-29 12:53:03,110:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-29 12:53:03,362:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-29 12:53:03,363:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-29 12:53:03,371:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-29 12:53:03,380:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-29 12:53:03,483:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-29 12:53:03,560:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-29 12:53:03,561:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-29 12:53:03,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-29 12:53:03,567:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-29 12:53:03,575:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-29 12:53:03,583:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-29 12:53:03,682:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-29 12:53:03,756:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-29 12:53:03,756:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-29 12:53:03,761:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-29 12:53:03,769:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-29 12:53:03,777:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-29 12:53:03,874:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-29 12:53:03,949:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-29 12:53:03,949:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-29 12:53:03,954:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-29 12:53:03,954:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-29 12:53:03,970:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-29 12:53:04,070:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-29 12:53:04,147:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-29 12:53:04,149:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-29 12:53:04,153:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-29 12:53:04,172:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-29 12:53:04,269:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-29 12:53:04,344:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-29 12:53:04,345:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-29 12:53:04,349:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-29 12:53:04,350:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-29 12:53:04,468:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-29 12:53:04,548:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-29 12:53:04,549:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-29 12:53:04,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-29 12:53:04,668:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-29 12:53:04,743:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-29 12:53:04,744:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-29 12:53:04,749:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-29 12:53:04,749:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-29 12:53:04,865:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-29 12:53:04,940:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-29 12:53:04,944:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-29 12:53:05,061:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-29 12:53:05,141:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-29 12:53:05,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-29 12:53:05,146:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-29 12:53:05,336:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-29 12:53:05,341:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-29 12:53:05,529:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-29 12:53:05,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-29 12:53:05,537:INFO:Preparing preprocessing pipeline...
2023-06-29 12:53:05,538:INFO:Set up simple imputation.
2023-06-29 12:53:05,543:INFO:Set up encoding of ordinal features.
2023-06-29 12:53:05,545:INFO:Set up encoding of categorical features.
2023-06-29 12:53:05,752:INFO:Finished creating preprocessing pipeline.
2023-06-29 12:53:05,791:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Naman\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='most...
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              handle_missing='return_nan')))])
2023-06-29 12:53:05,791:INFO:Creating final display dataframe.
2023-06-29 12:53:06,395:INFO:Setup _display_container:                     Description             Value
0                    Session id              4580
1                        Target          Survived
2                   Target type        Regression
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Ordinal features                 1
8              Numeric features                 6
9          Categorical features                 5
10     Rows with missing values             79.5%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              cc68
2023-06-29 12:53:06,607:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-29 12:53:06,611:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-29 12:53:06,801:INFO:Soft dependency imported: xgboost: 1.7.5
2023-06-29 12:53:06,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-29 12:53:06,806:INFO:setup() successfully completed in 4.89s...............
2023-06-29 12:53:06,816:INFO:Initializing compare_models()
2023-06-29 12:53:06,817:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-29 12:53:06,817:INFO:Checking exceptions
2023-06-29 12:53:06,822:INFO:Preparing display monitor
2023-06-29 12:53:06,826:INFO:Initializing Linear Regression
2023-06-29 12:53:06,826:INFO:Total runtime is 0.0 minutes
2023-06-29 12:53:06,827:INFO:SubProcess create_model() called ==================================
2023-06-29 12:53:06,828:INFO:Initializing create_model()
2023-06-29 12:53:06,828:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:53:06,828:INFO:Checking exceptions
2023-06-29 12:53:06,828:INFO:Importing libraries
2023-06-29 12:53:06,828:INFO:Copying training dataset
2023-06-29 12:53:06,838:INFO:Defining folds
2023-06-29 12:53:06,838:INFO:Declaring metric variables
2023-06-29 12:53:06,838:INFO:Importing untrained model
2023-06-29 12:53:06,838:INFO:Linear Regression Imported successfully
2023-06-29 12:53:06,839:INFO:Starting cross validation
2023-06-29 12:53:06,862:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:53:14,024:INFO:Calculating mean and std
2023-06-29 12:53:14,025:INFO:Creating metrics dataframe
2023-06-29 12:53:14,263:INFO:Uploading results into container
2023-06-29 12:53:14,263:INFO:Uploading model into container now
2023-06-29 12:53:14,264:INFO:_master_model_container: 1
2023-06-29 12:53:14,264:INFO:_display_container: 2
2023-06-29 12:53:14,264:INFO:LinearRegression(n_jobs=-1)
2023-06-29 12:53:14,264:INFO:create_model() successfully completed......................................
2023-06-29 12:53:14,402:INFO:SubProcess create_model() end ==================================
2023-06-29 12:53:14,402:INFO:Creating metrics dataframe
2023-06-29 12:53:14,406:INFO:Initializing Lasso Regression
2023-06-29 12:53:14,406:INFO:Total runtime is 0.1263283689816793 minutes
2023-06-29 12:53:14,406:INFO:SubProcess create_model() called ==================================
2023-06-29 12:53:14,407:INFO:Initializing create_model()
2023-06-29 12:53:14,407:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:53:14,407:INFO:Checking exceptions
2023-06-29 12:53:14,407:INFO:Importing libraries
2023-06-29 12:53:14,407:INFO:Copying training dataset
2023-06-29 12:53:14,411:INFO:Defining folds
2023-06-29 12:53:14,411:INFO:Declaring metric variables
2023-06-29 12:53:14,411:INFO:Importing untrained model
2023-06-29 12:53:14,411:INFO:Lasso Regression Imported successfully
2023-06-29 12:53:14,412:INFO:Starting cross validation
2023-06-29 12:53:14,413:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:53:16,446:INFO:Calculating mean and std
2023-06-29 12:53:16,447:INFO:Creating metrics dataframe
2023-06-29 12:53:16,680:INFO:Uploading results into container
2023-06-29 12:53:16,681:INFO:Uploading model into container now
2023-06-29 12:53:16,681:INFO:_master_model_container: 2
2023-06-29 12:53:16,681:INFO:_display_container: 2
2023-06-29 12:53:16,681:INFO:Lasso(random_state=4580)
2023-06-29 12:53:16,681:INFO:create_model() successfully completed......................................
2023-06-29 12:53:16,809:INFO:SubProcess create_model() end ==================================
2023-06-29 12:53:16,809:INFO:Creating metrics dataframe
2023-06-29 12:53:16,814:INFO:Initializing Ridge Regression
2023-06-29 12:53:16,815:INFO:Total runtime is 0.1664726773897807 minutes
2023-06-29 12:53:16,815:INFO:SubProcess create_model() called ==================================
2023-06-29 12:53:16,815:INFO:Initializing create_model()
2023-06-29 12:53:16,815:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:53:16,815:INFO:Checking exceptions
2023-06-29 12:53:16,815:INFO:Importing libraries
2023-06-29 12:53:16,815:INFO:Copying training dataset
2023-06-29 12:53:16,820:INFO:Defining folds
2023-06-29 12:53:16,821:INFO:Declaring metric variables
2023-06-29 12:53:16,821:INFO:Importing untrained model
2023-06-29 12:53:16,822:INFO:Ridge Regression Imported successfully
2023-06-29 12:53:16,822:INFO:Starting cross validation
2023-06-29 12:53:16,824:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:53:17,906:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-29 12:53:22,627:INFO:Calculating mean and std
2023-06-29 12:53:22,633:INFO:Creating metrics dataframe
2023-06-29 12:53:23,309:INFO:Uploading results into container
2023-06-29 12:53:23,309:INFO:Uploading model into container now
2023-06-29 12:53:23,310:INFO:_master_model_container: 3
2023-06-29 12:53:23,310:INFO:_display_container: 2
2023-06-29 12:53:23,310:INFO:Ridge(random_state=4580)
2023-06-29 12:53:23,310:INFO:create_model() successfully completed......................................
2023-06-29 12:53:23,444:INFO:SubProcess create_model() end ==================================
2023-06-29 12:53:23,444:INFO:Creating metrics dataframe
2023-06-29 12:53:23,449:INFO:Initializing Elastic Net
2023-06-29 12:53:23,449:INFO:Total runtime is 0.2770522952079773 minutes
2023-06-29 12:53:23,449:INFO:SubProcess create_model() called ==================================
2023-06-29 12:53:23,449:INFO:Initializing create_model()
2023-06-29 12:53:23,450:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:53:23,450:INFO:Checking exceptions
2023-06-29 12:53:23,450:INFO:Importing libraries
2023-06-29 12:53:23,450:INFO:Copying training dataset
2023-06-29 12:53:23,455:INFO:Defining folds
2023-06-29 12:53:23,455:INFO:Declaring metric variables
2023-06-29 12:53:23,455:INFO:Importing untrained model
2023-06-29 12:53:23,455:INFO:Elastic Net Imported successfully
2023-06-29 12:53:23,456:INFO:Starting cross validation
2023-06-29 12:53:23,457:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:53:25,416:INFO:Calculating mean and std
2023-06-29 12:53:25,418:INFO:Creating metrics dataframe
2023-06-29 12:53:25,660:INFO:Uploading results into container
2023-06-29 12:53:25,661:INFO:Uploading model into container now
2023-06-29 12:53:25,661:INFO:_master_model_container: 4
2023-06-29 12:53:25,661:INFO:_display_container: 2
2023-06-29 12:53:25,662:INFO:ElasticNet(random_state=4580)
2023-06-29 12:53:25,662:INFO:create_model() successfully completed......................................
2023-06-29 12:53:25,790:INFO:SubProcess create_model() end ==================================
2023-06-29 12:53:25,791:INFO:Creating metrics dataframe
2023-06-29 12:53:25,796:INFO:Initializing Least Angle Regression
2023-06-29 12:53:25,796:INFO:Total runtime is 0.31615563233693444 minutes
2023-06-29 12:53:25,796:INFO:SubProcess create_model() called ==================================
2023-06-29 12:53:25,797:INFO:Initializing create_model()
2023-06-29 12:53:25,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:53:25,797:INFO:Checking exceptions
2023-06-29 12:53:25,797:INFO:Importing libraries
2023-06-29 12:53:25,797:INFO:Copying training dataset
2023-06-29 12:53:25,801:INFO:Defining folds
2023-06-29 12:53:25,801:INFO:Declaring metric variables
2023-06-29 12:53:25,801:INFO:Importing untrained model
2023-06-29 12:53:25,801:INFO:Least Angle Regression Imported successfully
2023-06-29 12:53:25,801:INFO:Starting cross validation
2023-06-29 12:53:25,803:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:53:26,026:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:26,026:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:26,038:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:26,051:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:26,060:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:26,535:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:26,545:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:26,573:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:26,573:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:27,755:INFO:Calculating mean and std
2023-06-29 12:53:27,757:INFO:Creating metrics dataframe
2023-06-29 12:53:27,993:INFO:Uploading results into container
2023-06-29 12:53:27,993:INFO:Uploading model into container now
2023-06-29 12:53:27,994:INFO:_master_model_container: 5
2023-06-29 12:53:27,994:INFO:_display_container: 2
2023-06-29 12:53:27,994:INFO:Lars(random_state=4580)
2023-06-29 12:53:27,994:INFO:create_model() successfully completed......................................
2023-06-29 12:53:28,125:INFO:SubProcess create_model() end ==================================
2023-06-29 12:53:28,125:INFO:Creating metrics dataframe
2023-06-29 12:53:28,130:INFO:Initializing Lasso Least Angle Regression
2023-06-29 12:53:28,130:INFO:Total runtime is 0.3550596594810486 minutes
2023-06-29 12:53:28,130:INFO:SubProcess create_model() called ==================================
2023-06-29 12:53:28,131:INFO:Initializing create_model()
2023-06-29 12:53:28,131:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:53:28,131:INFO:Checking exceptions
2023-06-29 12:53:28,131:INFO:Importing libraries
2023-06-29 12:53:28,131:INFO:Copying training dataset
2023-06-29 12:53:28,136:INFO:Defining folds
2023-06-29 12:53:28,136:INFO:Declaring metric variables
2023-06-29 12:53:28,136:INFO:Importing untrained model
2023-06-29 12:53:28,137:INFO:Lasso Least Angle Regression Imported successfully
2023-06-29 12:53:28,137:INFO:Starting cross validation
2023-06-29 12:53:28,138:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:53:28,313:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-29 12:53:28,359:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-29 12:53:28,363:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-29 12:53:28,370:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-29 12:53:28,379:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-29 12:53:28,381:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-29 12:53:28,830:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-29 12:53:28,834:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-29 12:53:28,858:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-29 12:53:28,872:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-29 12:53:29,990:INFO:Calculating mean and std
2023-06-29 12:53:29,991:INFO:Creating metrics dataframe
2023-06-29 12:53:30,243:INFO:Uploading results into container
2023-06-29 12:53:30,244:INFO:Uploading model into container now
2023-06-29 12:53:30,244:INFO:_master_model_container: 6
2023-06-29 12:53:30,244:INFO:_display_container: 2
2023-06-29 12:53:30,244:INFO:LassoLars(random_state=4580)
2023-06-29 12:53:30,244:INFO:create_model() successfully completed......................................
2023-06-29 12:53:30,380:INFO:SubProcess create_model() end ==================================
2023-06-29 12:53:30,381:INFO:Creating metrics dataframe
2023-06-29 12:53:30,387:INFO:Initializing Orthogonal Matching Pursuit
2023-06-29 12:53:30,387:INFO:Total runtime is 0.39267787138621013 minutes
2023-06-29 12:53:30,387:INFO:SubProcess create_model() called ==================================
2023-06-29 12:53:30,388:INFO:Initializing create_model()
2023-06-29 12:53:30,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:53:30,388:INFO:Checking exceptions
2023-06-29 12:53:30,388:INFO:Importing libraries
2023-06-29 12:53:30,388:INFO:Copying training dataset
2023-06-29 12:53:30,392:INFO:Defining folds
2023-06-29 12:53:30,392:INFO:Declaring metric variables
2023-06-29 12:53:30,392:INFO:Importing untrained model
2023-06-29 12:53:30,393:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-29 12:53:30,393:INFO:Starting cross validation
2023-06-29 12:53:30,395:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:53:30,600:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:30,601:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:30,602:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:30,602:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:30,628:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:30,651:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:31,080:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:31,110:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:31,143:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:31,154:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-29 12:53:32,230:INFO:Calculating mean and std
2023-06-29 12:53:32,231:INFO:Creating metrics dataframe
2023-06-29 12:53:32,475:INFO:Uploading results into container
2023-06-29 12:53:32,475:INFO:Uploading model into container now
2023-06-29 12:53:32,476:INFO:_master_model_container: 7
2023-06-29 12:53:32,476:INFO:_display_container: 2
2023-06-29 12:53:32,476:INFO:OrthogonalMatchingPursuit()
2023-06-29 12:53:32,476:INFO:create_model() successfully completed......................................
2023-06-29 12:53:32,600:INFO:SubProcess create_model() end ==================================
2023-06-29 12:53:32,600:INFO:Creating metrics dataframe
2023-06-29 12:53:32,604:INFO:Initializing Bayesian Ridge
2023-06-29 12:53:32,605:INFO:Total runtime is 0.42963887453079225 minutes
2023-06-29 12:53:32,605:INFO:SubProcess create_model() called ==================================
2023-06-29 12:53:32,605:INFO:Initializing create_model()
2023-06-29 12:53:32,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:53:32,605:INFO:Checking exceptions
2023-06-29 12:53:32,605:INFO:Importing libraries
2023-06-29 12:53:32,605:INFO:Copying training dataset
2023-06-29 12:53:32,609:INFO:Defining folds
2023-06-29 12:53:32,609:INFO:Declaring metric variables
2023-06-29 12:53:32,609:INFO:Importing untrained model
2023-06-29 12:53:32,609:INFO:Bayesian Ridge Imported successfully
2023-06-29 12:53:32,609:INFO:Starting cross validation
2023-06-29 12:53:32,611:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:53:34,480:INFO:Calculating mean and std
2023-06-29 12:53:34,481:INFO:Creating metrics dataframe
2023-06-29 12:53:34,711:INFO:Uploading results into container
2023-06-29 12:53:34,712:INFO:Uploading model into container now
2023-06-29 12:53:34,712:INFO:_master_model_container: 8
2023-06-29 12:53:34,712:INFO:_display_container: 2
2023-06-29 12:53:34,712:INFO:BayesianRidge()
2023-06-29 12:53:34,712:INFO:create_model() successfully completed......................................
2023-06-29 12:53:34,835:INFO:SubProcess create_model() end ==================================
2023-06-29 12:53:34,835:INFO:Creating metrics dataframe
2023-06-29 12:53:34,840:INFO:Initializing Passive Aggressive Regressor
2023-06-29 12:53:34,840:INFO:Total runtime is 0.4668890357017517 minutes
2023-06-29 12:53:34,840:INFO:SubProcess create_model() called ==================================
2023-06-29 12:53:34,840:INFO:Initializing create_model()
2023-06-29 12:53:34,840:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:53:34,841:INFO:Checking exceptions
2023-06-29 12:53:34,841:INFO:Importing libraries
2023-06-29 12:53:34,841:INFO:Copying training dataset
2023-06-29 12:53:34,845:INFO:Defining folds
2023-06-29 12:53:34,845:INFO:Declaring metric variables
2023-06-29 12:53:34,845:INFO:Importing untrained model
2023-06-29 12:53:34,846:INFO:Passive Aggressive Regressor Imported successfully
2023-06-29 12:53:34,846:INFO:Starting cross validation
2023-06-29 12:53:34,847:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:53:36,753:INFO:Calculating mean and std
2023-06-29 12:53:36,754:INFO:Creating metrics dataframe
2023-06-29 12:53:37,016:INFO:Uploading results into container
2023-06-29 12:53:37,017:INFO:Uploading model into container now
2023-06-29 12:53:37,017:INFO:_master_model_container: 9
2023-06-29 12:53:37,017:INFO:_display_container: 2
2023-06-29 12:53:37,017:INFO:PassiveAggressiveRegressor(random_state=4580)
2023-06-29 12:53:37,017:INFO:create_model() successfully completed......................................
2023-06-29 12:53:37,140:INFO:SubProcess create_model() end ==================================
2023-06-29 12:53:37,141:INFO:Creating metrics dataframe
2023-06-29 12:53:37,145:INFO:Initializing Huber Regressor
2023-06-29 12:53:37,145:INFO:Total runtime is 0.5053137461344401 minutes
2023-06-29 12:53:37,145:INFO:SubProcess create_model() called ==================================
2023-06-29 12:53:37,145:INFO:Initializing create_model()
2023-06-29 12:53:37,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:53:37,145:INFO:Checking exceptions
2023-06-29 12:53:37,145:INFO:Importing libraries
2023-06-29 12:53:37,146:INFO:Copying training dataset
2023-06-29 12:53:37,149:INFO:Defining folds
2023-06-29 12:53:37,150:INFO:Declaring metric variables
2023-06-29 12:53:37,150:INFO:Importing untrained model
2023-06-29 12:53:37,150:INFO:Huber Regressor Imported successfully
2023-06-29 12:53:37,150:INFO:Starting cross validation
2023-06-29 12:53:37,151:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:53:37,463:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-29 12:53:37,463:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-29 12:53:37,474:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-29 12:53:37,481:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-29 12:53:37,520:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-29 12:53:37,562:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-29 12:53:37,955:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-29 12:53:38,002:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-29 12:53:38,047:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-29 12:53:38,047:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-29 12:53:39,210:INFO:Calculating mean and std
2023-06-29 12:53:39,212:INFO:Creating metrics dataframe
2023-06-29 12:53:39,462:INFO:Uploading results into container
2023-06-29 12:53:39,462:INFO:Uploading model into container now
2023-06-29 12:53:39,463:INFO:_master_model_container: 10
2023-06-29 12:53:39,463:INFO:_display_container: 2
2023-06-29 12:53:39,463:INFO:HuberRegressor()
2023-06-29 12:53:39,463:INFO:create_model() successfully completed......................................
2023-06-29 12:53:39,592:INFO:SubProcess create_model() end ==================================
2023-06-29 12:53:39,592:INFO:Creating metrics dataframe
2023-06-29 12:53:39,596:INFO:Initializing K Neighbors Regressor
2023-06-29 12:53:39,596:INFO:Total runtime is 0.5461586356163025 minutes
2023-06-29 12:53:39,596:INFO:SubProcess create_model() called ==================================
2023-06-29 12:53:39,596:INFO:Initializing create_model()
2023-06-29 12:53:39,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:53:39,596:INFO:Checking exceptions
2023-06-29 12:53:39,597:INFO:Importing libraries
2023-06-29 12:53:39,597:INFO:Copying training dataset
2023-06-29 12:53:39,601:INFO:Defining folds
2023-06-29 12:53:39,601:INFO:Declaring metric variables
2023-06-29 12:53:39,601:INFO:Importing untrained model
2023-06-29 12:53:39,602:INFO:K Neighbors Regressor Imported successfully
2023-06-29 12:53:39,602:INFO:Starting cross validation
2023-06-29 12:53:39,603:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:53:41,820:INFO:Calculating mean and std
2023-06-29 12:53:41,821:INFO:Creating metrics dataframe
2023-06-29 12:53:42,071:INFO:Uploading results into container
2023-06-29 12:53:42,072:INFO:Uploading model into container now
2023-06-29 12:53:42,073:INFO:_master_model_container: 11
2023-06-29 12:53:42,073:INFO:_display_container: 2
2023-06-29 12:53:42,073:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-29 12:53:42,073:INFO:create_model() successfully completed......................................
2023-06-29 12:53:42,203:INFO:SubProcess create_model() end ==================================
2023-06-29 12:53:42,203:INFO:Creating metrics dataframe
2023-06-29 12:53:42,208:INFO:Initializing Decision Tree Regressor
2023-06-29 12:53:42,209:INFO:Total runtime is 0.589693291982015 minutes
2023-06-29 12:53:42,209:INFO:SubProcess create_model() called ==================================
2023-06-29 12:53:42,209:INFO:Initializing create_model()
2023-06-29 12:53:42,209:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:53:42,209:INFO:Checking exceptions
2023-06-29 12:53:42,209:INFO:Importing libraries
2023-06-29 12:53:42,210:INFO:Copying training dataset
2023-06-29 12:53:42,215:INFO:Defining folds
2023-06-29 12:53:42,215:INFO:Declaring metric variables
2023-06-29 12:53:42,215:INFO:Importing untrained model
2023-06-29 12:53:42,215:INFO:Decision Tree Regressor Imported successfully
2023-06-29 12:53:42,216:INFO:Starting cross validation
2023-06-29 12:53:42,217:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:53:43,129:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-29 12:53:44,463:INFO:Calculating mean and std
2023-06-29 12:53:44,465:INFO:Creating metrics dataframe
2023-06-29 12:53:44,720:INFO:Uploading results into container
2023-06-29 12:53:44,721:INFO:Uploading model into container now
2023-06-29 12:53:44,721:INFO:_master_model_container: 12
2023-06-29 12:53:44,721:INFO:_display_container: 2
2023-06-29 12:53:44,721:INFO:DecisionTreeRegressor(random_state=4580)
2023-06-29 12:53:44,721:INFO:create_model() successfully completed......................................
2023-06-29 12:53:44,846:INFO:SubProcess create_model() end ==================================
2023-06-29 12:53:44,846:INFO:Creating metrics dataframe
2023-06-29 12:53:44,850:INFO:Initializing Random Forest Regressor
2023-06-29 12:53:44,851:INFO:Total runtime is 0.6337546269098918 minutes
2023-06-29 12:53:44,851:INFO:SubProcess create_model() called ==================================
2023-06-29 12:53:44,851:INFO:Initializing create_model()
2023-06-29 12:53:44,851:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:53:44,851:INFO:Checking exceptions
2023-06-29 12:53:44,851:INFO:Importing libraries
2023-06-29 12:53:44,851:INFO:Copying training dataset
2023-06-29 12:53:44,855:INFO:Defining folds
2023-06-29 12:53:44,856:INFO:Declaring metric variables
2023-06-29 12:53:44,856:INFO:Importing untrained model
2023-06-29 12:53:44,856:INFO:Random Forest Regressor Imported successfully
2023-06-29 12:53:44,856:INFO:Starting cross validation
2023-06-29 12:53:44,857:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:53:47,765:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-29 12:53:48,418:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-29 12:53:48,426:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-29 12:53:49,372:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-29 12:53:49,525:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-29 12:53:49,580:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-29 12:53:49,654:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-29 12:53:49,709:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-29 12:53:49,737:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-29 12:53:52,069:INFO:Calculating mean and std
2023-06-29 12:53:52,070:INFO:Creating metrics dataframe
2023-06-29 12:53:52,313:INFO:Uploading results into container
2023-06-29 12:53:52,313:INFO:Uploading model into container now
2023-06-29 12:53:52,314:INFO:_master_model_container: 13
2023-06-29 12:53:52,314:INFO:_display_container: 2
2023-06-29 12:53:52,314:INFO:RandomForestRegressor(n_jobs=-1, random_state=4580)
2023-06-29 12:53:52,314:INFO:create_model() successfully completed......................................
2023-06-29 12:53:52,444:INFO:SubProcess create_model() end ==================================
2023-06-29 12:53:52,444:INFO:Creating metrics dataframe
2023-06-29 12:53:52,448:INFO:Initializing Extra Trees Regressor
2023-06-29 12:53:52,448:INFO:Total runtime is 0.760357149442037 minutes
2023-06-29 12:53:52,449:INFO:SubProcess create_model() called ==================================
2023-06-29 12:53:52,449:INFO:Initializing create_model()
2023-06-29 12:53:52,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:53:52,449:INFO:Checking exceptions
2023-06-29 12:53:52,449:INFO:Importing libraries
2023-06-29 12:53:52,449:INFO:Copying training dataset
2023-06-29 12:53:52,454:INFO:Defining folds
2023-06-29 12:53:52,454:INFO:Declaring metric variables
2023-06-29 12:53:52,454:INFO:Importing untrained model
2023-06-29 12:53:52,454:INFO:Extra Trees Regressor Imported successfully
2023-06-29 12:53:52,454:INFO:Starting cross validation
2023-06-29 12:53:52,456:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:53:54,752:INFO:Calculating mean and std
2023-06-29 12:53:54,753:INFO:Creating metrics dataframe
2023-06-29 12:53:55,306:INFO:Uploading results into container
2023-06-29 12:53:55,311:INFO:Uploading model into container now
2023-06-29 12:53:55,313:INFO:_master_model_container: 14
2023-06-29 12:53:55,314:INFO:_display_container: 2
2023-06-29 12:53:55,316:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4580)
2023-06-29 12:53:55,316:INFO:create_model() successfully completed......................................
2023-06-29 12:53:55,845:INFO:SubProcess create_model() end ==================================
2023-06-29 12:53:55,846:INFO:Creating metrics dataframe
2023-06-29 12:53:55,882:INFO:Initializing AdaBoost Regressor
2023-06-29 12:53:55,883:INFO:Total runtime is 0.8176203886667888 minutes
2023-06-29 12:53:55,884:INFO:SubProcess create_model() called ==================================
2023-06-29 12:53:55,886:INFO:Initializing create_model()
2023-06-29 12:53:55,886:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:53:55,888:INFO:Checking exceptions
2023-06-29 12:53:55,888:INFO:Importing libraries
2023-06-29 12:53:55,889:INFO:Copying training dataset
2023-06-29 12:53:55,933:INFO:Defining folds
2023-06-29 12:53:55,934:INFO:Declaring metric variables
2023-06-29 12:53:55,935:INFO:Importing untrained model
2023-06-29 12:53:55,938:INFO:AdaBoost Regressor Imported successfully
2023-06-29 12:53:55,939:INFO:Starting cross validation
2023-06-29 12:53:55,949:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:53:57,993:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-29 12:53:58,915:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-29 12:53:59,019:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-29 12:53:59,020:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-29 12:53:59,091:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-29 12:54:00,970:INFO:Calculating mean and std
2023-06-29 12:54:00,971:INFO:Creating metrics dataframe
2023-06-29 12:54:04,150:INFO:Uploading results into container
2023-06-29 12:54:04,158:INFO:Uploading model into container now
2023-06-29 12:54:04,161:INFO:_master_model_container: 15
2023-06-29 12:54:04,161:INFO:_display_container: 2
2023-06-29 12:54:04,163:INFO:AdaBoostRegressor(random_state=4580)
2023-06-29 12:54:04,164:INFO:create_model() successfully completed......................................
2023-06-29 12:54:04,976:INFO:SubProcess create_model() end ==================================
2023-06-29 12:54:04,977:INFO:Creating metrics dataframe
2023-06-29 12:54:05,003:INFO:Initializing Gradient Boosting Regressor
2023-06-29 12:54:05,003:INFO:Total runtime is 0.9696170608202617 minutes
2023-06-29 12:54:05,003:INFO:SubProcess create_model() called ==================================
2023-06-29 12:54:05,003:INFO:Initializing create_model()
2023-06-29 12:54:05,004:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:54:05,004:INFO:Checking exceptions
2023-06-29 12:54:05,004:INFO:Importing libraries
2023-06-29 12:54:05,004:INFO:Copying training dataset
2023-06-29 12:54:05,011:INFO:Defining folds
2023-06-29 12:54:05,011:INFO:Declaring metric variables
2023-06-29 12:54:05,011:INFO:Importing untrained model
2023-06-29 12:54:05,012:INFO:Gradient Boosting Regressor Imported successfully
2023-06-29 12:54:05,012:INFO:Starting cross validation
2023-06-29 12:54:05,013:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:54:07,332:INFO:Calculating mean and std
2023-06-29 12:54:07,333:INFO:Creating metrics dataframe
2023-06-29 12:54:07,607:INFO:Uploading results into container
2023-06-29 12:54:07,608:INFO:Uploading model into container now
2023-06-29 12:54:07,609:INFO:_master_model_container: 16
2023-06-29 12:54:07,609:INFO:_display_container: 2
2023-06-29 12:54:07,609:INFO:GradientBoostingRegressor(random_state=4580)
2023-06-29 12:54:07,609:INFO:create_model() successfully completed......................................
2023-06-29 12:54:07,734:INFO:SubProcess create_model() end ==================================
2023-06-29 12:54:07,734:INFO:Creating metrics dataframe
2023-06-29 12:54:07,738:INFO:Initializing Extreme Gradient Boosting
2023-06-29 12:54:07,738:INFO:Total runtime is 1.0151963671048483 minutes
2023-06-29 12:54:07,738:INFO:SubProcess create_model() called ==================================
2023-06-29 12:54:07,738:INFO:Initializing create_model()
2023-06-29 12:54:07,738:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:54:07,738:INFO:Checking exceptions
2023-06-29 12:54:07,739:INFO:Importing libraries
2023-06-29 12:54:07,739:INFO:Copying training dataset
2023-06-29 12:54:07,743:INFO:Defining folds
2023-06-29 12:54:07,743:INFO:Declaring metric variables
2023-06-29 12:54:07,743:INFO:Importing untrained model
2023-06-29 12:54:07,744:INFO:Extreme Gradient Boosting Imported successfully
2023-06-29 12:54:07,744:INFO:Starting cross validation
2023-06-29 12:54:07,745:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:54:11,659:INFO:Calculating mean and std
2023-06-29 12:54:11,660:INFO:Creating metrics dataframe
2023-06-29 12:54:11,953:INFO:Uploading results into container
2023-06-29 12:54:11,954:INFO:Uploading model into container now
2023-06-29 12:54:11,954:INFO:_master_model_container: 17
2023-06-29 12:54:11,954:INFO:_display_container: 2
2023-06-29 12:54:11,955:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=4580, ...)
2023-06-29 12:54:11,955:INFO:create_model() successfully completed......................................
2023-06-29 12:54:12,095:INFO:SubProcess create_model() end ==================================
2023-06-29 12:54:12,096:INFO:Creating metrics dataframe
2023-06-29 12:54:12,102:INFO:Initializing Light Gradient Boosting Machine
2023-06-29 12:54:12,102:INFO:Total runtime is 1.0879242817560832 minutes
2023-06-29 12:54:12,102:INFO:SubProcess create_model() called ==================================
2023-06-29 12:54:12,102:INFO:Initializing create_model()
2023-06-29 12:54:12,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:54:12,102:INFO:Checking exceptions
2023-06-29 12:54:12,102:INFO:Importing libraries
2023-06-29 12:54:12,102:INFO:Copying training dataset
2023-06-29 12:54:12,106:INFO:Defining folds
2023-06-29 12:54:12,106:INFO:Declaring metric variables
2023-06-29 12:54:12,107:INFO:Importing untrained model
2023-06-29 12:54:12,107:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-29 12:54:12,107:INFO:Starting cross validation
2023-06-29 12:54:12,108:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:54:17,449:INFO:Calculating mean and std
2023-06-29 12:54:17,453:INFO:Creating metrics dataframe
2023-06-29 12:54:19,132:INFO:Uploading results into container
2023-06-29 12:54:19,133:INFO:Uploading model into container now
2023-06-29 12:54:19,133:INFO:_master_model_container: 18
2023-06-29 12:54:19,133:INFO:_display_container: 2
2023-06-29 12:54:19,134:INFO:LGBMRegressor(random_state=4580)
2023-06-29 12:54:19,134:INFO:create_model() successfully completed......................................
2023-06-29 12:54:19,270:INFO:SubProcess create_model() end ==================================
2023-06-29 12:54:19,270:INFO:Creating metrics dataframe
2023-06-29 12:54:19,274:INFO:Initializing Dummy Regressor
2023-06-29 12:54:19,275:INFO:Total runtime is 1.207455348968506 minutes
2023-06-29 12:54:19,275:INFO:SubProcess create_model() called ==================================
2023-06-29 12:54:19,275:INFO:Initializing create_model()
2023-06-29 12:54:19,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019C54FEAEC0>, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:54:19,275:INFO:Checking exceptions
2023-06-29 12:54:19,275:INFO:Importing libraries
2023-06-29 12:54:19,275:INFO:Copying training dataset
2023-06-29 12:54:19,281:INFO:Defining folds
2023-06-29 12:54:19,281:INFO:Declaring metric variables
2023-06-29 12:54:19,281:INFO:Importing untrained model
2023-06-29 12:54:19,281:INFO:Dummy Regressor Imported successfully
2023-06-29 12:54:19,282:INFO:Starting cross validation
2023-06-29 12:54:19,283:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-29 12:54:21,343:INFO:Calculating mean and std
2023-06-29 12:54:21,344:INFO:Creating metrics dataframe
2023-06-29 12:54:21,607:INFO:Uploading results into container
2023-06-29 12:54:21,608:INFO:Uploading model into container now
2023-06-29 12:54:21,608:INFO:_master_model_container: 19
2023-06-29 12:54:21,608:INFO:_display_container: 2
2023-06-29 12:54:21,609:INFO:DummyRegressor()
2023-06-29 12:54:21,609:INFO:create_model() successfully completed......................................
2023-06-29 12:54:21,747:INFO:SubProcess create_model() end ==================================
2023-06-29 12:54:21,747:INFO:Creating metrics dataframe
2023-06-29 12:54:21,754:INFO:Initializing create_model()
2023-06-29 12:54:21,754:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019C3E040BB0>, estimator=Ridge(random_state=4580), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-29 12:54:21,754:INFO:Checking exceptions
2023-06-29 12:54:21,755:INFO:Importing libraries
2023-06-29 12:54:21,755:INFO:Copying training dataset
2023-06-29 12:54:21,760:INFO:Defining folds
2023-06-29 12:54:21,760:INFO:Declaring metric variables
2023-06-29 12:54:21,760:INFO:Importing untrained model
2023-06-29 12:54:21,760:INFO:Declaring custom model
2023-06-29 12:54:21,760:INFO:Ridge Regression Imported successfully
2023-06-29 12:54:21,761:INFO:Cross validation set to False
2023-06-29 12:54:21,762:INFO:Fitting Model
2023-06-29 12:54:22,085:INFO:Ridge(random_state=4580)
2023-06-29 12:54:22,085:INFO:create_model() successfully completed......................................
2023-06-29 12:54:22,231:INFO:_master_model_container: 19
2023-06-29 12:54:22,231:INFO:_display_container: 2
2023-06-29 12:54:22,231:INFO:Ridge(random_state=4580)
2023-06-29 12:54:22,232:INFO:compare_models() successfully completed......................................
2023-07-17 17:24:57,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-17 17:24:57,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-17 17:24:57,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-17 17:24:57,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-17 17:25:00,853:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-17 17:25:04,155:WARNING:C:\New folder\lib\site-packages\numba\core\decorators.py:262: NumbaDeprecationWarning: [1mnumba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.[0m
  warnings.warn(msg, NumbaDeprecationWarning)

2023-07-17 17:25:04,247:WARNING:C:\New folder\lib\site-packages\visions\backends\shared\nan_handling.py:51: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def hasna(x: np.ndarray) -> bool:

2023-07-17 17:25:04,883:WARNING:C:\Users\Naman\Desktop\my_projects\automl_app\automl.py:5: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.
  import pandas_profiling

2023-07-17 17:27:20,186:INFO:PyCaret RegressionExperiment
2023-07-17 17:27:20,188:INFO:Logging name: reg-default-name
2023-07-17 17:27:20,188:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-17 17:27:20,188:INFO:version 3.0.2
2023-07-17 17:27:20,188:INFO:Initializing setup()
2023-07-17 17:27:20,188:INFO:self.USI: b816
2023-07-17 17:27:20,188:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'X_train', 'data', 'logging_param', 'memory', 'y_test', 'X_test', 'fold_generator', 'gpu_n_jobs_param', 'exp_id', 'X', 'fold_groups_param', 'target_param', 'USI', 'gpu_param', '_ml_usecase', 'n_jobs_param', 'exp_name_log', 'html_param', 'pipeline', '_available_plots', 'log_plots_param', 'y', 'transform_target_param', 'seed', 'y_train'}
2023-07-17 17:27:20,188:INFO:Checking environment
2023-07-17 17:27:20,188:INFO:python_version: 3.10.4
2023-07-17 17:27:20,188:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2023-07-17 17:27:20,188:INFO:machine: AMD64
2023-07-17 17:27:20,211:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-17 17:27:20,223:INFO:Memory: svmem(total=7969243136, available=1258037248, percent=84.2, used=6711205888, free=1258037248)
2023-07-17 17:27:20,223:INFO:Physical Core: 6
2023-07-17 17:27:20,223:INFO:Logical Core: 6
2023-07-17 17:27:20,223:INFO:Checking libraries
2023-07-17 17:27:20,223:INFO:System:
2023-07-17 17:27:20,223:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2023-07-17 17:27:20,223:INFO:executable: C:\New folder\python.exe
2023-07-17 17:27:20,223:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-17 17:27:20,223:INFO:PyCaret required dependencies:
2023-07-17 17:27:20,224:INFO:                 pip: 23.1.2
2023-07-17 17:27:20,224:INFO:          setuptools: 58.1.0
2023-07-17 17:27:20,224:INFO:             pycaret: 3.0.2
2023-07-17 17:27:20,224:INFO:             IPython: 8.7.0
2023-07-17 17:27:20,224:INFO:          ipywidgets: 8.0.3
2023-07-17 17:27:20,224:INFO:                tqdm: 4.65.0
2023-07-17 17:27:20,224:INFO:               numpy: 1.23.5
2023-07-17 17:27:20,224:INFO:              pandas: 1.5.3
2023-07-17 17:27:20,224:INFO:              jinja2: 3.1.0
2023-07-17 17:27:20,224:INFO:               scipy: 1.9.1
2023-07-17 17:27:20,224:INFO:              joblib: 1.2.0
2023-07-17 17:27:20,224:INFO:             sklearn: 1.1.2
2023-07-17 17:27:20,224:INFO:                pyod: 1.1.0
2023-07-17 17:27:20,224:INFO:            imblearn: 0.10.1
2023-07-17 17:27:20,224:INFO:   category_encoders: 2.6.1
2023-07-17 17:27:20,224:INFO:            lightgbm: 3.3.5
2023-07-17 17:27:20,224:INFO:               numba: 0.57.1
2023-07-17 17:27:20,225:INFO:            requests: 2.28.1
2023-07-17 17:27:20,225:INFO:          matplotlib: 3.7.1
2023-07-17 17:27:20,225:INFO:          scikitplot: 0.3.7
2023-07-17 17:27:20,225:INFO:         yellowbrick: 1.5
2023-07-17 17:27:20,225:INFO:              plotly: 5.15.0
2023-07-17 17:27:20,225:INFO:             kaleido: 0.2.1
2023-07-17 17:27:20,225:INFO:         statsmodels: 0.14.0
2023-07-17 17:27:20,225:INFO:              sktime: 0.17.0
2023-07-17 17:27:20,225:INFO:               tbats: 1.1.3
2023-07-17 17:27:20,225:INFO:            pmdarima: 2.0.3
2023-07-17 17:27:20,225:INFO:              psutil: 5.9.4
2023-07-17 17:27:20,225:INFO:PyCaret optional dependencies:
2023-07-17 17:27:20,239:INFO:                shap: Not installed
2023-07-17 17:27:20,241:INFO:           interpret: Not installed
2023-07-17 17:27:20,241:INFO:                umap: Not installed
2023-07-17 17:27:20,241:INFO:    pandas_profiling: 4.3.1
2023-07-17 17:27:20,241:INFO:  explainerdashboard: Not installed
2023-07-17 17:27:20,242:INFO:             autoviz: Not installed
2023-07-17 17:27:20,242:INFO:           fairlearn: Not installed
2023-07-17 17:27:20,242:INFO:             xgboost: 1.7.5
2023-07-17 17:27:20,242:INFO:            catboost: Not installed
2023-07-17 17:27:20,242:INFO:              kmodes: Not installed
2023-07-17 17:27:20,242:INFO:             mlxtend: Not installed
2023-07-17 17:27:20,242:INFO:       statsforecast: Not installed
2023-07-17 17:27:20,242:INFO:        tune_sklearn: Not installed
2023-07-17 17:27:20,242:INFO:                 ray: Not installed
2023-07-17 17:27:20,242:INFO:            hyperopt: Not installed
2023-07-17 17:27:20,242:INFO:              optuna: Not installed
2023-07-17 17:27:20,242:INFO:               skopt: Not installed
2023-07-17 17:27:20,242:INFO:              mlflow: Not installed
2023-07-17 17:27:20,242:INFO:              gradio: Not installed
2023-07-17 17:27:20,242:INFO:             fastapi: Not installed
2023-07-17 17:27:20,242:INFO:             uvicorn: Not installed
2023-07-17 17:27:20,242:INFO:              m2cgen: Not installed
2023-07-17 17:27:20,242:INFO:           evidently: Not installed
2023-07-17 17:27:20,242:INFO:               fugue: Not installed
2023-07-17 17:27:20,242:INFO:           streamlit: 1.23.1
2023-07-17 17:27:20,242:INFO:             prophet: Not installed
2023-07-17 17:27:20,242:INFO:None
2023-07-17 17:27:20,242:INFO:Set up data.
2023-07-17 17:27:20,256:INFO:Set up train/test split.
2023-07-17 17:27:20,272:INFO:Set up index.
2023-07-17 17:27:20,273:INFO:Set up folding strategy.
2023-07-17 17:27:20,273:INFO:Assigning column types.
2023-07-17 17:27:20,279:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-17 17:27:20,279:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-17 17:27:20,287:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-17 17:27:20,296:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:20,407:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:20,488:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:20,489:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:20,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:20,712:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-17 17:27:20,719:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-17 17:27:20,730:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:20,829:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:20,910:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:20,911:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:20,915:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:20,916:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-07-17 17:27:20,924:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-17 17:27:20,935:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:21,039:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:21,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:21,121:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:21,125:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:21,136:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-17 17:27:21,143:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:21,247:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:21,325:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:21,326:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:21,332:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:21,333:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-07-17 17:27:21,351:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:21,448:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:21,522:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:21,523:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:21,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:21,545:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:21,650:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:21,729:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:21,730:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:21,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:21,735:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-07-17 17:27:21,849:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:21,931:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:21,932:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:21,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:22,057:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:22,137:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:22,138:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:22,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:22,145:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-17 17:27:22,265:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:22,349:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:22,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:22,480:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:22,561:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:22,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:22,567:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-07-17 17:27:22,767:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:22,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:22,971:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:22,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:22,982:INFO:Preparing preprocessing pipeline...
2023-07-17 17:27:22,983:INFO:Set up simple imputation.
2023-07-17 17:27:22,989:INFO:Set up encoding of ordinal features.
2023-07-17 17:27:22,991:INFO:Set up encoding of categorical features.
2023-07-17 17:27:23,200:INFO:Finished creating preprocessing pipeline.
2023-07-17 17:27:23,243:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Naman\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='most...
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              handle_missing='return_nan')))])
2023-07-17 17:27:23,243:INFO:Creating final display dataframe.
2023-07-17 17:27:23,869:INFO:Setup _display_container:                     Description             Value
0                    Session id              2273
1                        Target          Survived
2                   Target type        Regression
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Ordinal features                 1
8              Numeric features                 6
9          Categorical features                 5
10     Rows with missing values             79.5%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              b816
2023-07-17 17:27:24,091:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:24,097:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:24,291:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:24,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:24,297:INFO:setup() successfully completed in 4.93s...............
2023-07-17 17:27:24,359:INFO:Initializing compare_models()
2023-07-17 17:27:24,359:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-17 17:27:24,360:INFO:Checking exceptions
2023-07-17 17:27:24,363:INFO:Preparing display monitor
2023-07-17 17:27:24,367:INFO:Initializing Linear Regression
2023-07-17 17:27:24,367:INFO:Total runtime is 0.0 minutes
2023-07-17 17:27:24,370:INFO:SubProcess create_model() called ==================================
2023-07-17 17:27:24,371:INFO:Initializing create_model()
2023-07-17 17:27:24,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:27:24,371:INFO:Checking exceptions
2023-07-17 17:27:24,371:INFO:Importing libraries
2023-07-17 17:27:24,371:INFO:Copying training dataset
2023-07-17 17:27:24,377:INFO:Defining folds
2023-07-17 17:27:24,378:INFO:Declaring metric variables
2023-07-17 17:27:24,378:INFO:Importing untrained model
2023-07-17 17:27:24,378:INFO:Linear Regression Imported successfully
2023-07-17 17:27:24,378:INFO:Starting cross validation
2023-07-17 17:27:24,390:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:27:31,720:INFO:Calculating mean and std
2023-07-17 17:27:31,721:INFO:Creating metrics dataframe
2023-07-17 17:27:31,947:INFO:Uploading results into container
2023-07-17 17:27:31,948:INFO:Uploading model into container now
2023-07-17 17:27:31,948:INFO:_master_model_container: 1
2023-07-17 17:27:31,948:INFO:_display_container: 2
2023-07-17 17:27:31,949:INFO:LinearRegression(n_jobs=-1)
2023-07-17 17:27:31,949:INFO:create_model() successfully completed......................................
2023-07-17 17:27:32,092:INFO:SubProcess create_model() end ==================================
2023-07-17 17:27:32,092:INFO:Creating metrics dataframe
2023-07-17 17:27:32,096:INFO:Initializing Lasso Regression
2023-07-17 17:27:32,097:INFO:Total runtime is 0.12883036136627196 minutes
2023-07-17 17:27:32,097:INFO:SubProcess create_model() called ==================================
2023-07-17 17:27:32,097:INFO:Initializing create_model()
2023-07-17 17:27:32,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:27:32,097:INFO:Checking exceptions
2023-07-17 17:27:32,097:INFO:Importing libraries
2023-07-17 17:27:32,097:INFO:Copying training dataset
2023-07-17 17:27:32,101:INFO:Defining folds
2023-07-17 17:27:32,102:INFO:Declaring metric variables
2023-07-17 17:27:32,102:INFO:Importing untrained model
2023-07-17 17:27:32,102:INFO:Lasso Regression Imported successfully
2023-07-17 17:27:32,102:INFO:Starting cross validation
2023-07-17 17:27:32,103:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:27:33,805:INFO:Calculating mean and std
2023-07-17 17:27:33,807:INFO:Creating metrics dataframe
2023-07-17 17:27:34,031:INFO:Uploading results into container
2023-07-17 17:27:34,033:INFO:Uploading model into container now
2023-07-17 17:27:34,033:INFO:_master_model_container: 2
2023-07-17 17:27:34,033:INFO:_display_container: 2
2023-07-17 17:27:34,034:INFO:Lasso(random_state=2273)
2023-07-17 17:27:34,034:INFO:create_model() successfully completed......................................
2023-07-17 17:27:34,166:INFO:SubProcess create_model() end ==================================
2023-07-17 17:27:34,167:INFO:Creating metrics dataframe
2023-07-17 17:27:34,171:INFO:Initializing Ridge Regression
2023-07-17 17:27:34,171:INFO:Total runtime is 0.16339805920918782 minutes
2023-07-17 17:27:34,171:INFO:SubProcess create_model() called ==================================
2023-07-17 17:27:34,172:INFO:Initializing create_model()
2023-07-17 17:27:34,172:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:27:34,172:INFO:Checking exceptions
2023-07-17 17:27:34,172:INFO:Importing libraries
2023-07-17 17:27:34,172:INFO:Copying training dataset
2023-07-17 17:27:34,176:INFO:Defining folds
2023-07-17 17:27:34,176:INFO:Declaring metric variables
2023-07-17 17:27:34,176:INFO:Importing untrained model
2023-07-17 17:27:34,177:INFO:Ridge Regression Imported successfully
2023-07-17 17:27:34,177:INFO:Starting cross validation
2023-07-17 17:27:34,178:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:27:36,004:INFO:Calculating mean and std
2023-07-17 17:27:36,005:INFO:Creating metrics dataframe
2023-07-17 17:27:36,232:INFO:Uploading results into container
2023-07-17 17:27:36,233:INFO:Uploading model into container now
2023-07-17 17:27:36,234:INFO:_master_model_container: 3
2023-07-17 17:27:36,234:INFO:_display_container: 2
2023-07-17 17:27:36,234:INFO:Ridge(random_state=2273)
2023-07-17 17:27:36,234:INFO:create_model() successfully completed......................................
2023-07-17 17:27:36,483:INFO:SubProcess create_model() end ==================================
2023-07-17 17:27:36,484:INFO:Creating metrics dataframe
2023-07-17 17:27:36,541:INFO:Initializing Elastic Net
2023-07-17 17:27:36,543:INFO:Total runtime is 0.20292098919550577 minutes
2023-07-17 17:27:36,544:INFO:SubProcess create_model() called ==================================
2023-07-17 17:27:36,546:INFO:Initializing create_model()
2023-07-17 17:27:36,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:27:36,547:INFO:Checking exceptions
2023-07-17 17:27:36,548:INFO:Importing libraries
2023-07-17 17:27:36,548:INFO:Copying training dataset
2023-07-17 17:27:36,593:INFO:Defining folds
2023-07-17 17:27:36,594:INFO:Declaring metric variables
2023-07-17 17:27:36,595:INFO:Importing untrained model
2023-07-17 17:27:36,597:INFO:Elastic Net Imported successfully
2023-07-17 17:27:36,598:INFO:Starting cross validation
2023-07-17 17:27:36,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:27:37,967:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-17 17:27:38,800:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-17 17:27:38,956:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-17 17:27:39,004:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-17 17:27:39,267:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-17 17:27:39,446:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-17 17:27:40,069:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-17 17:27:42,183:INFO:Calculating mean and std
2023-07-17 17:27:42,184:INFO:Creating metrics dataframe
2023-07-17 17:27:43,711:INFO:PyCaret RegressionExperiment
2023-07-17 17:27:43,711:INFO:Logging name: reg-default-name
2023-07-17 17:27:43,714:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-17 17:27:43,715:INFO:version 3.0.2
2023-07-17 17:27:43,715:INFO:Initializing setup()
2023-07-17 17:27:43,716:INFO:self.USI: 68f4
2023-07-17 17:27:43,717:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'X_train', 'data', 'logging_param', 'memory', 'y_test', 'X_test', 'fold_generator', 'gpu_n_jobs_param', 'exp_id', 'X', 'fold_groups_param', 'target_param', 'USI', 'gpu_param', '_ml_usecase', 'n_jobs_param', 'exp_name_log', 'html_param', 'pipeline', '_available_plots', 'log_plots_param', 'y', 'transform_target_param', 'seed', 'y_train'}
2023-07-17 17:27:43,719:INFO:Checking environment
2023-07-17 17:27:43,720:INFO:python_version: 3.10.4
2023-07-17 17:27:43,721:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2023-07-17 17:27:43,722:INFO:machine: AMD64
2023-07-17 17:27:43,723:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-17 17:27:43,748:INFO:Memory: svmem(total=7969243136, available=681132032, percent=91.5, used=7288111104, free=681132032)
2023-07-17 17:27:43,749:INFO:Physical Core: 6
2023-07-17 17:27:43,750:INFO:Logical Core: 6
2023-07-17 17:27:43,751:INFO:Checking libraries
2023-07-17 17:27:43,753:INFO:System:
2023-07-17 17:27:43,754:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2023-07-17 17:27:43,755:INFO:executable: C:\New folder\python.exe
2023-07-17 17:27:43,756:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-17 17:27:43,757:INFO:PyCaret required dependencies:
2023-07-17 17:27:43,758:INFO:                 pip: 23.1.2
2023-07-17 17:27:43,759:INFO:          setuptools: 58.1.0
2023-07-17 17:27:43,759:INFO:             pycaret: 3.0.2
2023-07-17 17:27:43,761:INFO:             IPython: 8.7.0
2023-07-17 17:27:43,762:INFO:          ipywidgets: 8.0.3
2023-07-17 17:27:43,763:INFO:                tqdm: 4.65.0
2023-07-17 17:27:43,764:INFO:               numpy: 1.23.5
2023-07-17 17:27:43,765:INFO:              pandas: 1.5.3
2023-07-17 17:27:43,766:INFO:              jinja2: 3.1.0
2023-07-17 17:27:43,767:INFO:               scipy: 1.9.1
2023-07-17 17:27:43,768:INFO:              joblib: 1.2.0
2023-07-17 17:27:43,769:INFO:             sklearn: 1.1.2
2023-07-17 17:27:43,771:INFO:                pyod: 1.1.0
2023-07-17 17:27:43,773:INFO:            imblearn: 0.10.1
2023-07-17 17:27:43,774:INFO:   category_encoders: 2.6.1
2023-07-17 17:27:43,776:INFO:            lightgbm: 3.3.5
2023-07-17 17:27:43,778:INFO:               numba: 0.57.1
2023-07-17 17:27:43,779:INFO:            requests: 2.28.1
2023-07-17 17:27:43,780:INFO:          matplotlib: 3.7.1
2023-07-17 17:27:43,781:INFO:          scikitplot: 0.3.7
2023-07-17 17:27:43,781:INFO:         yellowbrick: 1.5
2023-07-17 17:27:43,783:INFO:              plotly: 5.15.0
2023-07-17 17:27:43,784:INFO:             kaleido: 0.2.1
2023-07-17 17:27:43,785:INFO:         statsmodels: 0.14.0
2023-07-17 17:27:43,787:INFO:              sktime: 0.17.0
2023-07-17 17:27:43,788:INFO:               tbats: 1.1.3
2023-07-17 17:27:43,789:INFO:            pmdarima: 2.0.3
2023-07-17 17:27:43,789:INFO:              psutil: 5.9.4
2023-07-17 17:27:43,791:INFO:PyCaret optional dependencies:
2023-07-17 17:27:43,793:INFO:                shap: Not installed
2023-07-17 17:27:43,793:INFO:           interpret: Not installed
2023-07-17 17:27:43,794:INFO:                umap: Not installed
2023-07-17 17:27:43,795:INFO:    pandas_profiling: 4.3.1
2023-07-17 17:27:43,796:INFO:  explainerdashboard: Not installed
2023-07-17 17:27:43,796:INFO:             autoviz: Not installed
2023-07-17 17:27:43,797:INFO:           fairlearn: Not installed
2023-07-17 17:27:43,798:INFO:             xgboost: 1.7.5
2023-07-17 17:27:43,798:INFO:            catboost: Not installed
2023-07-17 17:27:43,799:INFO:              kmodes: Not installed
2023-07-17 17:27:43,801:INFO:             mlxtend: Not installed
2023-07-17 17:27:43,801:INFO:       statsforecast: Not installed
2023-07-17 17:27:43,803:INFO:        tune_sklearn: Not installed
2023-07-17 17:27:43,805:INFO:                 ray: Not installed
2023-07-17 17:27:43,805:INFO:            hyperopt: Not installed
2023-07-17 17:27:43,806:INFO:              optuna: Not installed
2023-07-17 17:27:43,806:INFO:               skopt: Not installed
2023-07-17 17:27:43,809:INFO:              mlflow: Not installed
2023-07-17 17:27:43,811:INFO:              gradio: Not installed
2023-07-17 17:27:43,811:INFO:             fastapi: Not installed
2023-07-17 17:27:43,812:INFO:             uvicorn: Not installed
2023-07-17 17:27:43,812:INFO:              m2cgen: Not installed
2023-07-17 17:27:43,815:INFO:           evidently: Not installed
2023-07-17 17:27:43,816:INFO:               fugue: Not installed
2023-07-17 17:27:43,816:INFO:           streamlit: 1.23.1
2023-07-17 17:27:43,817:INFO:             prophet: Not installed
2023-07-17 17:27:43,818:INFO:None
2023-07-17 17:27:43,819:INFO:Set up data.
2023-07-17 17:27:43,891:INFO:Set up train/test split.
2023-07-17 17:27:43,957:INFO:Set up index.
2023-07-17 17:27:43,960:INFO:Set up folding strategy.
2023-07-17 17:27:43,961:INFO:Assigning column types.
2023-07-17 17:27:43,999:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-17 17:27:44,001:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-17 17:27:44,053:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-17 17:27:44,108:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:44,743:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:45,249:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:45,257:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:45,286:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:45,288:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-17 17:27:45,340:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-17 17:27:45,398:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,025:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,377:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:46,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:46,381:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-07-17 17:27:46,386:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,390:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,455:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,504:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,504:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:46,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:46,512:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,517:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,580:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,627:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,628:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:46,631:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:46,632:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-07-17 17:27:46,641:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,709:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,764:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,765:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:46,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:46,781:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,846:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,898:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:46,899:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:46,903:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:46,903:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-07-17 17:27:46,982:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:47,030:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:47,031:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:47,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:47,115:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:47,168:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:47,169:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:47,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:47,172:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-17 17:27:47,244:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:47,291:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:47,294:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:47,375:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:47,421:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:47,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:47,425:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-07-17 17:27:47,550:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:47,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:47,672:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:47,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:47,677:INFO:Preparing preprocessing pipeline...
2023-07-17 17:27:47,677:INFO:Set up simple imputation.
2023-07-17 17:27:47,680:INFO:Set up encoding of ordinal features.
2023-07-17 17:27:47,681:INFO:Set up encoding of categorical features.
2023-07-17 17:27:47,856:INFO:Uploading results into container
2023-07-17 17:27:47,856:INFO:Uploading model into container now
2023-07-17 17:27:47,857:INFO:_master_model_container: 4
2023-07-17 17:27:47,857:INFO:_display_container: 2
2023-07-17 17:27:47,857:INFO:ElasticNet(random_state=2273)
2023-07-17 17:27:47,857:INFO:create_model() successfully completed......................................
2023-07-17 17:27:47,994:INFO:SubProcess create_model() end ==================================
2023-07-17 17:27:47,994:INFO:Creating metrics dataframe
2023-07-17 17:27:47,998:INFO:Initializing Least Angle Regression
2023-07-17 17:27:47,998:INFO:Total runtime is 0.3938427448272705 minutes
2023-07-17 17:27:47,999:INFO:SubProcess create_model() called ==================================
2023-07-17 17:27:47,999:INFO:Initializing create_model()
2023-07-17 17:27:47,999:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:27:47,999:INFO:Checking exceptions
2023-07-17 17:27:48,000:INFO:Importing libraries
2023-07-17 17:27:48,000:INFO:Copying training dataset
2023-07-17 17:27:48,007:INFO:Defining folds
2023-07-17 17:27:48,007:INFO:Declaring metric variables
2023-07-17 17:27:48,007:INFO:Importing untrained model
2023-07-17 17:27:48,008:INFO:Least Angle Regression Imported successfully
2023-07-17 17:27:48,008:INFO:Starting cross validation
2023-07-17 17:27:48,009:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:27:48,258:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:48,263:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:48,269:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:48,270:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:48,289:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:48,506:INFO:PyCaret RegressionExperiment
2023-07-17 17:27:48,506:INFO:Logging name: reg-default-name
2023-07-17 17:27:48,506:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-17 17:27:48,506:INFO:version 3.0.2
2023-07-17 17:27:48,506:INFO:Initializing setup()
2023-07-17 17:27:48,507:INFO:self.USI: 0afd
2023-07-17 17:27:48,507:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'X_train', 'data', 'logging_param', 'memory', 'y_test', 'X_test', 'fold_generator', 'gpu_n_jobs_param', 'exp_id', 'X', 'fold_groups_param', 'target_param', 'USI', 'gpu_param', '_ml_usecase', 'n_jobs_param', 'exp_name_log', 'html_param', 'pipeline', '_available_plots', 'log_plots_param', 'y', 'transform_target_param', 'seed', 'y_train'}
2023-07-17 17:27:48,507:INFO:Checking environment
2023-07-17 17:27:48,507:INFO:python_version: 3.10.4
2023-07-17 17:27:48,507:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2023-07-17 17:27:48,507:INFO:machine: AMD64
2023-07-17 17:27:48,507:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-17 17:27:48,512:INFO:Memory: svmem(total=7969243136, available=683995136, percent=91.4, used=7285248000, free=683995136)
2023-07-17 17:27:48,512:INFO:Physical Core: 6
2023-07-17 17:27:48,513:INFO:Logical Core: 6
2023-07-17 17:27:48,513:INFO:Checking libraries
2023-07-17 17:27:48,513:INFO:System:
2023-07-17 17:27:48,513:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2023-07-17 17:27:48,513:INFO:executable: C:\New folder\python.exe
2023-07-17 17:27:48,513:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-17 17:27:48,513:INFO:PyCaret required dependencies:
2023-07-17 17:27:48,513:INFO:                 pip: 23.1.2
2023-07-17 17:27:48,513:INFO:          setuptools: 58.1.0
2023-07-17 17:27:48,513:INFO:             pycaret: 3.0.2
2023-07-17 17:27:48,513:INFO:             IPython: 8.7.0
2023-07-17 17:27:48,513:INFO:          ipywidgets: 8.0.3
2023-07-17 17:27:48,513:INFO:                tqdm: 4.65.0
2023-07-17 17:27:48,513:INFO:               numpy: 1.23.5
2023-07-17 17:27:48,513:INFO:              pandas: 1.5.3
2023-07-17 17:27:48,513:INFO:              jinja2: 3.1.0
2023-07-17 17:27:48,514:INFO:               scipy: 1.9.1
2023-07-17 17:27:48,514:INFO:              joblib: 1.2.0
2023-07-17 17:27:48,514:INFO:             sklearn: 1.1.2
2023-07-17 17:27:48,514:INFO:                pyod: 1.1.0
2023-07-17 17:27:48,514:INFO:            imblearn: 0.10.1
2023-07-17 17:27:48,514:INFO:   category_encoders: 2.6.1
2023-07-17 17:27:48,514:INFO:            lightgbm: 3.3.5
2023-07-17 17:27:48,514:INFO:               numba: 0.57.1
2023-07-17 17:27:48,514:INFO:            requests: 2.28.1
2023-07-17 17:27:48,514:INFO:          matplotlib: 3.7.1
2023-07-17 17:27:48,514:INFO:          scikitplot: 0.3.7
2023-07-17 17:27:48,514:INFO:         yellowbrick: 1.5
2023-07-17 17:27:48,514:INFO:              plotly: 5.15.0
2023-07-17 17:27:48,514:INFO:             kaleido: 0.2.1
2023-07-17 17:27:48,514:INFO:         statsmodels: 0.14.0
2023-07-17 17:27:48,514:INFO:              sktime: 0.17.0
2023-07-17 17:27:48,514:INFO:               tbats: 1.1.3
2023-07-17 17:27:48,514:INFO:            pmdarima: 2.0.3
2023-07-17 17:27:48,514:INFO:              psutil: 5.9.4
2023-07-17 17:27:48,515:INFO:PyCaret optional dependencies:
2023-07-17 17:27:48,515:INFO:                shap: Not installed
2023-07-17 17:27:48,515:INFO:           interpret: Not installed
2023-07-17 17:27:48,515:INFO:                umap: Not installed
2023-07-17 17:27:48,515:INFO:    pandas_profiling: 4.3.1
2023-07-17 17:27:48,515:INFO:  explainerdashboard: Not installed
2023-07-17 17:27:48,515:INFO:             autoviz: Not installed
2023-07-17 17:27:48,515:INFO:           fairlearn: Not installed
2023-07-17 17:27:48,515:INFO:             xgboost: 1.7.5
2023-07-17 17:27:48,515:INFO:            catboost: Not installed
2023-07-17 17:27:48,515:INFO:              kmodes: Not installed
2023-07-17 17:27:48,515:INFO:             mlxtend: Not installed
2023-07-17 17:27:48,515:INFO:       statsforecast: Not installed
2023-07-17 17:27:48,515:INFO:        tune_sklearn: Not installed
2023-07-17 17:27:48,515:INFO:                 ray: Not installed
2023-07-17 17:27:48,515:INFO:            hyperopt: Not installed
2023-07-17 17:27:48,515:INFO:              optuna: Not installed
2023-07-17 17:27:48,515:INFO:               skopt: Not installed
2023-07-17 17:27:48,516:INFO:              mlflow: Not installed
2023-07-17 17:27:48,516:INFO:              gradio: Not installed
2023-07-17 17:27:48,516:INFO:             fastapi: Not installed
2023-07-17 17:27:48,516:INFO:             uvicorn: Not installed
2023-07-17 17:27:48,516:INFO:              m2cgen: Not installed
2023-07-17 17:27:48,516:INFO:           evidently: Not installed
2023-07-17 17:27:48,516:INFO:               fugue: Not installed
2023-07-17 17:27:48,516:INFO:           streamlit: 1.23.1
2023-07-17 17:27:48,516:INFO:             prophet: Not installed
2023-07-17 17:27:48,516:INFO:None
2023-07-17 17:27:48,516:INFO:Set up data.
2023-07-17 17:27:48,525:INFO:Set up train/test split.
2023-07-17 17:27:48,533:INFO:Set up index.
2023-07-17 17:27:48,533:INFO:Set up folding strategy.
2023-07-17 17:27:48,533:INFO:Assigning column types.
2023-07-17 17:27:48,537:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-17 17:27:48,537:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-17 17:27:48,542:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-17 17:27:48,547:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:48,613:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:48,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:48,679:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:48,683:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:48,683:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-17 17:27:48,689:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-17 17:27:48,695:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:48,767:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:48,798:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:48,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:48,818:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:48,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:48,827:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-07-17 17:27:48,830:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:48,833:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-17 17:27:48,838:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:48,847:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:48,902:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:48,951:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:48,952:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:48,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:48,960:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-17 17:27:48,965:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:48,976:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:49,029:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:49,077:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:49,079:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:49,083:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:49,083:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-07-17 17:27:49,094:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:49,154:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:49,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:49,201:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:49,205:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:49,215:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-17 17:27:49,277:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:49,328:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:49,328:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:49,331:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:49,331:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-07-17 17:27:49,408:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:49,458:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:49,459:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:49,462:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:49,537:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:49,590:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-17 17:27:49,591:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:49,594:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:49,594:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-17 17:27:49,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:49,723:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:49,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:49,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-17 17:27:49,854:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:49,857:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:49,858:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-07-17 17:27:49,986:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:49,989:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:50,122:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-17 17:27:50,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-17 17:27:50,128:INFO:Preparing preprocessing pipeline...
2023-07-17 17:27:50,128:INFO:Set up simple imputation.
2023-07-17 17:27:50,132:INFO:Set up encoding of ordinal features.
2023-07-17 17:27:50,133:INFO:Set up encoding of categorical features.
2023-07-17 17:27:56,024:INFO:Calculating mean and std
2023-07-17 17:27:56,024:INFO:Creating metrics dataframe
2023-07-17 17:27:56,258:INFO:Uploading results into container
2023-07-17 17:27:56,259:INFO:Uploading model into container now
2023-07-17 17:27:56,259:INFO:_master_model_container: 5
2023-07-17 17:27:56,259:INFO:_display_container: 2
2023-07-17 17:27:56,264:INFO:Lars(random_state=2273)
2023-07-17 17:27:56,264:INFO:create_model() successfully completed......................................
2023-07-17 17:27:56,398:INFO:SubProcess create_model() end ==================================
2023-07-17 17:27:56,398:INFO:Creating metrics dataframe
2023-07-17 17:27:56,403:INFO:Initializing Lasso Least Angle Regression
2023-07-17 17:27:56,403:INFO:Total runtime is 0.5339215636253357 minutes
2023-07-17 17:27:56,403:INFO:SubProcess create_model() called ==================================
2023-07-17 17:27:56,403:INFO:Initializing create_model()
2023-07-17 17:27:56,403:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:27:56,403:INFO:Checking exceptions
2023-07-17 17:27:56,403:INFO:Importing libraries
2023-07-17 17:27:56,403:INFO:Copying training dataset
2023-07-17 17:27:56,407:INFO:Defining folds
2023-07-17 17:27:56,407:INFO:Declaring metric variables
2023-07-17 17:27:56,408:INFO:Importing untrained model
2023-07-17 17:27:56,408:INFO:Lasso Least Angle Regression Imported successfully
2023-07-17 17:27:56,408:INFO:Starting cross validation
2023-07-17 17:27:56,409:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:27:56,577:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-17 17:27:56,594:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-17 17:27:56,622:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-17 17:27:56,628:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-17 17:27:56,635:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-17 17:27:56,671:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-17 17:27:57,086:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-17 17:27:57,112:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-17 17:27:57,114:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-17 17:27:57,125:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-17 17:27:58,186:INFO:Calculating mean and std
2023-07-17 17:27:58,187:INFO:Creating metrics dataframe
2023-07-17 17:27:58,432:INFO:Uploading results into container
2023-07-17 17:27:58,433:INFO:Uploading model into container now
2023-07-17 17:27:58,434:INFO:_master_model_container: 6
2023-07-17 17:27:58,434:INFO:_display_container: 2
2023-07-17 17:27:58,434:INFO:LassoLars(random_state=2273)
2023-07-17 17:27:58,434:INFO:create_model() successfully completed......................................
2023-07-17 17:27:58,566:INFO:SubProcess create_model() end ==================================
2023-07-17 17:27:58,566:INFO:Creating metrics dataframe
2023-07-17 17:27:58,572:INFO:Initializing Orthogonal Matching Pursuit
2023-07-17 17:27:58,573:INFO:Total runtime is 0.5700859427452087 minutes
2023-07-17 17:27:58,573:INFO:SubProcess create_model() called ==================================
2023-07-17 17:27:58,573:INFO:Initializing create_model()
2023-07-17 17:27:58,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:27:58,573:INFO:Checking exceptions
2023-07-17 17:27:58,573:INFO:Importing libraries
2023-07-17 17:27:58,573:INFO:Copying training dataset
2023-07-17 17:27:58,577:INFO:Defining folds
2023-07-17 17:27:58,577:INFO:Declaring metric variables
2023-07-17 17:27:58,577:INFO:Importing untrained model
2023-07-17 17:27:58,578:INFO:Orthogonal Matching Pursuit Imported successfully
2023-07-17 17:27:58,578:INFO:Starting cross validation
2023-07-17 17:27:58,580:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:27:58,767:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:58,779:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:58,817:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:58,824:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:58,824:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:58,844:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:59,261:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:59,298:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:59,362:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:27:59,384:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-17 17:28:00,410:INFO:Calculating mean and std
2023-07-17 17:28:00,411:INFO:Creating metrics dataframe
2023-07-17 17:28:00,652:INFO:Uploading results into container
2023-07-17 17:28:00,653:INFO:Uploading model into container now
2023-07-17 17:28:00,653:INFO:_master_model_container: 7
2023-07-17 17:28:00,654:INFO:_display_container: 2
2023-07-17 17:28:00,654:INFO:OrthogonalMatchingPursuit()
2023-07-17 17:28:00,654:INFO:create_model() successfully completed......................................
2023-07-17 17:28:00,789:INFO:SubProcess create_model() end ==================================
2023-07-17 17:28:00,789:INFO:Creating metrics dataframe
2023-07-17 17:28:00,794:INFO:Initializing Bayesian Ridge
2023-07-17 17:28:00,794:INFO:Total runtime is 0.6071057120958964 minutes
2023-07-17 17:28:00,794:INFO:SubProcess create_model() called ==================================
2023-07-17 17:28:00,795:INFO:Initializing create_model()
2023-07-17 17:28:00,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:28:00,795:INFO:Checking exceptions
2023-07-17 17:28:00,795:INFO:Importing libraries
2023-07-17 17:28:00,795:INFO:Copying training dataset
2023-07-17 17:28:00,798:INFO:Defining folds
2023-07-17 17:28:00,798:INFO:Declaring metric variables
2023-07-17 17:28:00,798:INFO:Importing untrained model
2023-07-17 17:28:00,799:INFO:Bayesian Ridge Imported successfully
2023-07-17 17:28:00,799:INFO:Starting cross validation
2023-07-17 17:28:00,800:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:28:02,559:INFO:Calculating mean and std
2023-07-17 17:28:02,559:INFO:Creating metrics dataframe
2023-07-17 17:28:02,792:INFO:Uploading results into container
2023-07-17 17:28:02,793:INFO:Uploading model into container now
2023-07-17 17:28:02,793:INFO:_master_model_container: 8
2023-07-17 17:28:02,793:INFO:_display_container: 2
2023-07-17 17:28:02,793:INFO:BayesianRidge()
2023-07-17 17:28:02,794:INFO:create_model() successfully completed......................................
2023-07-17 17:28:02,931:INFO:SubProcess create_model() end ==================================
2023-07-17 17:28:02,931:INFO:Creating metrics dataframe
2023-07-17 17:28:02,935:INFO:Initializing Passive Aggressive Regressor
2023-07-17 17:28:02,935:INFO:Total runtime is 0.642786697546641 minutes
2023-07-17 17:28:02,935:INFO:SubProcess create_model() called ==================================
2023-07-17 17:28:02,936:INFO:Initializing create_model()
2023-07-17 17:28:02,936:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:28:02,936:INFO:Checking exceptions
2023-07-17 17:28:02,936:INFO:Importing libraries
2023-07-17 17:28:02,936:INFO:Copying training dataset
2023-07-17 17:28:02,939:INFO:Defining folds
2023-07-17 17:28:02,939:INFO:Declaring metric variables
2023-07-17 17:28:02,940:INFO:Importing untrained model
2023-07-17 17:28:02,940:INFO:Passive Aggressive Regressor Imported successfully
2023-07-17 17:28:02,940:INFO:Starting cross validation
2023-07-17 17:28:02,942:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:28:04,821:INFO:Calculating mean and std
2023-07-17 17:28:04,822:INFO:Creating metrics dataframe
2023-07-17 17:28:05,066:INFO:Uploading results into container
2023-07-17 17:28:05,067:INFO:Uploading model into container now
2023-07-17 17:28:05,067:INFO:_master_model_container: 9
2023-07-17 17:28:05,067:INFO:_display_container: 2
2023-07-17 17:28:05,067:INFO:PassiveAggressiveRegressor(random_state=2273)
2023-07-17 17:28:05,067:INFO:create_model() successfully completed......................................
2023-07-17 17:28:05,202:INFO:SubProcess create_model() end ==================================
2023-07-17 17:28:05,203:INFO:Creating metrics dataframe
2023-07-17 17:28:05,206:INFO:Initializing Huber Regressor
2023-07-17 17:28:05,206:INFO:Total runtime is 0.6806403239568074 minutes
2023-07-17 17:28:05,207:INFO:SubProcess create_model() called ==================================
2023-07-17 17:28:05,207:INFO:Initializing create_model()
2023-07-17 17:28:05,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:28:05,207:INFO:Checking exceptions
2023-07-17 17:28:05,207:INFO:Importing libraries
2023-07-17 17:28:05,207:INFO:Copying training dataset
2023-07-17 17:28:05,211:INFO:Defining folds
2023-07-17 17:28:05,213:INFO:Declaring metric variables
2023-07-17 17:28:05,213:INFO:Importing untrained model
2023-07-17 17:28:05,213:INFO:Huber Regressor Imported successfully
2023-07-17 17:28:05,214:INFO:Starting cross validation
2023-07-17 17:28:05,215:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:28:05,440:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-17 17:28:05,451:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-17 17:28:05,512:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-17 17:28:05,520:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-17 17:28:05,521:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-17 17:28:05,551:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-17 17:28:06,031:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-17 17:28:06,074:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-17 17:28:06,118:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-17 17:28:06,147:WARNING:C:\Users\Naman\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-17 17:28:07,118:INFO:Calculating mean and std
2023-07-17 17:28:07,119:INFO:Creating metrics dataframe
2023-07-17 17:28:07,362:INFO:Uploading results into container
2023-07-17 17:28:07,363:INFO:Uploading model into container now
2023-07-17 17:28:07,363:INFO:_master_model_container: 10
2023-07-17 17:28:07,364:INFO:_display_container: 2
2023-07-17 17:28:07,364:INFO:HuberRegressor()
2023-07-17 17:28:07,364:INFO:create_model() successfully completed......................................
2023-07-17 17:28:08,001:INFO:SubProcess create_model() end ==================================
2023-07-17 17:28:08,002:INFO:Creating metrics dataframe
2023-07-17 17:28:08,079:INFO:Initializing K Neighbors Regressor
2023-07-17 17:28:08,080:INFO:Total runtime is 0.7285365263621012 minutes
2023-07-17 17:28:08,083:INFO:SubProcess create_model() called ==================================
2023-07-17 17:28:08,085:INFO:Initializing create_model()
2023-07-17 17:28:08,089:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:28:08,089:INFO:Checking exceptions
2023-07-17 17:28:08,089:INFO:Importing libraries
2023-07-17 17:28:08,091:INFO:Copying training dataset
2023-07-17 17:28:08,145:INFO:Defining folds
2023-07-17 17:28:08,146:INFO:Declaring metric variables
2023-07-17 17:28:08,147:INFO:Importing untrained model
2023-07-17 17:28:08,154:INFO:K Neighbors Regressor Imported successfully
2023-07-17 17:28:08,157:INFO:Starting cross validation
2023-07-17 17:28:08,190:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:28:10,066:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-17 17:28:10,346:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-17 17:28:10,502:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-17 17:28:11,152:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-17 17:28:11,230:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-17 17:28:11,275:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-17 17:28:13,402:INFO:PyCaret RegressionExperiment
2023-07-17 17:28:13,402:INFO:Logging name: reg-default-name
2023-07-17 17:28:13,402:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-17 17:28:13,402:INFO:version 3.0.2
2023-07-17 17:28:13,403:INFO:Initializing setup()
2023-07-17 17:28:13,403:INFO:self.USI: bf3b
2023-07-17 17:28:13,404:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'X_train', 'data', 'logging_param', 'memory', 'y_test', 'X_test', 'fold_generator', 'gpu_n_jobs_param', 'exp_id', 'X', 'fold_groups_param', 'target_param', 'USI', 'gpu_param', '_ml_usecase', 'n_jobs_param', 'exp_name_log', 'html_param', 'pipeline', '_available_plots', 'log_plots_param', 'y', 'transform_target_param', 'seed', 'y_train'}
2023-07-17 17:28:13,404:INFO:Checking environment
2023-07-17 17:28:13,404:INFO:python_version: 3.10.4
2023-07-17 17:28:13,404:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2023-07-17 17:28:13,404:INFO:machine: AMD64
2023-07-17 17:28:13,404:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-17 17:28:13,409:INFO:Memory: svmem(total=7969243136, available=630001664, percent=92.1, used=7339241472, free=630001664)
2023-07-17 17:28:13,409:INFO:Physical Core: 6
2023-07-17 17:28:13,409:INFO:Logical Core: 6
2023-07-17 17:28:13,409:INFO:Checking libraries
2023-07-17 17:28:13,409:INFO:System:
2023-07-17 17:28:13,409:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2023-07-17 17:28:13,409:INFO:executable: C:\New folder\python.exe
2023-07-17 17:28:13,409:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-17 17:28:13,409:INFO:PyCaret required dependencies:
2023-07-17 17:28:13,409:INFO:                 pip: 23.1.2
2023-07-17 17:28:13,409:INFO:          setuptools: 58.1.0
2023-07-17 17:28:13,409:INFO:             pycaret: 3.0.2
2023-07-17 17:28:13,409:INFO:             IPython: 8.7.0
2023-07-17 17:28:13,409:INFO:          ipywidgets: 8.0.3
2023-07-17 17:28:13,409:INFO:                tqdm: 4.65.0
2023-07-17 17:28:13,409:INFO:               numpy: 1.23.5
2023-07-17 17:28:13,409:INFO:              pandas: 1.5.3
2023-07-17 17:28:13,409:INFO:              jinja2: 3.1.0
2023-07-17 17:28:13,409:INFO:               scipy: 1.9.1
2023-07-17 17:28:13,409:INFO:              joblib: 1.2.0
2023-07-17 17:28:13,409:INFO:             sklearn: 1.1.2
2023-07-17 17:28:13,409:INFO:                pyod: 1.1.0
2023-07-17 17:28:13,409:INFO:            imblearn: 0.10.1
2023-07-17 17:28:13,409:INFO:   category_encoders: 2.6.1
2023-07-17 17:28:13,409:INFO:            lightgbm: 3.3.5
2023-07-17 17:28:13,409:INFO:               numba: 0.57.1
2023-07-17 17:28:13,409:INFO:            requests: 2.28.1
2023-07-17 17:28:13,411:INFO:          matplotlib: 3.7.1
2023-07-17 17:28:13,411:INFO:          scikitplot: 0.3.7
2023-07-17 17:28:13,411:INFO:         yellowbrick: 1.5
2023-07-17 17:28:13,412:INFO:              plotly: 5.15.0
2023-07-17 17:28:13,412:INFO:             kaleido: 0.2.1
2023-07-17 17:28:13,412:INFO:         statsmodels: 0.14.0
2023-07-17 17:28:13,412:INFO:              sktime: 0.17.0
2023-07-17 17:28:13,412:INFO:               tbats: 1.1.3
2023-07-17 17:28:13,413:INFO:            pmdarima: 2.0.3
2023-07-17 17:28:13,413:INFO:              psutil: 5.9.4
2023-07-17 17:28:13,413:INFO:PyCaret optional dependencies:
2023-07-17 17:28:13,413:INFO:                shap: Not installed
2023-07-17 17:28:13,413:INFO:           interpret: Not installed
2023-07-17 17:28:13,413:INFO:                umap: Not installed
2023-07-17 17:28:13,414:INFO:    pandas_profiling: 4.3.1
2023-07-17 17:28:13,414:INFO:  explainerdashboard: Not installed
2023-07-17 17:28:13,414:INFO:             autoviz: Not installed
2023-07-17 17:28:13,414:INFO:           fairlearn: Not installed
2023-07-17 17:28:13,414:INFO:             xgboost: 1.7.5
2023-07-17 17:28:13,414:INFO:            catboost: Not installed
2023-07-17 17:28:13,414:INFO:              kmodes: Not installed
2023-07-17 17:28:13,414:INFO:             mlxtend: Not installed
2023-07-17 17:28:13,414:INFO:       statsforecast: Not installed
2023-07-17 17:28:13,414:INFO:        tune_sklearn: Not installed
2023-07-17 17:28:13,414:INFO:                 ray: Not installed
2023-07-17 17:28:13,415:INFO:            hyperopt: Not installed
2023-07-17 17:28:13,415:INFO:              optuna: Not installed
2023-07-17 17:28:13,415:INFO:               skopt: Not installed
2023-07-17 17:28:13,415:INFO:              mlflow: Not installed
2023-07-17 17:28:13,415:INFO:              gradio: Not installed
2023-07-17 17:28:13,415:INFO:             fastapi: Not installed
2023-07-17 17:28:13,415:INFO:             uvicorn: Not installed
2023-07-17 17:28:13,415:INFO:              m2cgen: Not installed
2023-07-17 17:28:13,416:INFO:           evidently: Not installed
2023-07-17 17:28:13,416:INFO:               fugue: Not installed
2023-07-17 17:28:13,416:INFO:           streamlit: 1.23.1
2023-07-17 17:28:13,416:INFO:             prophet: Not installed
2023-07-17 17:28:13,416:INFO:None
2023-07-17 17:28:13,416:INFO:Set up data.
2023-07-17 17:28:13,617:INFO:Calculating mean and std
2023-07-17 17:28:13,618:INFO:Creating metrics dataframe
2023-07-17 17:28:13,874:INFO:Uploading results into container
2023-07-17 17:28:13,876:INFO:Uploading model into container now
2023-07-17 17:28:13,876:INFO:_master_model_container: 11
2023-07-17 17:28:13,876:INFO:_display_container: 2
2023-07-17 17:28:13,877:INFO:KNeighborsRegressor(n_jobs=-1)
2023-07-17 17:28:13,877:INFO:create_model() successfully completed......................................
2023-07-17 17:28:14,021:INFO:SubProcess create_model() end ==================================
2023-07-17 17:28:14,021:INFO:Creating metrics dataframe
2023-07-17 17:28:14,026:INFO:Initializing Decision Tree Regressor
2023-07-17 17:28:14,026:INFO:Total runtime is 0.8276429335276285 minutes
2023-07-17 17:28:14,027:INFO:SubProcess create_model() called ==================================
2023-07-17 17:28:14,027:INFO:Initializing create_model()
2023-07-17 17:28:14,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:28:14,027:INFO:Checking exceptions
2023-07-17 17:28:14,027:INFO:Importing libraries
2023-07-17 17:28:14,027:INFO:Copying training dataset
2023-07-17 17:28:14,031:INFO:Defining folds
2023-07-17 17:28:14,032:INFO:Declaring metric variables
2023-07-17 17:28:14,032:INFO:Importing untrained model
2023-07-17 17:28:14,032:INFO:Decision Tree Regressor Imported successfully
2023-07-17 17:28:14,032:INFO:Starting cross validation
2023-07-17 17:28:14,033:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:28:16,005:INFO:Calculating mean and std
2023-07-17 17:28:16,006:INFO:Creating metrics dataframe
2023-07-17 17:28:16,254:INFO:Uploading results into container
2023-07-17 17:28:16,255:INFO:Uploading model into container now
2023-07-17 17:28:16,256:INFO:_master_model_container: 12
2023-07-17 17:28:16,256:INFO:_display_container: 2
2023-07-17 17:28:16,256:INFO:DecisionTreeRegressor(random_state=2273)
2023-07-17 17:28:16,256:INFO:create_model() successfully completed......................................
2023-07-17 17:28:16,398:INFO:SubProcess create_model() end ==================================
2023-07-17 17:28:16,398:INFO:Creating metrics dataframe
2023-07-17 17:28:16,404:INFO:Initializing Random Forest Regressor
2023-07-17 17:28:16,404:INFO:Total runtime is 0.867269206047058 minutes
2023-07-17 17:28:16,404:INFO:SubProcess create_model() called ==================================
2023-07-17 17:28:16,404:INFO:Initializing create_model()
2023-07-17 17:28:16,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:28:16,404:INFO:Checking exceptions
2023-07-17 17:28:16,404:INFO:Importing libraries
2023-07-17 17:28:16,404:INFO:Copying training dataset
2023-07-17 17:28:16,408:INFO:Defining folds
2023-07-17 17:28:16,408:INFO:Declaring metric variables
2023-07-17 17:28:16,408:INFO:Importing untrained model
2023-07-17 17:28:16,409:INFO:Random Forest Regressor Imported successfully
2023-07-17 17:28:16,409:INFO:Starting cross validation
2023-07-17 17:28:16,410:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:28:19,162:INFO:Calculating mean and std
2023-07-17 17:28:19,163:INFO:Creating metrics dataframe
2023-07-17 17:28:19,983:INFO:Uploading results into container
2023-07-17 17:28:19,989:INFO:Uploading model into container now
2023-07-17 17:28:19,991:INFO:_master_model_container: 13
2023-07-17 17:28:19,992:INFO:_display_container: 2
2023-07-17 17:28:19,996:INFO:RandomForestRegressor(n_jobs=-1, random_state=2273)
2023-07-17 17:28:19,996:INFO:create_model() successfully completed......................................
2023-07-17 17:28:21,303:INFO:SubProcess create_model() end ==================================
2023-07-17 17:28:21,304:INFO:Creating metrics dataframe
2023-07-17 17:28:21,390:INFO:Initializing Extra Trees Regressor
2023-07-17 17:28:21,391:INFO:Total runtime is 0.9503936688105264 minutes
2023-07-17 17:28:21,394:INFO:SubProcess create_model() called ==================================
2023-07-17 17:28:21,396:INFO:Initializing create_model()
2023-07-17 17:28:21,397:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:28:21,397:INFO:Checking exceptions
2023-07-17 17:28:21,398:INFO:Importing libraries
2023-07-17 17:28:21,398:INFO:Copying training dataset
2023-07-17 17:28:21,475:INFO:Defining folds
2023-07-17 17:28:21,480:INFO:Declaring metric variables
2023-07-17 17:28:21,484:INFO:Importing untrained model
2023-07-17 17:28:21,496:INFO:Extra Trees Regressor Imported successfully
2023-07-17 17:28:21,500:INFO:Starting cross validation
2023-07-17 17:28:21,598:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:28:23,581:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-17 17:28:23,880:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-17 17:28:24,008:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-17 17:28:24,425:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-17 17:28:24,444:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-17 17:28:24,468:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-17 17:28:27,161:INFO:Calculating mean and std
2023-07-17 17:28:27,162:INFO:Creating metrics dataframe
2023-07-17 17:28:28,271:INFO:Uploading results into container
2023-07-17 17:28:28,281:INFO:Uploading model into container now
2023-07-17 17:28:28,286:INFO:_master_model_container: 14
2023-07-17 17:28:28,287:INFO:_display_container: 2
2023-07-17 17:28:28,290:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2273)
2023-07-17 17:28:28,290:INFO:create_model() successfully completed......................................
2023-07-17 17:28:29,268:INFO:SubProcess create_model() end ==================================
2023-07-17 17:28:29,270:INFO:Creating metrics dataframe
2023-07-17 17:28:29,329:INFO:Initializing AdaBoost Regressor
2023-07-17 17:28:29,333:INFO:Total runtime is 1.082761792341868 minutes
2023-07-17 17:28:29,337:INFO:SubProcess create_model() called ==================================
2023-07-17 17:28:29,339:INFO:Initializing create_model()
2023-07-17 17:28:29,340:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:28:29,340:INFO:Checking exceptions
2023-07-17 17:28:29,342:INFO:Importing libraries
2023-07-17 17:28:29,344:INFO:Copying training dataset
2023-07-17 17:28:29,397:INFO:Defining folds
2023-07-17 17:28:29,397:INFO:Declaring metric variables
2023-07-17 17:28:29,399:INFO:Importing untrained model
2023-07-17 17:28:29,402:INFO:AdaBoost Regressor Imported successfully
2023-07-17 17:28:29,406:INFO:Starting cross validation
2023-07-17 17:28:29,426:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:28:31,414:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-17 17:28:32,146:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-17 17:28:32,147:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-17 17:28:32,460:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-17 17:28:32,481:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-17 17:28:33,431:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-17 17:28:34,536:INFO:Calculating mean and std
2023-07-17 17:28:34,537:INFO:Creating metrics dataframe
2023-07-17 17:28:34,810:INFO:Uploading results into container
2023-07-17 17:28:34,811:INFO:Uploading model into container now
2023-07-17 17:28:34,812:INFO:_master_model_container: 15
2023-07-17 17:28:34,812:INFO:_display_container: 2
2023-07-17 17:28:34,812:INFO:AdaBoostRegressor(random_state=2273)
2023-07-17 17:28:34,812:INFO:create_model() successfully completed......................................
2023-07-17 17:28:34,943:INFO:SubProcess create_model() end ==================================
2023-07-17 17:28:34,943:INFO:Creating metrics dataframe
2023-07-17 17:28:34,948:INFO:Initializing Gradient Boosting Regressor
2023-07-17 17:28:34,948:INFO:Total runtime is 1.1763402779897052 minutes
2023-07-17 17:28:34,948:INFO:SubProcess create_model() called ==================================
2023-07-17 17:28:34,948:INFO:Initializing create_model()
2023-07-17 17:28:34,948:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:28:34,948:INFO:Checking exceptions
2023-07-17 17:28:34,948:INFO:Importing libraries
2023-07-17 17:28:34,948:INFO:Copying training dataset
2023-07-17 17:28:34,952:INFO:Defining folds
2023-07-17 17:28:34,952:INFO:Declaring metric variables
2023-07-17 17:28:34,952:INFO:Importing untrained model
2023-07-17 17:28:34,953:INFO:Gradient Boosting Regressor Imported successfully
2023-07-17 17:28:34,953:INFO:Starting cross validation
2023-07-17 17:28:34,954:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:28:37,113:INFO:Calculating mean and std
2023-07-17 17:28:37,114:INFO:Creating metrics dataframe
2023-07-17 17:28:37,383:INFO:Uploading results into container
2023-07-17 17:28:37,384:INFO:Uploading model into container now
2023-07-17 17:28:37,384:INFO:_master_model_container: 16
2023-07-17 17:28:37,384:INFO:_display_container: 2
2023-07-17 17:28:37,384:INFO:GradientBoostingRegressor(random_state=2273)
2023-07-17 17:28:37,384:INFO:create_model() successfully completed......................................
2023-07-17 17:28:37,964:INFO:SubProcess create_model() end ==================================
2023-07-17 17:28:37,965:INFO:Creating metrics dataframe
2023-07-17 17:28:38,024:INFO:Initializing Extreme Gradient Boosting
2023-07-17 17:28:38,026:INFO:Total runtime is 1.2276441057523089 minutes
2023-07-17 17:28:38,028:INFO:SubProcess create_model() called ==================================
2023-07-17 17:28:38,030:INFO:Initializing create_model()
2023-07-17 17:28:38,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:28:38,034:INFO:Checking exceptions
2023-07-17 17:28:38,034:INFO:Importing libraries
2023-07-17 17:28:38,035:INFO:Copying training dataset
2023-07-17 17:28:38,069:INFO:Defining folds
2023-07-17 17:28:38,071:INFO:Declaring metric variables
2023-07-17 17:28:38,072:INFO:Importing untrained model
2023-07-17 17:28:38,080:INFO:Extreme Gradient Boosting Imported successfully
2023-07-17 17:28:38,082:INFO:Starting cross validation
2023-07-17 17:28:38,096:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:28:41,474:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-17 17:28:41,614:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-17 17:28:41,616:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-17 17:28:41,622:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-17 17:28:44,291:INFO:Calculating mean and std
2023-07-17 17:28:44,291:INFO:Creating metrics dataframe
2023-07-17 17:28:46,125:INFO:Uploading results into container
2023-07-17 17:28:46,130:INFO:Uploading model into container now
2023-07-17 17:28:46,132:INFO:_master_model_container: 17
2023-07-17 17:28:46,132:INFO:_display_container: 2
2023-07-17 17:28:46,141:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=2273, ...)
2023-07-17 17:28:46,141:INFO:create_model() successfully completed......................................
2023-07-17 17:28:46,803:INFO:SubProcess create_model() end ==================================
2023-07-17 17:28:46,804:INFO:Creating metrics dataframe
2023-07-17 17:28:46,858:INFO:Initializing Light Gradient Boosting Machine
2023-07-17 17:28:46,860:INFO:Total runtime is 1.3748689413070676 minutes
2023-07-17 17:28:46,861:INFO:SubProcess create_model() called ==================================
2023-07-17 17:28:46,863:INFO:Initializing create_model()
2023-07-17 17:28:46,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:28:46,864:INFO:Checking exceptions
2023-07-17 17:28:46,864:INFO:Importing libraries
2023-07-17 17:28:46,865:INFO:Copying training dataset
2023-07-17 17:28:46,911:INFO:Defining folds
2023-07-17 17:28:46,912:INFO:Declaring metric variables
2023-07-17 17:28:46,914:INFO:Importing untrained model
2023-07-17 17:28:46,917:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-17 17:28:46,919:INFO:Starting cross validation
2023-07-17 17:28:46,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:28:49,239:WARNING:C:\New folder\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-17 17:28:51,397:INFO:Calculating mean and std
2023-07-17 17:28:51,399:INFO:Creating metrics dataframe
2023-07-17 17:28:51,680:INFO:Uploading results into container
2023-07-17 17:28:51,681:INFO:Uploading model into container now
2023-07-17 17:28:51,682:INFO:_master_model_container: 18
2023-07-17 17:28:51,682:INFO:_display_container: 2
2023-07-17 17:28:51,682:INFO:LGBMRegressor(random_state=2273)
2023-07-17 17:28:51,682:INFO:create_model() successfully completed......................................
2023-07-17 17:28:51,838:INFO:SubProcess create_model() end ==================================
2023-07-17 17:28:51,838:INFO:Creating metrics dataframe
2023-07-17 17:28:51,844:INFO:Initializing Dummy Regressor
2023-07-17 17:28:51,844:INFO:Total runtime is 1.457935825983683 minutes
2023-07-17 17:28:51,844:INFO:SubProcess create_model() called ==================================
2023-07-17 17:28:51,844:INFO:Initializing create_model()
2023-07-17 17:28:51,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A5F53AB60>, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:28:51,845:INFO:Checking exceptions
2023-07-17 17:28:51,845:INFO:Importing libraries
2023-07-17 17:28:51,845:INFO:Copying training dataset
2023-07-17 17:28:51,848:INFO:Defining folds
2023-07-17 17:28:51,848:INFO:Declaring metric variables
2023-07-17 17:28:51,849:INFO:Importing untrained model
2023-07-17 17:28:51,849:INFO:Dummy Regressor Imported successfully
2023-07-17 17:28:51,850:INFO:Starting cross validation
2023-07-17 17:28:51,851:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-17 17:28:53,937:INFO:Calculating mean and std
2023-07-17 17:28:53,937:INFO:Creating metrics dataframe
2023-07-17 17:28:54,218:INFO:Uploading results into container
2023-07-17 17:28:54,219:INFO:Uploading model into container now
2023-07-17 17:28:54,219:INFO:_master_model_container: 19
2023-07-17 17:28:54,219:INFO:_display_container: 2
2023-07-17 17:28:54,220:INFO:DummyRegressor()
2023-07-17 17:28:54,220:INFO:create_model() successfully completed......................................
2023-07-17 17:28:54,356:INFO:SubProcess create_model() end ==================================
2023-07-17 17:28:54,356:INFO:Creating metrics dataframe
2023-07-17 17:28:54,364:INFO:Initializing create_model()
2023-07-17 17:28:54,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024A5EBB8730>, estimator=Ridge(random_state=2273), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-17 17:28:54,364:INFO:Checking exceptions
2023-07-17 17:28:54,365:INFO:Importing libraries
2023-07-17 17:28:54,365:INFO:Copying training dataset
2023-07-17 17:28:54,369:INFO:Defining folds
2023-07-17 17:28:54,369:INFO:Declaring metric variables
2023-07-17 17:28:54,369:INFO:Importing untrained model
2023-07-17 17:28:54,369:INFO:Declaring custom model
2023-07-17 17:28:54,371:INFO:Ridge Regression Imported successfully
2023-07-17 17:28:54,373:INFO:Cross validation set to False
2023-07-17 17:28:54,373:INFO:Fitting Model
2023-07-17 17:28:54,687:INFO:Ridge(random_state=2273)
2023-07-17 17:28:54,687:INFO:create_model() successfully completed......................................
2023-07-17 17:28:54,846:INFO:_master_model_container: 19
2023-07-17 17:28:54,846:INFO:_display_container: 2
2023-07-17 17:28:54,846:INFO:Ridge(random_state=2273)
2023-07-17 17:28:54,846:INFO:compare_models() successfully completed......................................
